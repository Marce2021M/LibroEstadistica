# Muestreo Aleatorio Multietápico
```{r, echo = FALSE, message=FALSE}
library(tidyverse)
library(kableExtra)
```
La idea de un muestreo aleatorio multietápico es un modelo donde la aleatoriedad ocurre más de una vez. El ejemplo común es el de encuestadores que van a una casa. De inicio la casa se selecciona al azar usando un censo o un mapa (primer fuente de aleatoriedad) y una vez que se llega a la casa y se le pregunta a la gente de la misma cuántos habitantes hay, se selecciona a una persona de la casa de manera aleatoria (segunda fuente de aleatoriedad) para realizarle la encuesta. 

> **Nota** La diferencia esencial entre una etapa y un estrato es que el estrato no es aleatorio. Un estrato es cómo decido yo dividir mi muestra que tenga sentido de manera explicativa (por ejemplo hombre/mujer/otrx o por estado civil, grupo de edad). Pero no es que _aleatoriamente_ se seleccione un hombre o una mujer sino que es una característica de la población que se mide y en base a la cual se clasifica. Por otro lado, una etapa va a ser algo que se selecciona de manera aleatoria.

Hay dos razones principales para hacer muestreo multietápico:

  a. *Se desconoce la población total.* No hay un censo de toda la población. Pero sí hay forma de identificar otros grupos dentro de los cuales se puede muestrear y obtener un censo. 
    
  b. *La muestra está repartida en un área demasiado grande* (piensa, por ejemplo, muestrear en una selva) por lo que es imposible cubrir toda el área por lo que se muestrean regiones y luego subregiones a fin de tener toda la muestra (en la selva igual se seleccionarían al azar regiones y luego subregiones). 
  

El primer ejemplo que analizaremos será un _muestreo aleatorizado por clusters de una sola etapa_. De ahí saltaremos al bietápico y daremos las líneas para el multietápico (sin meternos mucho en ello). Para ello la definición de cluster será un subgrupo en el cual se divide la población donde la selección aleatoria ocurre entre los grupos (y no entre las unidades primarias de muestreo) y luego dentro del cluster se realiza un censo. 

Por poner un ejemplo, de _muestreo aleatorizado por clusters de una sola etapa_ podría interesar conocer el uso de drogas dentro de estudiantes de preparatoria. Para ello se divide a la población estudiantil en subgrupos (las preparatorias) y se muestrean las preparatorias (el cluster). Una vez seleccionadas algunas preparatorias dentro de las mismas se hace un censo de todos los estudiantes preguntándoles sobre consumo de drogas.  

El algoritmo multietápico suele ser como sigue: 

  a. Se agrupan elementos poblacionales en subpoblaciones disjuntas conocidas como **unidades primarias de muestreo** (PSU) dentro de las cuales se toma una muestra (_primera etapa_)
    
  b. Los elementos de cada PSU se consideran nuevas unidades de muestreo (SSU, unidades secundarias de muestreo) las cuales pueden ser elementos (de los cuales se toma un censo) o bien nuevos clusters
    
  c. En caso que la SSU sean nuevos clusters el proceso se repite en tantas etapas como sea necesario hasta tener un censo de elementos (en algún nivel). Estas se conocen como undades terciarias de muestro (o penúltimas, $n$-ésimas, lo que sea que aplique según cuántas se tengan). 
    
## Muestreo aleatorio por clusters en una sola etapa 
En este caso se tiene una población finita $U = (x_1, x_2, \dots, x_N)^T$ particionada en $N_t$ subpoblaciones llamadas _clusters_ denotadas $U_1, U_2, \dots, U_{N_1}$. Generalmente identificamos al cluster por su subíndice:
$$
\mathcal{U}_1 = \{ 1, 2, \dots, N_1\}
$$
En este caso se tiene que:
$$
U = \bigcup_{i \in \mathcal{C}_1} U_i \qquad \text{y} \qquad N = \sum\limits_{i \in \mathcal{C}_1} N_i
$$
El muestreo aleatorio por clusters en una sola etapa se define como sigue:

    a. Se obtiene una muestra^[La muestra puede ser estratificada, aleatoria simple, bernoulli, como sea...] $\mathcal{S}_1$ de clusters obtenidos de $\mathcal{C}_1$ de acuerdo a algún diseño probabilístico $\mathbb{P}_1$. El tamaño de la muestra es $n_1$. 
    
    b. Se mide cada elemento de los clusters seleccionados. 
    
Podemos hacer dicho esquema de muestreo en `R`, por ejemplo si consideramos una base de escuelas donde se tiene el registro de cada uno de los alumnos en la escuela:

```{r}
#Creamos la base de datos
escuelas       <- paste0("Escuela ", 1:20)
datos.escuelas <- data.frame(Escuela = sample(escuelas, 1000, replace = TRUE), 
                             Promedio_Alumno = runif(1000, 6, 10))

#Seleccionamos las escuelas al azar (los clusters)
escuelas.seleccionadas <- sample(escuelas, 5)

#Una vez se tiene el cluster se produce un censo de los clusters
muestra <- datos.escuelas %>% filter(Escuela %in% escuelas.seleccionadas)
```

En este caso denotaremos la muestra observada como:
$$
\mathcal{S} = \bigcup_{i \in \mathcal{S}_1} U_i
$$

con su tamaño respectivo:
$$
n_{\mathcal{S}} = \sum\limits_{i \in \mathcal{S}_1} N_i
$$
> Toma en cuenta que aunque la muestra de clusters sea de tamaño fijo en general el número de elementos observados no va a ser fijo pues los tamaños de cluster pueden variar. 

Agregamos unas nuevas probabilidades de pertenencia. Para un elemento $x_k \in U_i$ se tiene que:
$$
\pi_{k} = \mathbb{P}(x_k \in \mathcal{S}) = \mathbb{P}(U_i \subseteq \mathcal{S}) = \pi_{1,i}
$$
mientras que para $x_k \in U_i$ y $x_l\in U_j$ se tiene:
$$
\pi_{k,l} = \mathbb{P}(x_k  \in \mathcal{S},x_l  \in \mathcal{S}) = \mathbb{P}(U_i \subseteq \mathcal{S}, U_j \subseteq \mathcal{S}) = \pi_{1,i,j}
$$

El total poblacional puede escribirse como:
$$
t = \sum_{U_i} t_i = \sum_{k = 1}^N x_k 
$$
donde $t_i = \sum_{x_k \in U_i} x_k$ son los totales de cada cluster. En este contexto tenemos que:
$$
\hat{t} = \sum\limits_{i \in \mathcal{S}_1} \dfrac{t_i}{\pi_{1i}}
$$
es un estimador insesgado del total poblacional. Su varianza está dada por:
$$
\textrm{Var}(\hat{t}) = \sum\limits_{j \in \mathcal{C}_1}\sum\limits_{i \in \mathcal{C}_1} \dfrac{\Delta_{1ij}}{\pi_{1i}\pi_{1j}} t_i t_j
$$
mientras que un estimador insesgado es:
$$
\widehat{\textrm{Var}}(\hat{t}) = \sum\limits_{j \in \mathcal{S}_1}\sum\limits_{i \in \mathcal{S}_1}\dfrac{1}{\pi_{1ij}} \dfrac{\Delta_{1ij}}{\pi_{1i}\pi_{1j}} t_i t_j
$$
Las demostraciones de que dichos estimadores son insesgados son idénticas a las que ya hicimos con muestreo aleatorio simple y no las repetiremos. 

En particular podemos tener que en el caso de muestreo aleatorio simple sin reemplazo se tiene:
$$
\hat{t} = N_1 \bar{t}_{\mathcal{S}_1}
$$
donde $\bar{t}_{\mathcal{S}_1} = \sum_{i \in \mathcal{S}_1} t_i / n_1$ es la media de los totales. En este caso las expresiones de las varianzas son idénticas a las que ya conocemos (justo porque se deducen de la misma manera):
$$
\textrm{Var}(\hat{t}) = N_1^2 \dfrac{1 - f_1}{n_1}S^2_{t,\mathcal{U}_1}
$$
donde $f_1 = n_1/N_1$ es la fracción muestral del cluster y 
$$
S^2_{t,\mathcal{U}_1} = \dfrac{1}{N_1 - 1} \sum_{i\in\mathcal{U}_1}(t_i - \bar{t}_{\mathcal{U}_1})^2
$$
con $\bar{t}_{\mathcal{U}_1} = \sum\limits_{i \in \mathcal{U}_1} t_i / N_1$. El estimador de la varianza corresponde al muestral:
$$
\widehat{\textrm{Var}}(\hat{t}) =  N_1^2 \dfrac{1 - f_1}{n_1}S^2_{t,\mathcal{S}_1}
$$
donde
$$
S^2_{t,\mathcal{S}_1} = \dfrac{1}{n_1 - 1} \sum_{i\in\mathcal{S}_1}(t_i - \bar{t}_{\mathcal{S}_1})^2
$$

### Ejemplo 
El objetivo es estimar la media de ingreso de hogares en una colonia de una ciudad que consiste de 60 cuadras de casas de tamaño variable. Para esto seleccionamos tres cuadras usando muestreo aleatorio simple sin reemplazo y entrevistamos a todos los hogares en dichas cuadras. Se sabe, además que hay $5000$ casas en esta colonia y la tabla muestra los resultados de la encuesta

```{r, echo = FALSE}
data.frame(
  Cuadra = c(1,2,3),
  `Casas en la cuadra` = c(120, 100, 80),
  `Total de ingreso en la cuadra` = c(2100, 2000, 1500)
) %>% 
  kable() %>% kable_styling()
```



**Estimar la media de ingreso y su varianza.**

**Solución**
Tenemos que $n_1 = 3$, $N = 5000$ y $N_1 = 60$. Las probabilidades de inclusión son:
$$
\pi_{1i} = \frac{n_1}{N_1} = \frac{1}{20}
$$
Se construye el estimador de la media mediante:
$$
\hat{\bar{x}} = \frac{1}{N} \sum_{i \in \mathcal{S}} \underbrace{\dfrac{t_i}{\frac{n_1}{N_1}}}_{\pi_{1i}} =  \frac{N_1}{N} \frac{1}{n_1}\sum_{i \in \mathcal{S}}t_i \approx 22.4
$$

Por otro lado como $\hat{\bar{x}} = \hat{t}/N$ entonces se tiene que
$$
\textrm{Var}(\hat{\bar{x}}) = \textrm{Var}(\hat{t})/N^2
$$
de donde se obtiene:
$$
\widehat{\textrm{Var}}(\hat{\bar{x}}) =\approx 4.7
$$
(El resultado anterior sale sólo de sustituir). 


## Muestreo aleatorio por clusters bietápico (en dos etapas)
Usualmente es demasiado caro hacer el censo _dentro_ del cluster por lo que se muestrea dentro del mismo una vez seleccionado. (Por ejemplo, en el caso de las drogas en las escuelas es más fácil seleccionar sólo unos alumnos al azar y no a todos los alumnos). En estos casos hay dos fuentes de aleatoriedad: las unidades primarias de muestreo (los clusters más grandotes) y las secundarias (muestreo dentro del cluster), La notación se va a complicar pero el principio es el mismo. 


La idea es que la población de elementos:
$$
\mathcal{U} = \{ x_1, x_2, \dots, x_N\}
$$
es subdividida en $N$ unidades primarias de muestreo denotadas $U_1, \dots, U_{N_1}$. El tamaño de $U_i$ es $N_u$. El diseño muestral es como sigue:

  a. Se obtiene una muestra $\mathcal{S}_1$ de unidades primarias de muestreo de acuerdo con algún diseño $\mathbb{P}_1$. 
  b. Para cada $U_i \in \mathcal{S}_1$ se selecciona una muestra de $S_i$ elementos de $U_i$ de acuerdo al diseño condicional $\mathbb{P}_i\big(\cdot | \mathcal{S}_1\big)$
  
La muestra resultante de elementos se denota:
$$
\mathcal{S} = \bigcup_{i \in \mathcal{S}_1} S_i
$$

En este capítulo pediremos dos cosas para los muestreos condicionales:

  **Independencia** Que el muestreo de $U_i$ sea independiente del de $U_j$. Matemáticamente esto se escribe como:
$$
\mathbb{P}\Bigg( \bigcup_{i \in \mathcal{S}} S_i | \mathcal{S}_1 \Bigg)  = \prod\limits_{i \in \mathcal{S}} \mathbb{P}(S_i | \mathcal{S}_1 )
$$

  **Invarianza** Una vez que se incluye el $U_i$ en la muestra el muestreo siempre es igual independientemente de los $U_j$; es decir:  $\mathbb{P}_i\big(\cdot | \mathcal{S}_1\big) = \mathbb{P}_i\big(\cdot \big)$. 

Los tamaños de muestra se definen como sigue: el número de unidades primarias de muestreo es $S_i$ es $n_i$. El número total de elementos en $\mathcal{S}$ está dado por:
$$
n_{\mathcal{S}} = \sum_{i \in \mathcal{S}} n_{i}
$$
Las probabilidades de inclusión en la primera etapa $\mathbb{P}_1$ son:
$$
\Delta_{1ij} = \pi_{1ij} - \pi_{1i} \pi_{1j}
$$
 con 
$$
\Delta_{1ii} = \pi_{1i}(1 - \pi_{1i})
$$
Para la segunda etapa (el muestreo adentro de un $\mathcal{S}_i$) las cantidades son:
$$
\Delta_{kl|i} = \pi_{kl|i} - \pi_{k|i} \pi_{l|i}
$$

con $\Delta_{kk|i} = \pi_{k|i}(1 - \pi_{k|i})$. Notamos que por invarianza e independencia:
$$
\pi_k = \pi_{1i} \pi_{k | i} \qquad \textrm{para } x_k\in U_i
$$
mientras que:
$$
\pi_{kl} = \begin{cases}
\pi_{1i} \pi_{k|i} & \text{ si } x_k = x_l \in U_i\\
\pi_{1i} \pi_{kl|i}  & \text{ si } x_k, x_l \in U_i\\
\pi_{1ij} \pi_{k|i}\pi_{l|j} & \text{ si } x_k \in U_i \text{ y } x_l \in U_j
\end{cases}
$$

Un estimador del total poblacional (insesgado) es el ya usual estimador HT:
$$
\hat{t} = \sum\limits_{\mathcal{S}_1} \frac{\hat{t}_{i}}{\pi_{1i}}
$$

donde $\hat{t}_{i}$ es el estimador de $t_i$ el total de $U_i$. La varianza de $\hat{t}$ se puede escribir como:
$$
\textrm{Var}(\hat{t}) = V_{PSU} + V_{SSU}
$$

donde 
$$
V_{PSU} = \sum\sum_{U_i} \dfrac{\Delta_{1ij}}{\pi_{1i} \pi_{1j}} t_i t_j
$$
$$
V_{SSU} = \sum_{U_i} \dfrac{V_i}{\pi_{1i}}
$$
con
$$
V_i = \sum\sum_{U_i} \Delta_{kl|i} \dfrac{x_k}{\pi_{k|i}}\dfrac{x_l}{\pi_{l|i}}
$$
Los estimadores insesgados así como las expresiones reducidas de la varianza pueden hallarse en el formulario bietápico disponible en comunidad. **Demostración** Checar el Sarndal páginas 136-139.

## Ejemplo: Disco duro

En el disco duro de una computadora hay 400 bases de datos cada una de las cuales consiste en 50 entradas (renglones). Se desea estimar el número de caracteres por entrada por lo que se hace muestreo aleatorio simple de los 80 archivos y luego dentro de cada archivo muestreo aleatorio simple para $5$ entradas. En el caso del formulario de comunidad, sean $m = 80$ y $n = 5$. Después de muestrear obtenemos:

  a. La media muestral de los estimadores para el número total de caracteres por archivo dada por: $s^2_T = 905000$
  b. La media de las $m$ varianzas muestrales $s^2_i$ es igual a $805$ donde $s^2_i$ representa la varianza del número de caracteres por entrada en el iésimo archivo.

Estimar el número promedio de caracteres por entrada junto con su precisión de manera insesgada. Dar un intervalo de confianza al $95\%$. 

**Solución**

Denotando $y_{i,k}$ al número de caracteres de la entrada $k$ del archivo $i$ tenemos que la cantidad de interés es:
$$
\bar{y} =\frac{1}{N} \sum\limits_{i = 1}^M \sum_{k \in U_i} y_{i,k} = \frac{1}{N} \sum\limits_{i = 1}^M \bar{N}\bar{y}_i = \frac{1}{M}\sum_{i = 1}^M \bar{y}_i
$$
donde

  a. $M = 400$ es el número de archivos (PSU)
  
  b. $\bar{N} = 50$ es el número de entradas por archivo (SSU)
  
  c. $N = 400 \times 50$ es el número total de entradas ($n_{\mathcal{S}}$)
  
  d. $\bar{y}_i$ es el número promedio de caracteres por entrada del archivo $i$. 

  e. $U_i$ es el cluster $i$ (identificadores de las entradas del archivo $i$ en este caso). 

El estimador insesgado de la media sería 
$$
\hat{\bar{y}} = \dfrac{\hat{y}}{N} = \dfrac{1}{N} \sum\limits_{i \in \mathcal{S}}^M \dfrac{\hat{t}_i }{m/M}
$$

donde $\hat{t}_i$ son los estimadores de los totales del archivo $i$ y $\mathcal{S}$ es la colección de índices seleccionados para la muestra. En particular:
$$
\hat{t}_i =\sum_{k \in \mathcal{S}_i} \dfrac{y_{i,k} }{\bar{n}/\bar{N}} = 
$$
El estimador de $\widehat{\textrm{Var}}(\hat{\bar{y}}) = \frac{1}{N^2}\widehat{\text{Var}}(\hat{t}) \approx 3.98.$ cuando se sustituye. Finalmente:
$$
\hat{\bar{y}} \pm Z_{1 - 0.05/2}\sqrt{3.98}
$$
da el intervalo de confianza. 

## Ejemplo: Encuesta Nacional de Salud 
La [Encuesta Nacional de Salud y Nutrición 2018](https://ensanut.insp.mx/encuestas/ensanut2018/descargas.php) es una encuesta nacional estratificada bietápica. La nota metodológica completa puede hallarse [en el reporte](https://ensanut.insp.mx/encuestas/ensanut2018/doctos/metodologia/ensanut_2018_diseno_muestral.pdf). A partir de la lectura de la nota metodológica se establece el diseño muestral:

```{r}
library(readr)
library(survey)
ensanut <- read_csv("~/Dropbox/ITAM_CLASES/Aplicada1/Archivos_2020/ENSANUT_1.csv")

#Diseño de encuesta completa
ensanut <- ensanut %>% mutate(id = paste0(VIV_SEL, NUMREN))

#Codificar diabéticos
ensanut <- ensanut %>% mutate(Diabetes = ifelse(P3_1 == 1, 1, 0))

#Diseño muestral
diseño  <- svydesign(id= ~id, strata= ~EST_DIS, weights=~F_20MAS, PSU=~UPM, data= ensanut, nest=TRUE)
```

Podemos utilizar el diseño muestral y el paquete survey para estimaciones como calcular la proporción nacional de diabéticos:

```{r}
media <- svymean(~Diabetes, diseño)
print(media)
confint(media)
```
