<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>B Repaso de Proba | Estadística I: Análisis exploratorio de datos y muestreo</title>
  <meta name="description" content="Libro de estadística aplicada: temas de análisis exploratorio y muestreo" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="B Repaso de Proba | Estadística I: Análisis exploratorio de datos y muestreo" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Libro de estadística aplicada: temas de análisis exploratorio y muestreo" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="B Repaso de Proba | Estadística I: Análisis exploratorio de datos y muestreo" />
  
  <meta name="twitter:description" content="Libro de estadística aplicada: temas de análisis exploratorio y muestreo" />
  

<meta name="author" content="Rodrigo Zepeda-Tello" />


<meta name="date" content="2020-09-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="programación-en-r.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística I: Análisis exploratorio de datos y muestreo</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Historia y conceptos</a></li>
<li class="chapter" data-level="2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html"><i class="fa fa-check"></i><b>2</b> Análisis Exploratorio de Datos</a><ul>
<li class="chapter" data-level="2.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#inicio"><i class="fa fa-check"></i><b>2.1</b> Inicio</a></li>
<li class="chapter" data-level="2.2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#librerías"><i class="fa fa-check"></i><b>2.2</b> Librerías</a></li>
<li class="chapter" data-level="2.3" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#base-a-analizar"><i class="fa fa-check"></i><b>2.3</b> Base a analizar</a></li>
<li class="chapter" data-level="2.4" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#definiciones-y-notación"><i class="fa fa-check"></i><b>2.4</b> Definiciones y notación</a></li>
<li class="chapter" data-level="2.5" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#estadísticos-univariados"><i class="fa fa-check"></i><b>2.5</b> Estadísticos univariados</a><ul>
<li class="chapter" data-level="2.5.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#definición-estadístico"><i class="fa fa-check"></i><b>2.5.1</b> Definición [Estadístico]</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio"><i class="fa fa-check"></i><b>2.6</b> Ejercicio</a></li>
<li class="chapter" data-level="2.7" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicios"><i class="fa fa-check"></i><b>2.7</b> Ejercicios</a></li>
<li class="chapter" data-level="2.8" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#gráficas-univariadas"><i class="fa fa-check"></i><b>2.8</b> Gráficas univariadas</a></li>
<li class="chapter" data-level="2.9" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#gráficas-bivariadas"><i class="fa fa-check"></i><b>2.9</b> Gráficas bivariadas</a><ul>
<li class="chapter" data-level="2.9.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-1"><i class="fa fa-check"></i><b>2.9.1</b> Ejercicio</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#estadísticos-bivariados"><i class="fa fa-check"></i><b>2.10</b> Estadísticos bivariados</a><ul>
<li class="chapter" data-level="2.10.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-2"><i class="fa fa-check"></i><b>2.10.1</b> Ejercicio</a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-3"><i class="fa fa-check"></i><b>2.11</b> Ejercicio</a></li>
<li class="chapter" data-level="2.12" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ajuste-funcional"><i class="fa fa-check"></i><b>2.12</b> Ajuste funcional</a><ul>
<li class="chapter" data-level="2.12.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-4"><i class="fa fa-check"></i><b>2.12.1</b> Ejercicio</a></li>
<li class="chapter" data-level="2.12.2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-sugerido"><i class="fa fa-check"></i><b>2.12.2</b> Ejercicio sugerido</a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicios-del-capítulo"><i class="fa fa-check"></i><b>2.13</b> Ejercicios del capítulo</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html"><i class="fa fa-check"></i><b>3</b> Muestreo Aleatorio Simple</a><ul>
<li class="chapter" data-level="3.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#inicio"><i class="fa fa-check"></i><b>3.1</b> Inicio</a></li>
<li class="chapter" data-level="3.2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#librerías"><i class="fa fa-check"></i><b>3.2</b> Librerías</a></li>
<li class="chapter" data-level="3.3" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#notación"><i class="fa fa-check"></i><b>3.3</b> Notación</a><ul>
<li class="chapter" data-level="3.3.1" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#ejemplo"><i class="fa fa-check"></i><b>3.3.1</b> Ejemplo</a></li>
<li class="chapter" data-level="3.3.2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio"><i class="fa fa-check"></i><b>3.3.2</b> Ejercicio</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#muestreo-aleatorio-simple-sin-reemplazo-massr"><i class="fa fa-check"></i><b>3.4</b> Muestreo Aleatorio Simple sin Reemplazo (MAS/sR)</a><ul>
<li class="chapter" data-level="3.4.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-1"><i class="fa fa-check"></i><b>3.4.1</b> Ejercicio</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#teorema-del-límite-central-aplicación"><i class="fa fa-check"></i><b>3.5</b> Teorema del Límite Central (Aplicación)</a><ul>
<li class="chapter" data-level="3.5.1" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#estimación-de-intervalos-de-confianza-para-el-total"><i class="fa fa-check"></i><b>3.5.1</b> Estimación de intervalos de confianza para el total</a></li>
<li class="chapter" data-level="3.5.2" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#ejemplo-con-simulación"><i class="fa fa-check"></i><b>3.5.2</b> Ejemplo con simulación:</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#ejemplo-resumen-estimación-de-una-proporción-bajo-muestreo-aleatorio-simple-sin-reemplazo"><i class="fa fa-check"></i><b>3.6</b> Ejemplo Resumen: Estimación de una proporción bajo muestreo aleatorio simple sin reemplazo</a></li>
<li class="chapter" data-level="3.7" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#ejemplo-resumen-estimación-del-total-de-individuos-en-una-fotografía"><i class="fa fa-check"></i><b>3.7</b> Ejemplo Resumen: Estimación del total de individuos en una fotografía</a></li>
<li class="chapter" data-level="3.8" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-2"><i class="fa fa-check"></i><b>3.8</b> Ejercicio:</a></li>
<li class="chapter" data-level="3.9" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#ejemplo-resumen-estimación-de-una-región-crítica"><i class="fa fa-check"></i><b>3.9</b> Ejemplo Resumen: Estimación de una región crítica</a></li>
<li class="chapter" data-level="3.10" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#ejemplo-resumen-estimación-del-total-de-una-población"><i class="fa fa-check"></i><b>3.10</b> Ejemplo Resumen: Estimación del total de una población</a></li>
<li class="chapter" data-level="3.11" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#demostración-del-teorema-del-límite-central-para-muestras-finitas"><i class="fa fa-check"></i><b>3.11</b> Demostración del Teorema del Límite Central para Muestras Finitas</a></li>
<li class="chapter" data-level="3.12" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#muestreo-aleatorio-simple-bernoulli-be"><i class="fa fa-check"></i><b>3.12</b> Muestreo Aleatorio Simple Bernoulli (BE)</a><ul>
<li class="chapter" data-level="3.12.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-3"><i class="fa fa-check"></i><b>3.12.1</b> Ejercicio</a></li>
<li class="chapter" data-level="3.12.2" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#ejemplo-1"><i class="fa fa-check"></i><b>3.12.2</b> Ejemplo</a></li>
<li class="chapter" data-level="3.12.3" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#un-mejor-estimador-el-proporcional-al-tamaño"><i class="fa fa-check"></i><b>3.12.3</b> Un mejor estimador: el proporcional al tamaño</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#ejemplo-resumen-aduana"><i class="fa fa-check"></i><b>3.13</b> Ejemplo Resumen: Aduana</a></li>
<li class="chapter" data-level="3.14" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#muestreo-aleatorio-simple-con-reemplazo-mascr"><i class="fa fa-check"></i><b>3.14</b> Muestreo Aleatorio Simple con Reemplazo (MAS/cR)</a></li>
<li class="chapter" data-level="3.15" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#ejemplo-resumen-proporción-de-trabajadores-enfermos-con-o-sin-reemplazo"><i class="fa fa-check"></i><b>3.15</b> Ejemplo Resumen: Proporción de trabajadores enfermos con o sin reemplazo</a></li>
<li class="chapter" data-level="3.16" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#ejemplo-resumen-captura-recaptura-con-reemplazo"><i class="fa fa-check"></i><b>3.16</b> Ejemplo Resumen: Captura-Recaptura con reemplazo</a></li>
<li class="chapter" data-level="3.17" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html#muestreo-aleatorio-simple-ponderado-masp"><i class="fa fa-check"></i><b>3.17</b> Muestreo Aleatorio Simple Ponderado (MAS/P)</a></li>
<li class="chapter" data-level="3.18" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicios"><i class="fa fa-check"></i><b>3.18</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="appendix"><span><b>Apéndice</b></span></li>
<li class="chapter" data-level="A" data-path="programación-en-r.html"><a href="programación-en-r.html"><i class="fa fa-check"></i><b>A</b> Programación en <code>R</code></a><ul>
<li class="chapter" data-level="A.1" data-path="programación-en-r.html"><a href="programación-en-r.html#algunas-ventajas-de-r-y-cosas-no-tan-padres"><i class="fa fa-check"></i><b>A.1</b> Algunas ventajas de <code>R</code> y cosas no tan padres</a><ul>
<li class="chapter" data-level="A.1.1" data-path="programación-en-r.html"><a href="programación-en-r.html#puntos-a-favor-de-r"><i class="fa fa-check"></i><b>A.1.1</b> Puntos a favor de <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="programación-en-r.html"><a href="programación-en-r.html#bienvenidx-a-r-taking-off-again-sí-así-se-llama-esta-versión"><i class="fa fa-check"></i><b>A.2</b> Bienvenidx a <code>R</code>, Taking Off Again (sí, así se llama esta versión)</a></li>
<li class="chapter" data-level="A.3" data-path="programación-en-r.html"><a href="programación-en-r.html#instalando-cosas"><i class="fa fa-check"></i><b>A.3</b> Instalando cosas</a><ul>
<li class="chapter" data-level="A.3.1" data-path="programación-en-r.html"><a href="programación-en-r.html#instalación-de-r"><i class="fa fa-check"></i><b>A.3.1</b> Instalación de <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="programación-en-r.html"><a href="programación-en-r.html#instalación-de-rstudio"><i class="fa fa-check"></i><b>A.4</b> Instalación de <code>RStudio</code></a></li>
<li class="chapter" data-level="A.5" data-path="programación-en-r.html"><a href="programación-en-r.html#primeros-pasos-en-r-usando-rstudio"><i class="fa fa-check"></i><b>A.5</b> Primeros pasos en <code>R</code> usando <code>RStudio</code></a></li>
<li class="chapter" data-level="A.6" data-path="programación-en-r.html"><a href="programación-en-r.html#cálculos-numéricos"><i class="fa fa-check"></i><b>A.6</b> Cálculos numéricos</a><ul>
<li class="chapter" data-level="A.6.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio"><i class="fa fa-check"></i><b>A.6.1</b> Ejercicio</a></li>
<li class="chapter" data-level="A.6.2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-1"><i class="fa fa-check"></i><b>A.6.2</b> Ejercicio</a></li>
<li class="chapter" data-level="A.6.3" data-path="programación-en-r.html"><a href="programación-en-r.html#respuestas"><i class="fa fa-check"></i><b>A.6.3</b> Respuestas</a></li>
</ul></li>
<li class="chapter" data-level="A.7" data-path="programación-en-r.html"><a href="programación-en-r.html#variables"><i class="fa fa-check"></i><b>A.7</b> Variables</a><ul>
<li class="chapter" data-level="A.7.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicios"><i class="fa fa-check"></i><b>A.7.1</b> Ejercicios</a></li>
<li class="chapter" data-level="A.7.2" data-path="programación-en-r.html"><a href="programación-en-r.html#nivel-3"><i class="fa fa-check"></i><b>A.7.2</b> NIVEL 3</a></li>
</ul></li>
<li class="chapter" data-level="A.8" data-path="programación-en-r.html"><a href="programación-en-r.html#observaciones-sobre-la-aritmética-de-punto-flotante"><i class="fa fa-check"></i><b>A.8</b> Observaciones sobre la aritmética de punto flotante</a><ul>
<li class="chapter" data-level="A.8.1" data-path="programación-en-r.html"><a href="programación-en-r.html#cómo-checar-un-if"><i class="fa fa-check"></i><b>A.8.1</b> ¿Cómo checar un if?</a></li>
</ul></li>
<li class="chapter" data-level="A.9" data-path="programación-en-r.html"><a href="programación-en-r.html#leer-y-almacenar-variables-en-r"><i class="fa fa-check"></i><b>A.9</b> Leer y almacenar variables en <code>R</code></a><ul>
<li class="chapter" data-level="A.9.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-2"><i class="fa fa-check"></i><b>A.9.1</b> Ejercicio</a></li>
</ul></li>
<li class="chapter" data-level="A.10" data-path="programación-en-r.html"><a href="programación-en-r.html#instalación-de-paquetes"><i class="fa fa-check"></i><b>A.10</b> Instalación de paquetes</a><ul>
<li class="chapter" data-level="A.10.1" data-path="programación-en-r.html"><a href="programación-en-r.html#ejercicios-1"><i class="fa fa-check"></i><b>A.10.1</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="A.11" data-path="programación-en-r.html"><a href="programación-en-r.html#comentarios-adicionales-sobre-el-formato"><i class="fa fa-check"></i><b>A.11</b> Comentarios adicionales sobre el formato</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html"><i class="fa fa-check"></i><b>B</b> Repaso de Proba</a><ul>
<li class="chapter" data-level="B.1" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#funciones-indicadoras"><i class="fa fa-check"></i><b>B.1</b> Funciones indicadoras</a></li>
<li class="chapter" data-level="B.2" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#conteo"><i class="fa fa-check"></i><b>B.2</b> Conteo</a></li>
<li class="chapter" data-level="B.3" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#espacios-de-probabilidad"><i class="fa fa-check"></i><b>B.3</b> Espacios de probabilidad</a></li>
<li class="chapter" data-level="B.4" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#probabilidad-condicional"><i class="fa fa-check"></i><b>B.4</b> Probabilidad condicional</a></li>
<li class="chapter" data-level="B.5" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#independencia"><i class="fa fa-check"></i><b>B.5</b> Independencia</a></li>
<li class="chapter" data-level="B.6" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#variables-aleatorias-y-función-de-distribución-acumulada"><i class="fa fa-check"></i><b>B.6</b> Variables aleatorias y función de distribución (acumulada)</a></li>
<li class="chapter" data-level="B.7" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#funciones-de-masa-de-probabilidad"><i class="fa fa-check"></i><b>B.7</b> Funciones de masa de probabilidad</a></li>
<li class="chapter" data-level="B.8" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#funciones-de-densidad"><i class="fa fa-check"></i><b>B.8</b> Funciones de densidad</a></li>
<li class="chapter" data-level="B.9" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#teorema-de-cambio-de-variable-unidimensional"><i class="fa fa-check"></i><b>B.9</b> Teorema de cambio de variable unidimensional</a></li>
<li class="chapter" data-level="B.10" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#probabilidad-multivariada"><i class="fa fa-check"></i><b>B.10</b> Probabilidad Multivariada</a></li>
<li class="chapter" data-level="B.11" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#esperanza-varianza-y-covarianza"><i class="fa fa-check"></i><b>B.11</b> Esperanza, varianza y covarianza</a><ul>
<li class="chapter" data-level="B.11.1" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#propiedades-de-valor-esperado-varianza-y-covarianza"><i class="fa fa-check"></i><b>B.11.1</b> Propiedades de valor esperado, varianza y covarianza</a></li>
</ul></li>
<li class="chapter" data-level="B.12" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#condicionamiento-por-otra-variable-aleatoria"><i class="fa fa-check"></i><b>B.12</b> Condicionamiento por otra variable aleatoria</a></li>
<li class="chapter" data-level="B.13" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#funciones-características"><i class="fa fa-check"></i><b>B.13</b> Funciones características</a></li>
<li class="chapter" data-level="B.14" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#convergencias"><i class="fa fa-check"></i><b>B.14</b> Convergencias</a><ul>
<li class="chapter" data-level="B.14.1" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#teorema-de-continuidad-de-lévy"><i class="fa fa-check"></i><b>B.14.1</b> Teorema de continuidad de Lévy</a></li>
</ul></li>
<li class="chapter" data-level="B.15" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#ley-de-los-grandes-números"><i class="fa fa-check"></i><b>B.15</b> Ley de los grandes números</a></li>
<li class="chapter" data-level="B.16" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#teorema-del-límite-central"><i class="fa fa-check"></i><b>B.16</b> Teorema del límite central</a><ul>
<li class="chapter" data-level="B.16.1" data-path="repaso-de-proba.html"><a href="repaso-de-proba.html#programación-en-r-del-teorema-del-límite-central-con-variables-aleatorias-independientes-idénticamente-distribuidas"><i class="fa fa-check"></i><b>B.16.1</b> Programación en <code>R</code> del teorema del límite central con variables aleatorias independientes idénticamente distribuidas</a></li>
<li class="chapter" data-level="B.16.2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-3"><i class="fa fa-check"></i><b>B.16.2</b> Ejercicio</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Rodrigo Zepeda Tello</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística I: Análisis exploratorio de datos y muestreo</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="repaso-de-proba" class="section level1">
<h1><span class="header-section-number">B</span> Repaso de Proba</h1>
<div id="funciones-indicadoras" class="section level2">
<h2><span class="header-section-number">B.1</span> Funciones indicadoras</h2>
<p>Dado un conjunto <span class="math inline">\(A\)</span> definimos la función indicadora de <span class="math inline">\(A\)</span> como sigue:
<span class="math display">\[
\mathbb{I}_A (x)= \begin{cases}
1 &amp; \text{ si } x \in A \\
0 &amp; \text{ si } x \not\in A
\end{cases}
\]</span></p>
<p>La función indicadora cumple las siguientes propiedades:</p>
<p>Sean <span class="math inline">\(A,B\)</span> conjuntos; luego:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\mathbb{I}_{A \cap B}(x) = \mathbb{I}_{A}(x) \cdot \mathbb{I}_{B}(x)\)</span></p></li>
<li><p><span class="math inline">\(\mathbb{I}_{A \cup B}(x) = \mathbb{I}_{A}(x) + \mathbb{I}_{B}(x) - \mathbb{I}_{A}(x) \cdot \mathbb{I}_{B}(x)\)</span></p></li>
<li><p><span class="math inline">\(\mathbb{E}_X[\mathbb{I}_A(X)] = \mathbb{P}(X\in A)\)</span></p></li>
</ol>
<p><em>Demostración</em>:
1. Si <span class="math inline">\(x\in A \cap B\)</span> pasa que <span class="math inline">\(\mathbb{I}_{A \cap B}(x) = 1\)</span>; además, por hipótesis <span class="math inline">\(x\in A\)</span> y <span class="math inline">\(x \in B\)</span> lo que implica que <span class="math inline">\(\mathbb{I}_{A}(x) = 1\)</span> y <span class="math inline">\(\mathbb{I}_{B}(x) = 1\)</span>; en caso contrario <span class="math inline">\(\mathbb{I}_{A \cap B}(x) = 1\)</span> y como no está en el conjunto al menos uno <span class="math inline">\(\mathbb{I}_{A}(x)\)</span> ó <span class="math inline">\(\mathbb{I}_{B}(x)\)</span> es cero. Esto concluye la prueba.
2. Demostración es similar
3. Para cualquier variable aleatoria <span class="math inline">\(X\)</span>, <span class="math inline">\(\mathbb{I}_{A}(X)\)</span> sólo toma dos valores: <span class="math inline">\(0\)</span> si <span class="math inline">\(X\not\in A\)</span> y <span class="math inline">\(1\)</span> si <span class="math inline">\(X\in A\)</span>. Luego:</p>
<p><span class="math display">\[
\mathbb{E}_X[\mathbb{I}_A(X)] = 1 \cdot \mathbb{P}(X\in A) + 0 \cdot \mathbb{P}(X\not\in A) = \mathbb{P}(X\in A) 
\]</span></p>
</div>
<div id="conteo" class="section level2">
<h2><span class="header-section-number">B.2</span> Conteo</h2>
<p>Intentemos resumir todas las formas de contar que tenemos con un ejemplo de <span class="citation">Casella and Berger (<a href="#ref-casella2002statistical" role="doc-biblioref">2002</a>)</span>.</p>
<blockquote>
<p>En la lotería de Nueva York se eligen <span class="math inline">\(6\)</span> de <span class="math inline">\(44\)</span> números para un ticket. ¿Cuántos boletos de lotería posibles hay?</p>
</blockquote>
<p>Veamos algunas formas posibles de solución<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a>:</p>
<ol style="list-style-type: lower-alpha">
<li><p><strong>Ordenado y sin reemplazo</strong> Si sólo importa el orden y una vez que sale un número no se vuelve a meter a los posibles entonces tenemos:
<span class="math display">\[
\frac{44!}{(44-6)!}
\]</span></p></li>
<li><p><strong>Ordenado y con reemplazo</strong> En cada uno de los <span class="math inline">\(6\)</span> lugares hay <span class="math inline">\(44\)</span> números posibles:
<span class="math display">\[
44^6
\]</span></p></li>
<li><p><strong>Sin orden y sin reemplazo</strong> Esto es una combinación por lo que la forma de extraerlo es:
<span class="math display">\[
\binom{44}{6}
\]</span></p></li>
<li><p><strong>Sin orden y con reemplazo</strong> Para resolver este caso podemos usar la técnica de las barras y los puntos. Coloquemos barras y los huecos entre ellas representan cada uno de los <span class="math inline">\(44\)</span> números.
<span class="math display">\[\begin{equation}\nonumber
|\underbrace{\_}_{1}|\underbrace{\_}_{2}|\underbrace{\_}_{3}|\cdots |\underbrace{\_}_{n}|
\end{equation}\]</span>
Coloquemos puntos (<span class="math inline">\(\circ\)</span>) donde estén los números seleccionados. Por ejemplo la siguiente representa la combinación <span class="math inline">\(113555\)</span>
<span class="math display">\[\begin{equation}\nonumber
|\underbrace{\circ \circ}_{1}|\underbrace{\_}_{2}|\underbrace{\circ}_{3}||\underbrace{\_}_{4}|\underbrace{\circ \circ \circ}_{5}|\cdots |\underbrace{\_}_{n}|
\end{equation}\]</span>
Tenemos entonces que el problema se reduce a colocar <span class="math inline">\(n - 1= 43\)</span> barritas (son un total de <span class="math inline">\(45\)</span> pero la primera y la última no deben cambiar de lugar) y <span class="math inline">\(k = 6\)</span> círculos por tanto colocamos <span class="math inline">\(49\)</span> elementos en total. De estos, nos interesa poner <span class="math inline">\(6\)</span> por lo que tenemos:
<span class="math display">\[
\binom{44 + 6  - 1}{6}
\]</span>
formas distintas. Esto nos lleva a la tabla siguiente:</p></li>
</ol>
<p>Para obtener una muestra de tamaño <span class="math inline">\(k\)</span> a partir de un conjunto de tamaño <span class="math inline">\(n &gt; 0\)</span> éstas son las opciones:</p>
<table>
<tr>
<td>
</td>
<td>
</td>
<td>
<span class="math inline">\(\quad \text{Con Reemplazo}\)</span>
</td>
<td>
</td>
<td>
<span class="math inline">\(\quad \text{Sin Reemplazo}\)</span>
</td>
</tr>
<tr>
<td>
<span class="math inline">\(\quad \text{Con Orden}\)</span>
</td>
<td>
</td>
<td>
<span class="math inline">\(\quad n^k\)</span>
</td>
<td>
</td>
<td>
<span class="math inline">\(\quad (n)_k\)</span>
</td>
</tr>
<tr>
<td>
<span class="math inline">\(\quad \text{Sin Orden}\)</span>
</td>
<td>
</td>
<td>
<span class="math inline">\(\quad \binom{n+k-1}{k}\)</span>
</td>
<td>
</td>
<td>
<span class="math inline">\(\quad \binom{n}{k}\)</span>
</td>
</tr>
</table>
</div>
<div id="espacios-de-probabilidad" class="section level2">
<h2><span class="header-section-number">B.3</span> Espacios de probabilidad</h2>
<p>Los ingredientes para un modelo probabilístico son <span class="math inline">\(3\)</span>:</p>
<ol style="list-style-type: decimal">
<li><p>Un conjunto <span class="math inline">\(\Omega\)</span> conocido como <strong>espacio muestral</strong> el cual es el conjunto de los resultados de interés. Por ejemplo, en el tiro de un dado <span class="math inline">\(\Omega = \{1,2,3,4,5,6\}\)</span>, para el lanzamiento de una moneda <span class="math inline">\(\Omega = \{\text{Águila},\text{Sol}\}\)</span> o bien en seleccionar un número uniforme entre <span class="math inline">\(0\)</span> y <span class="math inline">\(1\)</span> tenemos que <span class="math inline">\(\Omega = [0,1]\)</span>.</p></li>
<li><p>Una colección <span class="math inline">\(\mathcal{F}\)</span> de subconjuntos de <span class="math inline">\(\Omega\)</span> conocida como <strong>sigma-álgebra</strong> o bien como <strong>espacio de eventos</strong> la cual cumple las siguientes características:</p></li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\Omega \in \mathcal{F}\)</span></li>
<li>Si <span class="math inline">\(A\in\mathcal{F}\)</span> entonces <span class="math inline">\(A^C \in \mathcal{F}\)</span></li>
<li>Si <span class="math inline">\(A_1, A_2, \dots\)</span> es una colección finita ó numerable de elementos de <span class="math inline">\(\mathcal{F}\)</span> entonces <span class="math inline">\(\bigcup_{n} A_n \in \mathcal{F}\)</span></li>
</ol>
<p>Generalmente identificamos a la <span class="math inline">\(\mathcal{F}\)</span> con el potencia para conjuntos <span class="math inline">\(\Omega\)</span> finitos; para casos infinitos el teorema de Vitali nos dice que las cosas son más complicadas.</p>
<ol start="3" style="list-style-type: decimal">
<li>Una función <span class="math inline">\(\mathbb{P}:\mathcal{F} \to [0,1]\)</span> que cumple que:</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\mathbb{P}(\Omega) = 1\)</span>.</li>
<li><span class="math inline">\(\mathbb{P}(A) \geq 0\)</span> para todo <span class="math inline">\(A \in \mathcal{F}\)</span>.</li>
<li>Si <span class="math inline">\(A_1, A_2, \dots\)</span> es una colección finita ó numerable de conjuntos disjuntos (<span class="math inline">\(A_i\cap A_j = \emptyset\)</span> para <span class="math inline">\(i \neq j\)</span>) entonces <span class="math inline">\(\mathbb{P}(\bigcup_{n} A_n) = \sum\limits_{n}\mathbb{P}(A_n)\)</span>.</li>
</ol>
<p>Estos últimos tres puntos se conocen como <strong>Axiomas de Kolmogorov</strong>. Una vez armados con los axiomas podíamos empezar a probar cosas con ellos; por ejemplo:</p>
<p>Sea <span class="math inline">\((\Omega,\mathcal{F},\mathbb{P})\)</span> un espacio de probabilidad. Sea <span class="math inline">\(A\)</span> evento de <span class="math inline">\(\mathcal{F}\)</span>. Luego:
<span class="math display">\[
\mathbb{P}(A^C) = 1 - \mathbb{P}(A).
\]</span></p>
<p>Para verlo, podemos escribir <span class="math inline">\(\Omega = A\cup A^C\)</span> de donde se sigue que:
<span class="math display">\[
1 = \mathbb{P}(\Omega) = \mathbb{P}(A \cup A^C) = \mathbb{P}(A) + \mathbb{P}(A^C);
\]</span>
si despejamos obtenemos el resultado deseado.</p>
<p>También podemos probar, por ejemplo:
<span class="math display">\[
\mathbb{P}(A\setminus B) = \mathbb{P}(A) - \mathbb{P}(A \cap B)
\]</span></p>
<p>si escribimos <span class="math inline">\(A = (A\setminus B) \cup (A \cap B)\)</span> de donde se sigue que:
<span class="math display">\[
\mathbb{P}(A) = \mathbb{P}\big((A\setminus B) \cup (A \cap B) \big) =  \mathbb{P}(A\setminus B) + \mathbb{P} (A \cap B)
\]</span>
y despejamos para tener el resultado deseado.</p>
<p>Una última cosa de importancia es tomar <span class="math inline">\(A,B\)</span> eventos de <span class="math inline">\(\mathcal{F}\)</span>. Luego:
<span class="math display">\[
\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A \cap B)
\]</span></p>
<p>Para verlo, escribimos <span class="math inline">\(A\cup B\)</span> como <span class="math inline">\(A\cup B = (A\setminus B)\cup (A \cap B)\cup (B\setminus A)\)</span> luego:
<span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
\mathbb{P}(A\cup B) &amp; = \mathbb{P}(A\setminus B) + \mathbb{P} (A \cap B) + \mathbb{P}(B\setminus A) \\
&amp; = \mathbb{P}(A) - \mathbb{P}(A \cap B) + \mathbb{P} (A \cap B) + \mathbb{P}(B) - \mathbb{P}(A \cap B)
\\ &amp; = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A \cap B)
\end{aligned}
\end{equation}\]</span></p>
</div>
<div id="probabilidad-condicional" class="section level2">
<h2><span class="header-section-number">B.4</span> Probabilidad condicional</h2>
<p>Muchas veces la probabilidad cambia conforme obtenemos información extra. Por ejemplo, si consideramos los tiros de un dado <span class="math inline">\(\Omega = \{1,2,3,4,5,6\}\)</span> y se sabe que cayó par <span class="math inline">\(B = \{2,4,6 \}\)</span>, la probabilidad de obtener <span class="math inline">\(2\)</span> ó <span class="math inline">\(4\)</span> (el evento) <span class="math inline">\(A = \{ 2, 4\}\)</span> cambia de probabilidad:
<span class="math display">\[
\mathbb{P}(A | B) = \dfrac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}
\]</span></p>
<p>En particular hay dos teoremas principales con probabilidad condicional: la ley de probabilidad total que te permite reconstruirlas probabilidades originales a partir de las condicionales y el de Bayes.</p>
<p>El teorema de Bayes puede deducirse a partir de un simple despeje pues notamos que:
<span class="math display">\[
\mathbb{P}(A | B) = \dfrac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}
\]</span>
y por otro lado:
<span class="math display">\[
\mathbb{P}(B | A) = \dfrac{\mathbb{P}(A \cap B)}{\mathbb{P}(A)}
\]</span>
Si despejamos del segundo, obtenemos:
<span class="math display">\[
\mathbb{P}(B | A)\mathbb{P}(A) = \mathbb{P}(A \cap B)
\]</span>
Podemos sustituir la definición de intersección en <span class="math inline">\(\mathbb{P}(A|B)\)</span> y así obtener:
<span class="math display">\[
\mathbb{P}(A | B) = \dfrac{\mathbb{P}(B | A)\mathbb{P}(A)}{\mathbb{P}(B)}
\]</span></p>
<p>Por otro lado, dada una partición <span class="math inline">\(B_1, B_2, \dots\)</span> finita o numerable de <span class="math inline">\(\Omega\)</span> podemos definir la probabilidad de <span class="math inline">\(A\)</span> en términos de cada uno de los pedazos:</p>
<p><span class="math display">\[
\mathbb{P}(A) = \sum\limits_{k} \mathbb{P}(A | B_k) \cdot \mathbb{P}(B_k)
\]</span></p>
<p>Esta identidad se sigue de que:
<span class="math display">\[
\mathbb{P}(A | B_k) = \dfrac{\mathbb{P}(A \cap B_k)}{\mathbb{P}(B_k)}
\]</span></p>
<p>de donde podemos sustituir arriba y obtener:
<span class="math display">\[
\mathbb{P}(A) = \sum\limits_{k} \dfrac{\mathbb{P}(A \cap B_k)}{\mathbb{P}(B_k)} \cdot \mathbb{P}(B_k) = \sum\limits_{k} \mathbb{P}(A \cap B_k) =  \mathbb{P}\big(A \cap (\bigcup_k B_k) \big) =  \mathbb{P}\big(A \cap \Omega \big) 
\]</span></p>
<p>Tenemos entonces el teorema siguiente:</p>
<p>Sean $B_1, B_2, $ eventos que forman una partición de <span class="math inline">\(\Omega\)</span>; sea <span class="math inline">\(A\)</span> un evento cualquiera; luego:
<span class="math display">\[
\mathbb{P}(A) = \sum\limits_{k} \mathbb{P}(A | B_k) \cdot \mathbb{P}(B_k)
\]</span></p>
<p>Usando probabilidad condicional podemos resolver problemas como el siguiente:</p>
<blockquote>
<p>Considera el conjunto <span class="math inline">\(C = \{1,2,\dots, n\}\)</span> para <span class="math inline">\(n \geq 2\)</span>. Se extraen dos números <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> (primero el <span class="math inline">\(a\)</span> y luego el <span class="math inline">\(b\)</span>) con probabilidad uniforme sin reemplazo. Determina la probabilidad de que <span class="math inline">\(a &gt; b\)</span>.
Podemos utilizar probabilidad condicional para representar el evento:
<span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
\mathbb{P}(a &gt; b) &amp;  = \sum\limits_{k = 1}^{n} \mathbb{P}(a &gt; b \quad |  \quad  a = k) \mathbb{P}(a = k)
\end{aligned}
\end{equation}\]</span>
Donde <span class="math inline">\(\mathbb{P}(a = k) = \frac{1}{n}\)</span> para todos los <span class="math inline">\(k\)</span> pues es uniforme (y es el primero en salir). Luego:
<span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
\mathbb{P}(a &gt; b) &amp;  = \sum\limits_{k = 1}^{n} \mathbb{P}(a &gt; b \quad |  \quad  a = k) \mathbb{P}(a = k) \\
&amp; = \dfrac{1}{n} \sum\limits_{k = 1}^{n} \mathbb{P}(a &gt; b \quad |  \quad  a = k) \\
&amp; = \dfrac{1}{n} \sum\limits_{k = 1}^{n} \mathbb{P}(k &gt; b \quad |  \quad  a = k) \\
\end{aligned}
\end{equation}\]</span>
Notamos que cuando <span class="math inline">\(k = 1\)</span> no hay forma de que <span class="math inline">\(k &gt; b\)</span>; cuando <span class="math inline">\(k = 2\)</span> hay una única forma (que <span class="math inline">\(b\)</span> valga <span class="math inline">\(1\)</span>); cuando <span class="math inline">\(k = 3\)</span> hay dos formas. En general para una <span class="math inline">\(k\)</span> genérica hay <span class="math inline">\(k-1\)</span> formas de seleccionar un <span class="math inline">\(b\)</span> menor a <span class="math inline">\(k\)</span> luego:
<span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
\mathbb{P}(a &gt; b) &amp;  = \dfrac{1}{n} \sum\limits_{k = 1}^{n} \dfrac{k-1}{n}
\\ &amp; = \dfrac{1}{n^2} \sum\limits_{k = 1}^{n} k-1
\\ &amp; = \dfrac{1}{n^2} \sum\limits_{k = 0}^{n-1} k
\\ &amp; = \dfrac{1}{n^2} \dfrac{n(n-1)}{2}
\\ &amp; = \dfrac{n-1}{2n} 
\end{aligned}
\end{equation}\]</span></p>
</blockquote>
</div>
<div id="independencia" class="section level2">
<h2><span class="header-section-number">B.5</span> Independencia</h2>
<p>Dos eventos <span class="math inline">\(A,B\)</span> son independientes si:
<span class="math display">\[
\mathbb{P}(A \cap B) = \mathbb{P}(A) \mathbb{P}(B)
\]</span></p>
<p>Intuitivamente esto significa que saber <span class="math inline">\(A\)</span> no me dice nada de <span class="math inline">\(B\)</span> pues la independencia implica que:
<span class="math display">\[
\mathbb{P}(A | B) = \mathbb{P}(A)
\]</span></p>
</div>
<div id="variables-aleatorias-y-función-de-distribución-acumulada" class="section level2">
<h2><span class="header-section-number">B.6</span> Variables aleatorias y función de distribución (acumulada)</h2>
<p>Para hablar de probabilidad uno de los ingredientes principales eran las variables aleatorias. Éstas son funciones (<strong>no son variables ni son aleatorias</strong>) de tal manera que su imagen inversa pertenece a la sigma-álgebra <span class="math inline">\(\mathcal{F}\)</span>:</p>
<p>Una función <span class="math inline">\(X: \Omega \to \mathbb{R}\)</span> es una variable aleatoria si:
<span class="math display">\[
X^{-1}(A) = \{ \omega \in \Omega \quad : \quad X(\omega) \in A \} \in \mathcal{F}
\]</span>
para todo <span class="math inline">\(A\subseteq\textrm{Dom}_X\)</span></p>
<p>En general la pregunta <span class="math inline">\(\mathbb{P}(X \in A)\)</span> la traducíamos a una pregunta sobre conjuntos:
<span class="math display">\[
\mathbb{P}(X \in A) = \mathbb{P}\Big( \{ \omega \in \Omega \quad : \quad X(\omega) \in A \} \Big)
\]</span></p>
<p>y esto nos permitía hablar de probabilidades. En particular, construíamos la función de distribución acumulada como sigue:</p>
<blockquote>
<p>Definimos la función de distribución acumulada de una variable aleatoria <span class="math inline">\(X: \Omega \to \mathbb{R}\)</span> como:
<span class="math display">\[
F_X(x) = \mathbb{P}(X \leq x)
\]</span>
donde <span class="math inline">\(X\)</span> es la variable aleatoria y <span class="math inline">\(x\in\mathbb{R}\)</span> es un real.</p>
</blockquote>
<p>La función de distribución acumulada cumplía varias propiedades:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\lim_{x \to \infty} F_X(x) = 1\)</span></li>
<li><span class="math inline">\(\lim_{x \to -\infty} F_X(x) = 0\)</span></li>
<li><span class="math inline">\(F_X\)</span> es no decreciente.</li>
<li><span class="math inline">\(F_X\)</span> es continua por la derecha.</li>
<li><span class="math inline">\(F_X\)</span> tiene límites por la izquierda.</li>
</ol>
<p>Los puntos 4 y 5 se resumen diciendo que la función es <em>càdlág</em>.</p>
<p>Tener la acumulada nos permitía calcular probabilidades de intervalos; por ejemplo:
<span class="math display">\[
\mathbb{P}(a &lt; X \leq b) = F_X(b) - F_X(a)
\]</span>
o bien:
<span class="math display">\[
\mathbb{P}(X &lt; x) = \lim_{z \to x^-} F(z)
\]</span></p>
<p>Las funciones de distribución acumulada más comunes se veían como en la imagen:</p>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-254-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Si una función de distribución acumulada <span class="math inline">\(F_X\)</span> era continua entonces decíamos que la variable aleatoria asociada (<span class="math inline">\(X\)</span>) es <em>continua</em>. En particular, la continuidad implica que:
<span class="math display">\[
\mathbb{P}(X = k) = 0 \qquad \forall k 
\]</span></p>
</div>
<div id="funciones-de-masa-de-probabilidad" class="section level2">
<h2><span class="header-section-number">B.7</span> Funciones de masa de probabilidad</h2>
<p>Si una variable aleatoria <span class="math inline">\(X\)</span> tomaba una cantidad finita o numerable de valores decíamos que <span class="math inline">\(X\)</span> es una variable aleatoria discreta. Dentro de las variables aleatorias discretas teníamos varios modelos. Una cosa importante de las variables aleatorias es la función de masa de probabilidad que se define como:</p>
<p>Dada una variable aleatoria discreta <span class="math inline">\(X\)</span> definimos la función de masa de probabilidad de <span class="math inline">\(X\)</span> como la función <span class="math inline">\(p:\mathbb{R} \to \mathbb{R}\)</span> tal que:
<span class="math display">\[
p(x) = \mathbb{P}(X = x)
\]</span>
para todo <span class="math inline">\(x \in\mathbb{R}\)</span>.</p>
<p>Algunos modelos importantes son:</p>
<p>Sea <span class="math inline">\(A = \{ a_1, a_2, \dots, a_n \}\)</span> un conjunto finito de <span class="math inline">\(n\)</span> elementos. Una variable aleatoria <span class="math inline">\(X\)</span> tiene una distribución uniforme discreta si:
<span class="math display">\[
\mathbb{P}\big( X = a_k \big) = \dfrac{1}{n} \cdot \mathbb{I}_{A}(a_k) \qquad \forall k \in \{ 1, 2, \dots, n \} 
\]</span></p>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-255-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Un modelo particular salía de considerar el siguiente problema:</p>
<blockquote>
<p>Tenemos una moneda que cae Águila con probabilidad <span class="math inline">\(p\)</span> y Sol con probabilidad <span class="math inline">\((1-p)\)</span> (con <span class="math inline">\(0 &lt; p &lt; 1\)</span>). Nos interesa saber cuál es la probabilidad de tener <span class="math inline">\(k\)</span> Águilas en <span class="math inline">\(n\)</span> tiros.
<em>Solución</em> A fin de resolver este problema notamos que necesitamos acomodar las <span class="math inline">\(k\)</span> águilas en los <span class="math inline">\(n\)</span> tiros para ello hay <span class="math inline">\(\binom{n}{k}\)</span> formas de hacerlo; cada águila cae con probabilidad <span class="math inline">\(p\)</span> y hay <span class="math inline">\(k\)</span>; como son independientes esto nos da <span class="math inline">\(p^k\)</span>; por otro lado hay <span class="math inline">\(n-k\)</span> soles cada uno cayó con probabilidad <span class="math inline">\((1-p)\)</span>. Esta lógica da origen al modelo binomial:</p>
</blockquote>
<p>Una variable aleatoria <span class="math inline">\(X\)</span> tiene una distribución <span class="math inline">\(\text{Binomial}(n,p)\)</span> si:
<span class="math display">\[
\mathbb{P}\big(X = k \big) = \binom{n}{k} p^k (1-p)^{n-k} \mathbb{I}_{\{0,1,2,\dots,n \}}(k)
\]</span></p>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-256-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Una pregunta distinta que nos pudimos hacer fue:</p>
<blockquote>
<p>Tenemos una moneda que cae Águila con probabilidad <span class="math inline">\(p\)</span> y Sol con probabilidad <span class="math inline">\((1-p)\)</span> (con <span class="math inline">\(0 &lt; p &lt; 1\)</span>). Arrojamos la moneda hasta obtener <span class="math inline">\(r\)</span> Águilas y en ese momento nos detenemos. Determina la probabilidad de que se aviente la moneda <span class="math inline">\(k\)</span> veces.</p>
</blockquote>
<p>Para ello notamos que la última Águila está fija por lo que sólo debemos poner las <span class="math inline">\(r-1\)</span> Águilas en los <span class="math inline">\(k-1\)</span> lugares restantes, <span class="math inline">\(\binom{k-1}{r-1}\)</span>. Por otro lado, cada Águila tiene probabilidad <span class="math inline">\(p\)</span> y como son <span class="math inline">\(k\)</span> tiros independientes entonces tenemos <span class="math inline">\(p^r\)</span>; para los soles tenemos <span class="math inline">\((1-p)^{k-r}\)</span>. Esto nos genera el modelo Binomial Negativo:</p>
<p>Una variable aleatoria <span class="math inline">\(X\)</span> tiene una distribución <span class="math inline">\(\text{Binomial Negativa}(r,p)\)</span> si:
<span class="math display">\[
\mathbb{P}\big(X = k \big) = \binom{k-1}{r-1} p^r (1-p)^{k-r} \mathbb{I}_{\{r, r+1, r+2, \dots \}}(k)
\]</span></p>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-257-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Finalmente, otro modelo que pudimos hacer con monedas es un caso específico del <em>Binomial Negativo</em> . Aquí la pregunta es, se tira una moneda que tiene probabilidad <span class="math inline">\(p\)</span> de salir Águila hasta que se obtiene el águila. Contamos cuántos tiros ocurrieron hasta que ocurriera el primer Águila y la pregunta de interés es la probabilidad de haber realizado específicamente <span class="math inline">\(k\)</span> tiros. Para ello necesitamos tener <span class="math inline">\((k-1)\)</span> tiros que fueran sol: <span class="math inline">\((1-p)^{k-1}\)</span> y un tiro que saliera águila <span class="math inline">\(p\)</span>. Esto nos genera el modelo geométrico:</p>
<p>Una variable aleatoria <span class="math inline">\(X\)</span> tiene una distribución <span class="math inline">\(\text{Geométrica}(p)\)</span> si:
<span class="math display">\[
\mathbb{P}\big(X = k \big) = (1-p)^k p \cdot \mathbb{I}_{\mathbb{N}}(k).
\]</span></p>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-258-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Otro modelo de interés es el siguiente:</p>
<blockquote>
<p>Se tiene una población de tamaño <span class="math inline">\(M\)</span> donde <span class="math inline">\(N\)</span> individuos pertenecen al partido político AZUL y <span class="math inline">\(M-N\)</span> pertenecen al VERDE Se toma una submuestra de tamaño <span class="math inline">\(m\)</span>. Determina la probabilidad de que haya <span class="math inline">\(n\)</span> individuos del partido político AZUL.</p>
</blockquote>
<p>Para ello notamos que hay <span class="math inline">\(\binom{M}{m}\)</span> muestras totales. Por otro lado, necesitamos extraer de los <span class="math inline">\(N\)</span> azules a una submuestra de <span class="math inline">\(n\)</span>: <span class="math inline">\(\binom{N}{n}\)</span>; finalmente, de los <span class="math inline">\(M\)</span> verdes necesitamos extraer una submuestra de <span class="math inline">\(m\)</span>, hay <span class="math inline">\(\binom{M-N}{m-n}\)</span> formas de hacerlo. Concluimos entonces con el modelo hipergeométrico:</p>
<p>Una variable aleatoria <span class="math inline">\(X\)</span> tiene una distribución <span class="math inline">\(\text{Hipergeométrica}(M,N,m)\)</span> si:
<span class="math display">\[
\mathbb{P}\big(X = n \big) = \dfrac{\binom{M-N}{m-n} \binom{N}{n} }{\binom{M}{m}} \cdot \mathbb{I}_{\{0,1,\dots, \text{mín}\{m, N\} \}} (n)
\]</span></p>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-259-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>El modelo Poisson va a ser bastante útil. Para estudiarlo, consideremos un modelo. Vamos a pensar en un servidor de computación (piensa en una página de Internet) que recibe solicitudes de entrar a la página de manera independiente y aleatoria en un intervalo de tiempo entre <span class="math inline">\(t = 0\)</span> y <span class="math inline">\(t = 1\)</span>. Como primera aproximación podemos dividir el intervalo en <span class="math inline">\(n\)</span> pedazos cada uno de longitud <span class="math inline">\(1/n\)</span> y asumir que, a fuerza, sólo una conexión se puede realizar en cada uno de esos pedazos. Finalmente, asumamos que la probabilidad <span class="math inline">\(p\)</span> de que se haga una conexión es proporcional a la longitud del intervalo y sea <span class="math inline">\(p = \lambda / n\)</span>. Con estas hipótesis, la probabilidad de tener <span class="math inline">\(k\)</span> conexiones (<span class="math inline">\(k\)</span> entero entre <span class="math inline">\(0\)</span> y <span class="math inline">\(n\)</span>) está dada por un modelo binomial:
<span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
f_n(k) &amp; = \binom{n}{k} \Big( \frac{\lambda}{n} \Big)^k \Big(1 - \frac{\lambda}{n} \Big)^k \
&amp; = \frac{\lambda^k}{k!} \Big( 1 - \frac{\lambda}{n})^n \frac{n!}{n^k(n-k)!} \Big( 1 - \frac{\lambda}{n})^{-k}
\end{aligned}
\end{equation}\]</span>
de donde concluimos que si continuamos partiendo el intervalo en pedazos cada vez más pequeños obtenemos:
<span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
\lim_{n \to \infty} f_n(k) &amp; = \frac{e^{-\lambda} \lambda^k}{k!}
\end{aligned}
\end{equation}\]</span>
Esto resulta en el modelo Poisson:</p>
<p>Una variable aleatoria <span class="math inline">\(X\)</span> tiene una distribución <span class="math inline">\(\text{Poisson}(\lambda)\)</span> si:
<span class="math display">\[
\mathbb{P}\big(X = k \big) = \dfrac{\lambda^k e^{-\lambda}}{k!} \mathbb{I}_{\mathbb{N}\cup \{ 0 \}}(k)
\]</span></p>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-260-1.png" width="384" style="display: block; margin: auto;" /></p>
</div>
<div id="funciones-de-densidad" class="section level2">
<h2><span class="header-section-number">B.8</span> Funciones de densidad</h2>
<p>Por construcción, las variables aleatorias continuas no tienen una función de masa de probabilidad (recuerda que <span class="math inline">\(\mathbb{P}(X = k) = 0\)</span> si <span class="math inline">\(X\)</span> es continua para todo <span class="math inline">\(k\)</span>). Sin embargo, es posible definir, si <span class="math inline">\(F_X\)</span> es diferenciable algo <em>similar</em>, la función de densidad.</p>
<p>Para una variable aleatoria <span class="math inline">\(X\)</span> con función de distribución acumulada <span class="math inline">\(F_X\)</span> diferenciable, definimos la función de densidad como:
<span class="math display">\[
f_X(x) = \dfrac{d}{dx} F_X(x)
\]</span></p>
<p>Notamos que una función de densidad no es una probabilidad y no necesariamente sigue las mismas reglas; lo único que se requiere es:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(f_X(x) \geq 0\)</span> para toda <span class="math inline">\(x\)</span>.</li>
<li><span class="math inline">\(\int\limits_{-\infty}^{\infty} f_X(x) dx = 1\)</span>.</li>
</ol>
<p>La primer función de densidad es la que a un intervalo <span class="math inline">\([a,b]\)</span> (ya sea abierto, cerrado o como sea) asigna a cada subintervalo una probabilidad proporcional a su longitud. Éste es el modelo uniforme:</p>
<p>Una variable aleatoria <span class="math inline">\(X\)</span> tiene una distribución <span class="math inline">\(\text{Uniforme}(a,b)\)</span> si:
<span class="math display">\[
f_X(x) = \dfrac{1}{b-a}\mathbb{I}_{(a,b)}(x)
\]</span></p>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-261-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Una generalización del modelo uniforme es el beta (eventualmente veremos de dónde sale):</p>
<p>Una variable aleatoria <span class="math inline">\(X\)</span> tiene una distribución <span class="math inline">\(\text{Beta}(\alpha,\beta)\)</span> si:
<span class="math display">\[
f_X(x) = \dfrac{x^{\alpha - 1}(1-x)^{\beta - 1}}{B(\alpha, \beta)}\mathbb{I}_{(0,1)}(x)
\]</span>
donde
<span class="math display">\[
B(\alpha, \beta) = \dfrac{\Gamma (\alpha) \Gamma (\beta)}{\Gamma (\alpha + \beta)}
\]</span></p>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-262-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Podemos deducir el modelo exponencial a partir de la descripción del Poisson. Volvamos al mismo problema del <span class="math inline">\(\textrm{Poisson}(\lambda)\)</span> donde hay computadoras conectándose a un servidor. Sea <span class="math inline">\(W\)</span> la variable aleatoria que denota el tiempo de espera hasta el primer evento. Analicemos su distribución acumulada; notamos que
<span class="math display">\[
F_W(w) = \mathbb{P}(W \leq w) = 1 - \mathbb{P}(W &gt; w)
\]</span>
Ahora, para que <span class="math inline">\(W &gt; w\)</span> eso significa que ningún evento tuvo que haber ocurrido en los primeros <span class="math inline">\(w\)</span> minutos (horas, lo que sea la unidad de tiempo). Y ese evento es equivalente a que nuestra variable aleatoria Poisson (tasa <span class="math inline">\(\lambda w\)</span>)<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a> no tenga ningún arribo:
<span class="math display">\[
\mathbb{P}(X = 0) = \dfrac{(\lambda w)^0 e^{-\lambda w}}{0!} = e^{-\lambda}
\]</span>
De donde se obtiene la función de distribución acumulada:
<span class="math display">\[
F_W(w) = 1 - e^{-\lambda w}
\]</span>
De donde, al derivar respecto a <span class="math inline">\(w\)</span>, se obtiene el modelo exponencial:</p>
<p>Una variable aleatoria <span class="math inline">\(X\)</span> tiene una distribución <span class="math inline">\(\text{Exponencial}(\lambda)\)</span> si:
<span class="math display">\[
f_X(x) = \lambda e^{-\lambda x} \mathbb{I}_{(0,\infty)}(x)
\]</span></p>
<p>Para deducir la distribución gamma, vamos a preguntarnos por exactamente el mismo proceso pero esta vez, en lugar de preguntarnos por el tiempo para la primer conexión nos preguntaremos por el tiempo para la <span class="math inline">\(\alpha\)</span>-ésima conexión. Para ello, sea <span class="math inline">\(W_{\alpha}\)</span> el tiempo hasta la <span class="math inline">\(\alpha\)</span>-ésima conexión. Usamos el mismo truco del complemento que la vez pasada:
<span class="math display">\[
F_{W_{\alpha}}(w) = \mathbb{P}(W_{\alpha} \leq w) = 1 - \mathbb{P}(W_{\alpha} &gt; w)
\]</span>
Y notamos que para que <span class="math inline">\(W_{\alpha} &gt; w\)</span> entonces a lo más debieron haber <span class="math inline">\(\alpha-1\)</span> conexiones. Podemos reescribir:
<span class="math display">\[
F_{W_{\alpha}}(w) =  1 - \mathbb{P}(W_{\alpha} &gt; w) = 1 - \sum\limits_{k = 0}^{\alpha - 1} \dfrac{(\lambda w)^k e^{-\lambda w}}{k!} = 1 - e^{- \lambda w} - \sum\limits_{k = 1}^{\alpha - 1} \dfrac{(\lambda w)^k e^{-\lambda w}}{k!}
\]</span>
Derivamos:
<span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
\dfrac{d}{dw}F_{W_{\alpha}}(w) &amp; =  -\lambda e^{- \lambda w} - \sum\limits_{k = 1}^{\alpha - 1} \dfrac{k \lambda (\lambda w)^{k-1} e^{-\lambda w} - \lambda (\lambda w)^k e^{-\lambda w}}{k!} \
 &amp; =  -\lambda e^{- \lambda w} - \lambda e^{- \lambda w} \sum\limits_{k = 1}^{\alpha - 1} \underbrace{\dfrac{(\lambda w)^{k-1}}{(k-1)!}  - \dfrac{(\lambda w)^k }{k!}}_{\text{Telescópica}} \
 &amp; = -\lambda e^{- \lambda w} + \lambda e^{- \lambda w} \Bigg( \dfrac{(\lambda w)^{\alpha - 1} }{(\alpha - 1)!} - 1 \Bigg) \ 
 &amp; = \lambda e^{- \lambda w} \dfrac{(\lambda w)^{\alpha - 1} }{(\alpha - 1)!} \
 &amp; =  \dfrac{\beta^{\alpha} }{\Gamma (\alpha)} w^{\alpha - 1} e^{- \frac{w}{\beta}}  \
 \end{aligned}
\end{equation}\]</span>
donde tomamos <span class="math inline">\(\beta = \frac{1}{\lambda}\)</span>. Esto sugiere el modelo gamma:</p>
<p>Una variable aleatoria <span class="math inline">\(W\)</span> tiene una distribución <span class="math inline">\(\text{Gamma}(\alpha,\beta)\)</span> si:
<span class="math display">\[
f_W(w) =  \dfrac{\beta^{\alpha} }{\Gamma (\alpha)} w^{\alpha - 1} e^{- \frac{w}{\beta}} \mathbb{I}_{(0,\infty)}
\]</span>
para <span class="math inline">\(\alpha,\beta &gt; 0\)</span>.</p>
<p>Para deducir el modelo normal consideremos lo siguiente. Pensemos que estamos midiendo la posición de las estrellas en el cielo. Para ello hay dos formas. Bajo coordenadas cartesianas <span class="math inline">\((x,y)\)</span> pensemos que el error de medición es independiente; es decir, si <span class="math inline">\(f(x,y)\)</span> es la densidad de los errores entonces:</p>
<p><span class="math display">\[
\rho (x,y) = f(x) f(y) 
\]</span></p>
<p>Por otro lado, asumamos que existe también una representación en coordenadas polares de la posición de la estrella:
<span class="math display">\[
g (r, \theta)  = g(r) 
\]</span>
donde el error de medición depende sólo del radio (no del ángulo). Notamos entonces que:
<span class="math display">\[
f(x) f(y) = g\Big( \sqrt{x^2 + y^2} \Big) 
\]</span>
Si tomamos <span class="math inline">\(y = 0\)</span> tenemos que <span class="math inline">\(f(x) f(0) = g(x)\)</span> (asumo <span class="math inline">\(x &gt; 0\)</span>; los otros casos son similares). Podemos entonces sustituir:</p>
<p><span class="math display">\[
\dfrac{f(x) f(y)}{f(0)^2} = \dfrac{f\Big( \sqrt{x^2 + y^2} \Big) }{f(0)}
\]</span></p>
<p>Tomamos logaritmo:
<span class="math display">\[
\ln \dfrac{f(x)}{f(0)} + \ln \dfrac{f(y)}{f(0)}  = \ln \dfrac{f\Big( \sqrt{x^2 + y^2} \Big) }{f(0)}
\]</span>
Notamos que una solución es que:
<span class="math display">\[
\ln \dfrac{f(x)}{f(0)} = \alpha x^2
\]</span>
de donde despejamos y obtenemos:
<span class="math display">\[
f(x) = \frac{1}{f(0)} e^{\alpha x^2}
\]</span>
Finalmente sabemos que debe integrar a <span class="math inline">\(1\)</span> y por tanto esto fuerza a <span class="math inline">\(\alpha\)</span> a ser negativo. En particular tomaremos <span class="math inline">\(\alpha = -\frac{1}{2}\)</span>
<span class="math display">\[
f(x) = \frac{1}{f(0)} e^{-\frac{1}{2} x^2}
\]</span>
Y para que integre a <span class="math inline">\(1\)</span>:s
<span class="math display">\[
f(x) = \frac{1}{\sqrt{2 \pi}} e^{-\frac{1}{2} x^2}
\]</span></p>
<p>Por último, notamos que si <span class="math inline">\(Z\sim \textrm{Normal}(0,1)\)</span> entonces <span class="math inline">\(X = \sigma Z + \mu\)</span> tiene la densidad dada por<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a>:
<span class="math display">\[
f(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{1}{2\sigma^2} (x - \mu)^2}
\]</span></p>
<p>Una variable aleatoria <span class="math inline">\(X\)</span> tiene una distribución <span class="math inline">\(\text{Normal}(\mu,\sigma)\)</span> si:
<span class="math display">\[
f_X(x) =  \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(x - \mu)^2}{2 \sigma^2}} 
\]</span></p>
</div>
<div id="teorema-de-cambio-de-variable-unidimensional" class="section level2">
<h2><span class="header-section-number">B.9</span> Teorema de cambio de variable unidimensional</h2>
<p>Supongamos que tenemos una variable aleatoria <span class="math inline">\(X\)</span> y nos interesa ver cómo se ve la <span class="math inline">\(X\)</span> después de aplicarle una función <span class="math inline">\(\phi\)</span>. Por ejemplo, si <span class="math inline">\(X\sim\textrm{Normal}(0,1)\)</span> la función de densidad de <span class="math inline">\(e^X\)</span> está dada por:</p>
<p><span class="math display">\[
f_X(x) = \dfrac{1}{x \sqrt{2 \pi \sigma^2}}e^{-(\ln(x) - \mu)^2/2\sigma^2} \mathbb{I}_{(0,\infty)}(x).
\]</span></p>
<p>Lo cual cambia mucho la forma de la distribución:</p>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-263-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>La pregunta es, cómo obtener la función de densidad de <span class="math inline">\(X\)</span> si se conoce la función <span class="math inline">\(\phi\)</span>; el teorema de cambio de variable nos da una respuesta cuando <span class="math inline">\(\phi\)</span> es monótona estrictamente creciente o bien estrictamente decreciente y diferenciable.</p>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria continua y <span class="math inline">\(\phi\)</span> una función estrictamente creciente ó estrictamente decreciente y diferenciable. Entonces:
<span class="math display">\[
f_{\phi(X)}(t)  = f_X( \phi^{-1}(t) ) \cdot \left| \dfrac{d}{dt}  \phi^{-1}(t)  \right|
\]</span></p>
<p><strong>DEM: Caso estrictamente decreciente</strong>
Como <span class="math inline">\(\phi\)</span> es estrictamente decreciente es invertible y por tanto:
<span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
F_{\phi(X)}(t) &amp; =  \mathbb{P}(\phi(X) \leq t) \\
&amp; = \mathbb{P}(X \geq \phi^{-1}(t) ) \\
&amp; = 1 - \mathbb{P}(X \leq \phi^{-1}(t) ) \\
&amp; = 1 - F_X( \phi^{-1}(t) )
\end{aligned}
\end{equation}\]</span>
luego derivamos respecto a <span class="math inline">\(t\)</span>:
<span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
f_{\phi(X)}(t) &amp; = \dfrac{d}{dt} F_{\phi(X)}(t) \\
&amp; = - \dfrac{d}{dt} F_X( \phi^{-1}(t) )  \\
&amp; = - f_X( \phi^{-1}(t) ) \cdot \dfrac{d}{dt} \phi^{-1}(t)  \\
&amp; = f_X( \phi^{-1}(t) ) \cdot \left| \dfrac{d}{dt}  \phi^{-1}(t)  \right|
\end{aligned}
\end{equation}\]</span>
Donde el valor absoluto sale de que <span class="math inline">\(\phi^{-1}(t) &lt; 0\)</span> por ser estrictamente decreciente la <span class="math inline">\(\phi\)</span>.</p>
</div>
<div id="probabilidad-multivariada" class="section level2">
<h2><span class="header-section-number">B.10</span> Probabilidad Multivariada</h2>
<p>De la misma manera que hablamos de una sola variable aleatoria podemos hablar de muchas como múltiples funciones de <span class="math inline">\(\Omega \in \mathbb{R}\)</span>. Para una colección finita <span class="math inline">\(\{ X_i \}_{i = 1}^n\)</span> de variables aleatorias podemos hablar de su función de distribución acumulada conjunta como:
<span class="math display">\[
F_{\vec{X}}(x_1, x_2, \dots, x_n) = \mathbb{P}\big( X_1 \leq x_1, X_2 \leq x_2, \dots, X_n \leq x_n)
\]</span>
donde suponemos que <span class="math inline">\(\vec{X} = (X_1, X_2, \dots, X_n)^T\)</span> es un vector aleatorio cuyas entradas son las variables de la colección anterior. En el caso de que las <span class="math inline">\(n\)</span> variables sean discretas la función de masa conjunta está dada por:
<span class="math display">\[
p_{\vec{X}}(x_1, x_2, \dots, x_n) = \mathbb{P}(X_1 = x_1, X_2 = x_2, \dots, X_n = x_n)
\]</span>
En el caso de que sean continuas (<span class="math inline">\(F_{\vec{X}}\)</span> diferenciable en sus <span class="math inline">\(n\)</span> entradas) entonces la densidad está dada por:
<span class="math display">\[
f_{\vec{X}}(x_1, x_2, \dots, x_n) = \dfrac{\partial^n}{\partial x_1 \partial x_2 \dots \partial x_n}F_{\vec{X}}\Bigg|_{(x_1, x_2, \dots, x_n)}
\]</span>
En general la función de probabilidad conjunta siempre va a esta dada por:
<span class="math display">\[
\mathbb{P}(X_1 \in A_1, X_2 \in A_2, \dots, X_n \in A_n) = \mathbb{P}\Big(\{ \omega \in \Omega :  X_1(\omega) \in A_1 \text{ y } X_2(\omega) \in A_2  \text{ y } \dots \text{ y } X_n(\omega) \in A_n \}\Big)
\]</span></p>
<p>para <span class="math inline">\(A_1, A_2, \dots, A_n\)</span> medibles (bajo <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> respectivamente).</p>
<p>Dos variables aleatorias <span class="math inline">\(X_i\)</span> y <span class="math inline">\(X_j\)</span> (<span class="math inline">\(i \neq j\)</span>) son independientes si:
<span class="math display">\[
\mathbb{P}(X_i \in A, X_i \in B) = \mathbb{P}(X_i \in A) \cdot \mathbb{P}(X_j \in B)
\]</span>
para <span class="math inline">\(A,B\)</span> medibles. Una colección <span class="math inline">\(\{ X_i \}_{i}\)</span> de variables aleatorias es <strong>completamente independiente</strong> si para cualquier subcolección finita <span class="math inline">\(\{ X_{i_k} \}_{i_k}\)</span> se tiene que:
<span class="math display">\[
\mathbb{P}(X_{i_1} \in A_{i_1}, X_{i_2} \in A_{i_2}, \dots, X_{i_n} \in A_{i_n} ) = \prod_{k = 1}^n \mathbb{P}(X_{i_k} \in A) 
\]</span>
en el contexto de estas notas, a menos que se indique lo contrario, las variables aleatorias que utilicemos serán <strong>completamente independientes</strong>.</p>
<p>Un aspecto interesante de la independencia es que permite partir las funciones de masa, densidad y distribución acumulada en dos funciones independientes. Así, si <span class="math inline">\(X,Y\)</span> son independientes con masa conjunta <span class="math inline">\(p\)</span>:
<span class="math display">\[
p_{X,Y}(x,y) = \mathbb{P}(X = x, Y = y) = \mathbb{P}(X = x)\cdot\mathbb{P}(Y = y) = p_X(x)\cdot p_Y(y)
\]</span>
El resultado se mantiene para distribuciones:
<span class="math display">\[
F_{X,Y}(x,y) = \mathbb{P}(X \leq x, Y \leq y) = \mathbb{P}(X \leq x)\cdot\mathbb{P}(Y \leq y) = F_X(x)\cdot F_Y(y)
\]</span>
y si derivamos (en caso de <span class="math inline">\(F\)</span> diferenciable), se mantiene para densidades:</p>
<p><span class="math display">\[
f_{X,Y}(x,y) = \dfrac{\partial^2}{\partial x\partial y} F_{X,Y}\Big|_{(x,y)} = \dfrac{\partial^2}{\partial x\partial y} F_X(x)\cdot F_Y(y)\Big|_{(x,y)} = f_X(x) f_Y(y)
\]</span></p>
</div>
<div id="esperanza-varianza-y-covarianza" class="section level2">
<h2><span class="header-section-number">B.11</span> Esperanza, varianza y covarianza</h2>
<p>Para una función medible <span class="math inline">\(g\)</span> de una variable aleatoria <span class="math inline">\(X\)</span> definimos su valor esperado (si existe) como:
<span class="math display">\[
\mathbb{E}\big[g(X)\big] = \begin{cases}
\sum\limits_{x \in \text{Supp}(X)} g(x) \cdot \mathbb{P}(X  = x) &amp; \text{ si } X \text{ discreta.} \\
\int\limits_{-\infty}^{\infty} g(x) \cdot f_X(x) dx&amp; \text{ si } X \text{ continua}
\end{cases}
\]</span>
donde <span class="math inline">\(f_X\)</span> es la densidad de <span class="math inline">\(X\)</span> en el caso continuo y <span class="math inline">\(\text{Supp}(X)\)</span> es el conjunto imagen de <span class="math inline">\(X\)</span> (el soporte):
<span class="math display">\[
\text{Supp}(X) = \{ x : X(\omega) = x \text{ para } \omega \in \Omega \}
\]</span>
En el caso de conjuntos finitos de variables aleatorias la definción es similar:</p>
<p>Para una función <span class="math inline">\(g:\mathbb{R}^n \to \mathbb{R}\)</span> multivariada de <span class="math inline">\(n\)</span> variables aleatorias (sobre los reales) <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> definimos su valor esperado (si existe y sin pérdida de generalidad suponiendo las primeras <span class="math inline">\(j\)</span> son discretas y las últimas <span class="math inline">\(n - (j + 1)\)</span> continuas) como:

<span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
\mathbb{E}\big[  g(X_1, X_2, \dots, X_n) \big]  = 
\\ &amp;   \int_{-\infty}^{\infty}  \dots  \int_{-\infty}^{\infty} \sum_{x_j \in \text{Supp}(X_j)}  \dots \sum_{x_1 \in \text{Supp}(X_1)} g(x_1, x_2, \dots, x_n) p(x_1)  \dots p(x_j) f_{X_{j+1}}(x_{j+1}) \dots  f_{X_{n}}(x_{n}) dx_{j+1} \dots  dx_{n}
\end{aligned}
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(p(x_j)\)</span> es la masa de <span class="math inline">\(X_j\)</span> (es decir <span class="math inline">\(p(x_j) = \mathbb{P}(X_j = x_j)\)</span>. En el caso particular de dos variables aleatorias <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> podemos escribir la expresión de manera más sencilla:</p>
<p><span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
\mathbb{E}\big[ &amp; g(X_1, X_2) \big]  = 
\begin{cases}
\int\limits_{-\infty}^{\infty} \int_{-\infty}^{\infty}  g(x_1, x_2) f_{X_1}(x_1) f_{X_2}(x_2) dx_1 dx_2  &amp; \text{ ambas continuas,} \\ \\
\sum\limits_{x \in \text{Supp}(X_1)} \sum\limits_{x \in \text{Supp}(X_2)}   g(x_1, x_2) p(x_1) p(x_2)  &amp; \text{ ambas discretas,} \\ \\
\int_{-\infty}^{\infty} \sum\limits_{x \in \text{Supp}(X_1)}    g(x_1, x_2) p(x_1) p(x_2)  &amp; X_1 \text{ discreta, } X_2 \text{ continua.}  \\
\end{cases}
\end{aligned}
\end{equation}\]</span></p>
<p>En particular, en el espacio de las variables aleatorias definimos un producto interno, <strong>la covarianza</strong> la cual está dada por:
<span class="math display">\[
\textrm{Cov}(X_1, X_2) = \mathbb{E}\Big[ \big(X_1 - \mathbb{E}[X_1]\big) \cdot \big(X_2 - \mathbb{E}[X_2]\big) \Big]
\]</span>
La <strong>varianza</strong> es un caso particular de la covarianza: cuando <span class="math inline">\(X_1 = X_2\)</span>:</p>
<p><span class="math display">\[
\textrm{Cov}(X_1, X_1) = \mathbb{E}\Big[ \big(X_1 - \mathbb{E}[X_1]\big)^2 \Big]
\]</span></p>
<div id="propiedades-de-valor-esperado-varianza-y-covarianza" class="section level3">
<h3><span class="header-section-number">B.11.1</span> Propiedades de valor esperado, varianza y covarianza</h3>
<p>El valor esperado al ser representable mediante sumas ó integrales cumple todas las propiedades de las sumas (resp integrales) en particular la linealidad:
<span class="math display">\[
\mathbb{E}\Big[ a X + Y\Big] = a \mathbb{E}[X] + \mathbb{E}[Y]
\]</span>
La demostración se hace exactamente igual en el caso de variables discretas, continuas (ó mezcla de una y una). Aquí muestro la de continuas con densidades <span class="math inline">\(f_X\)</span> y <span class="math inline">\(f_Y\)</span>:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
\mathbb{E}\Big[ a X + Y\Big] &amp; = \int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{\infty} (a x + y) f_{X,Y}(x,y) dx dy \\
&amp; = a \int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{\infty} x  f_{X,Y}(x,y)  dx dy +  \int\limits_{-\infty}^{\infty} \int\limits_{-\infty}^{\infty} y f_{X,Y}(x,y)  dx dy \\
&amp; = a \Big[ \int\limits_{-\infty}^{\infty} x  f_X(x) dx \Big] +  \int\limits_{-\infty}^{\infty} y f_Y(y) dy \\
&amp; =  a \mathbb{E}[X] + \mathbb{E}[Y]
\end{aligned}
\end{equation}\]</span></p>
<p>Otro resultado importante es que si dos variables aleatorias <span class="math inline">\(X,Y\)</span> son independientes entonces el valor esperado del producto se parte:
<span class="math display">\[
\mathbb{E}[XY] = \mathbb{E}[X] \cdot \mathbb{E}[Y]
\]</span>
La demostración se hace de manera idéntica en todos los casos. Aquí mostramos el caso de <span class="math inline">\(X,Y\)</span> discretas:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
\mathbb{E}\Big[XY\Big] &amp; = \sum\limits_{y \in \text{Sup}(Y)} \sum\limits_{x \in \text{Sup}(X)} xy \mathbb{P}(X = x, Y = y) 
\\ &amp; = \sum\limits_{y \in \text{Sup}(Y)} \sum\limits_{x \in \text{Sup}(X)} xy \mathbb{P}(X = x) \mathbb{P}(Y = y) 
\\ &amp; = \Big[\sum\limits_{y \in \text{Sup}(Y)} y  \mathbb{P}(Y = y)\Big]  \Big[\sum\limits_{x \in \text{Sup}(X)} x \mathbb{P}(X = x)\Big]
\\ &amp; = \mathbb{E}[X] \cdot \mathbb{E}[Y]
\end{aligned}
\end{equation}\]</span></p>
<p>La linealidad nos permite reescribir la covarianza:
<span class="math display">\[\begin{equation}
\begin{aligned}
\textrm{Cov}(X_1, X_2) &amp; = \mathbb{E}\Big[ \big(X_1 - \mathbb{E}[X_1]\big) \cdot \big(X_2 - \mathbb{E}[X_2]\big) \Big] \\
&amp; =  \mathbb{E}\Big[ X_1 X_2 \Big]  - \mathbb{E}\Big[X_1\Big]\mathbb{E}\Big[X_2\Big]   - \mathbb{E}\Big[X_1\Big]\mathbb{E}\Big[X_2\Big]  +  \mathbb{E}\Big[X_1\Big]\mathbb{E}\Big[X_2\Big] 
\\ &amp; = \mathbb{E}\Big[ X_1 X_2 \Big] - \mathbb{E}\Big[X_1\Big]\mathbb{E}\Big[X_2\Big] 
\end{aligned}
\end{equation}\]</span></p>
<p>de tal forma que es claro que si <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> son independientes entonces <span class="math inline">\(\textrm{Cov}(X_1, X_2) = 0\)</span> por la propiedad anterior del valor esperado. <strong>OJO</strong> De manera general covarianza <span class="math inline">\(0\)</span> no implica que las variables sean independientes como puede verse con las variables aleatorias siguientes:
<span class="math display">\[
f_{X,Y}(x,y) = \begin{cases}
1/8 &amp; \text{ si } (x,y) \in \{ (-1,-1), (-1,1), (1, -1), (1,1)\} \\
1/2 &amp; \text{ si } (x,y)  = (0,0), \\
0 &amp; \text{ en otro caso}
\end{cases}
\]</span>
las cuales <em>no son independientes</em> pues <span class="math inline">\(\mathbb{P}(X = 0, Y = 0) = 1/2\neq 1/4 = \mathbb{P}(X = 0)\cdot \mathbb{P}(Y = 0)\)</span>; sin embargo (<em>ejercicio sugerido</em>) la covarianza es <span class="math inline">\(0\)</span>.</p>
<p>Una segunda propiedad de interés de la covarianza es que actúa como el producto interno (de hecho es uno):
<span class="math display">\[
\text{Cov}(a X + bY, cW + dV) = ac \text{Cov}(X,W) + ad \text{Cov}(X,V) + bc \text{Cov}(Y,W) + bd \text{Cov}(Y,V) 
\]</span>
la cual se demuestra igual mediante la linealidad:
<span class="math display">\[\begin{equation}
\begin{aligned}
\textrm{Cov}(a &amp; X + bY, cW + dV)  = \mathbb{E}\Big[ (a X + bY) (cW + dV) \Big] - \mathbb{E}\Big[a X + bY\Big]\mathbb{E}\Big[cW + dV\Big] 
\\ &amp; = \mathbb{E}\Big[ ac XW + bc YW + ad XV + bd YV\Big] - \bigg( a \mathbb{E}\Big[ X \Big] + b\mathbb{E}\Big[ Y\Big]\bigg)\bigg( c\mathbb{E}\Big[W\Big] + d\mathbb{E}\Big[V\Big] \bigg)
\\ &amp; =   ac \text{Cov}(X,W) + ad \text{Cov}(X,V) + bc \text{Cov}(Y,W) + bd \text{Cov}(Y,V) 
\end{aligned}
\end{equation}\]</span>
donde la última igualdad se sigue de agrupar los términos idénticos tras sus constantes.</p>
</div>
</div>
<div id="condicionamiento-por-otra-variable-aleatoria" class="section level2">
<h2><span class="header-section-number">B.12</span> Condicionamiento por otra variable aleatoria</h2>
<p>A rellenarse pronto</p>
</div>
<div id="funciones-características" class="section level2">
<h2><span class="header-section-number">B.13</span> Funciones características</h2>
<p>A rellenarse pronto</p>
</div>
<div id="convergencias" class="section level2">
<h2><span class="header-section-number">B.14</span> Convergencias</h2>
<p>A rellenarse pronto</p>
<div id="teorema-de-continuidad-de-lévy" class="section level3">
<h3><span class="header-section-number">B.14.1</span> Teorema de continuidad de Lévy</h3>
<p>A rellenarse pronto</p>
</div>
</div>
<div id="ley-de-los-grandes-números" class="section level2">
<h2><span class="header-section-number">B.15</span> Ley de los grandes números</h2>
<p>A rellenarse pronto</p>
</div>
<div id="teorema-del-límite-central" class="section level2">
<h2><span class="header-section-number">B.16</span> Teorema del límite central</h2>
<p>A rellenarse pronto</p>
<div id="programación-en-r-del-teorema-del-límite-central-con-variables-aleatorias-independientes-idénticamente-distribuidas" class="section level3">
<h3><span class="header-section-number">B.16.1</span> Programación en <code>R</code> del teorema del límite central con variables aleatorias independientes idénticamente distribuidas</h3>
<p>Lo que programaremos (por facilidad) en esta sección corresponde a ejemplos del teorema de proba 2: dadas variables aleatorias independientes idénticamente <span class="math inline">\(\{X_i\}\)</span> distribuidas con media <span class="math inline">\(\mu\)</span> y varianza finita <span class="math inline">\(\sigma^2\)</span> tenemos que:</p>
<p><span class="math display">\[
Z =\lim_{n \to \infty} \sqrt{\dfrac{n}{\sigma^2}} \cdot  \Big( \frac{1}{n}\sum_{i = 1}^n X_i - \mu\Big) \sim \textrm{Normal}(0,1)
\]</span>
donde el símbolo <span class="math inline">\(\sim\)</span> se lee “se distribuye”. En este caso la interpretación va a ser que para <span class="math inline">\(n\)</span> muy grande tendremos que
<span class="math display">\[
\sqrt{\dfrac{n}{\sigma^2}} \cdot  \Big( \frac{1}{n}\sum_{i = 1}^n X_i - \mu\Big) \mathrel{\dot\sim} \textrm{Normal}(0,1)
\]</span></p>
<p>donde <span class="math inline">\(\mathrel{\dot\sim}\)</span> se lee como “se distribuye aproximadamente”. Programaremos una función en <code>R</code> que para <span class="math inline">\(n\)</span> grande muestre eso:</p>
<p>donde podemos ver la aproximación normal si tomamos, por ejemplo, las <span class="math inline">\(X_i\)</span> siguen una distribución Gamma:</p>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-265-1.png" width="384" style="display: block; margin: auto;" />
La binomial se ve así:
<img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-266-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Poisson:
<img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-267-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>E inclusive uniformes:
<img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-268-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Experimenta con otras distribuciones ¿puedes encontrar alguna para la que no funcione?</p>
</div>
<div id="ejercicio-3" class="section level3">
<h3><span class="header-section-number">B.16.2</span> Ejercicio</h3>
<p>Repite la programación del teorema del límite central pero ahora tomando las <span class="math inline">\(X_k\)</span> con distintas distribuciones siempre y cuando <span class="math inline">\(X_k\)</span> tenga media <span class="math inline">\(\mu_k\)</span> finita y las variables aleatorias satisfagan la <a href="https://en.wikipedia.org/wiki/Lindeberg%27s_condition">condición de Lindberg</a> (una forma de hacerlo es teniendo varianzas finitas que no incrementan con la <span class="math inline">\(k\)</span>).</p>

<div id="refs" class="references">
<div>
<p>Casella, George, and Roger L Berger. 2002. <em>Statistical Inference</em>. Vol. 2. Duxbury Pacific Grove, CA.</p>
</div>
<div>
<p>Gelman, Andrew, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. 2013. <em>Bayesian Data Analysis</em>. CRC press.</p>
</div>
<div>
<p>Hyndman, Rob J, and Yanan Fan. 1996. “Sample Quantiles in Statistical Packages.” <em>The American Statistician</em> 50 (4): 361–65.</p>
</div>
<div>
<p>Myatt, Glenn J, and Wayne P Johnson. 2007. <em>Making Sense of Data</em>. Wiley Online Library.</p>
</div>
<div>
<p>Panaretos, Victor M. 2016. “Statistics for Mathematicians.” <em>Compact Textbook in Mathematics. Birkhäuser/Springer</em> 142: 9–15.</p>
</div>
<div>
<p>Peck, Roxy, Chris Olsen, and Jay L Devore. 2015. <em>Introduction to Statistics and Data Analysis</em>. Cengage Learning.</p>
</div>
<div>
<p>Pewsey, Arthur, Markus Neuhäuser, and Graeme D Ruxton. 2013. <em>Circular Statistics in R</em>. Oxford University Press.</p>
</div>
<div>
<p>Särndal, Carl-Erik, Bengt Swensson, and Jan Wretman. 2003. <em>Model Assisted Survey Sampling</em>. Springer Science &amp; Business Media.</p>
</div>
<div>
<p>SURI, NNR MURTY RANGA, M Narasimha Murty, and G Athithan. 2019. <em>Outlier Detection: Techniques and Applications</em>. Springer.</p>
</div>
<div>
<p>Wolfe, Douglas A, and Grant Schneider. 2017. <em>Intuitive Introductory Statistics</em>. Springer.</p>
</div>
</div>
</div>
</div>
</div>


























<h3>References</h3>
<div id="refs" class="references">
<div id="ref-casella2002statistical">
<p>Casella, George, and Roger L Berger. 2002. <em>Statistical Inference</em>. Vol. 2. Duxbury Pacific Grove, CA.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="18">
<li id="fn18"><p>¿Se te ocurre alguna que no esté aquí?<a href="repaso-de-proba.html#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>Recuerda que <span class="math inline">\(\lambda\)</span> era para un tiempo entre <span class="math inline">\(0\)</span> y <span class="math inline">\(1\)</span>; <span class="math inline">\(\lambda w\)</span> es para un escalamiento del tiempo entre <span class="math inline">\(0\)</span> y <span class="math inline">\(w\)</span>.<a href="repaso-de-proba.html#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>Por teorema de cambio de variable.<a href="repaso-de-proba.html#fnref20" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="programación-en-r.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": ["night", "white", "sepia"],
"family": "sans",
"size": [2, 4]
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Introduccion_a_Muestreo.pdf", "Introduccion_a_Muestreo.epub"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true,
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
