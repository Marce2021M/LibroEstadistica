<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 5 Muestreo Aleatorio Simple sin Reemplazo (MAS/sR) | Estadística I: Análisis exploratorio de datos y muestreo</title>
  <meta name="description" content="Libro de estadística aplicada: temas de análisis exploratorio y muestreo" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 5 Muestreo Aleatorio Simple sin Reemplazo (MAS/sR) | Estadística I: Análisis exploratorio de datos y muestreo" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Libro de estadística aplicada: temas de análisis exploratorio y muestreo" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 5 Muestreo Aleatorio Simple sin Reemplazo (MAS/sR) | Estadística I: Análisis exploratorio de datos y muestreo" />
  
  <meta name="twitter:description" content="Libro de estadística aplicada: temas de análisis exploratorio y muestreo" />
  

<meta name="author" content="Rodrigo Zepeda-Tello" />


<meta name="date" content="2020-09-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="notación.html"/>
<link rel="next" href="demostración-del-teorema-del-límite-central-para-muestras-finitas.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística I: Análisis exploratorio de datos y muestreo</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Historia y conceptos</a></li>
<li class="chapter" data-level="2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html"><i class="fa fa-check"></i><b>2</b> Análisis Exploratorio de Datos</a><ul>
<li class="chapter" data-level="2.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#inicio"><i class="fa fa-check"></i><b>2.1</b> Inicio</a></li>
<li class="chapter" data-level="2.2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#librerías"><i class="fa fa-check"></i><b>2.2</b> Librerías</a></li>
<li class="chapter" data-level="2.3" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#base-a-analizar"><i class="fa fa-check"></i><b>2.3</b> Base a analizar</a></li>
<li class="chapter" data-level="2.4" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#definiciones-y-notación"><i class="fa fa-check"></i><b>2.4</b> Definiciones y notación</a></li>
<li class="chapter" data-level="2.5" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#estadísticos-univariados"><i class="fa fa-check"></i><b>2.5</b> Estadísticos univariados</a><ul>
<li class="chapter" data-level="2.5.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#definición-estadístico"><i class="fa fa-check"></i><b>2.5.1</b> Definición [Estadístico]</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio"><i class="fa fa-check"></i><b>2.6</b> Ejercicio</a></li>
<li class="chapter" data-level="2.7" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicios"><i class="fa fa-check"></i><b>2.7</b> Ejercicios</a></li>
<li class="chapter" data-level="2.8" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#gráficas-univariadas"><i class="fa fa-check"></i><b>2.8</b> Gráficas univariadas</a></li>
<li class="chapter" data-level="2.9" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#gráficas-bivariadas"><i class="fa fa-check"></i><b>2.9</b> Gráficas bivariadas</a><ul>
<li class="chapter" data-level="2.9.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-1"><i class="fa fa-check"></i><b>2.9.1</b> Ejercicio</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#estadísticos-bivariados"><i class="fa fa-check"></i><b>2.10</b> Estadísticos bivariados</a><ul>
<li class="chapter" data-level="2.10.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-2"><i class="fa fa-check"></i><b>2.10.1</b> Ejercicio</a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-3"><i class="fa fa-check"></i><b>2.11</b> Ejercicio</a></li>
<li class="chapter" data-level="2.12" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ajuste-funcional"><i class="fa fa-check"></i><b>2.12</b> Ajuste funcional</a><ul>
<li class="chapter" data-level="2.12.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-4"><i class="fa fa-check"></i><b>2.12.1</b> Ejercicio</a></li>
<li class="chapter" data-level="2.12.2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-sugerido"><i class="fa fa-check"></i><b>2.12.2</b> Ejercicio sugerido</a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicios-del-capítulo"><i class="fa fa-check"></i><b>2.13</b> Ejercicios del capítulo</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="muestreo-aleatorio-simple.html"><a href="muestreo-aleatorio-simple.html"><i class="fa fa-check"></i><b>3</b> Muestreo Aleatorio Simple</a><ul>
<li class="chapter" data-level="3.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#inicio"><i class="fa fa-check"></i><b>3.1</b> Inicio</a></li>
<li class="chapter" data-level="3.2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#librerías"><i class="fa fa-check"></i><b>3.2</b> Librerías</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="notación.html"><a href="notación.html"><i class="fa fa-check"></i><b>4</b> Notación</a><ul>
<li class="chapter" data-level="4.0.1" data-path="notación.html"><a href="notación.html#ejemplo"><i class="fa fa-check"></i><b>4.0.1</b> Ejemplo</a></li>
<li class="chapter" data-level="4.0.2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio"><i class="fa fa-check"></i><b>4.0.2</b> Ejercicio</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="muestreo-aleatorio-simple-sin-reemplazo-massr.html"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html"><i class="fa fa-check"></i><b>5</b> Muestreo Aleatorio Simple sin Reemplazo (MAS/sR)</a><ul>
<li class="chapter" data-level="5.1" data-path="muestreo-aleatorio-simple-sin-reemplazo-massr.html"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#definición"><i class="fa fa-check"></i><b>5.1</b> Definición</a><ul>
<li class="chapter" data-level="5.1.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-1"><i class="fa fa-check"></i><b>5.1.1</b> Ejercicio</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="muestreo-aleatorio-simple-sin-reemplazo-massr.html"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#teorema-del-límite-central-aplicación"><i class="fa fa-check"></i><b>5.2</b> Teorema del Límite Central (Aplicación)</a><ul>
<li class="chapter" data-level="5.2.1" data-path="muestreo-aleatorio-simple-sin-reemplazo-massr.html"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#programación-en-r-del-teorema-del-límite-central-con-variables-aleatorias-independientes-idénticamente-distribuidas"><i class="fa fa-check"></i><b>5.2.1</b> Programación en <code>R</code> del teorema del límite central con variables aleatorias independientes idénticamente distribuidas</a></li>
<li class="chapter" data-level="5.2.2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-2"><i class="fa fa-check"></i><b>5.2.2</b> Ejercicio</a></li>
<li class="chapter" data-level="5.2.3" data-path="muestreo-aleatorio-simple-sin-reemplazo-massr.html"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#estimación-de-intervalos-de-confianza-para-el-total"><i class="fa fa-check"></i><b>5.2.3</b> Estimación de intervalos de confianza para el total</a></li>
<li class="chapter" data-level="5.2.4" data-path="muestreo-aleatorio-simple-sin-reemplazo-massr.html"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#ejemplo-con-simulación"><i class="fa fa-check"></i><b>5.2.4</b> Ejemplo con simulación:</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="muestreo-aleatorio-simple-sin-reemplazo-massr.html"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#ejemplo-resumen-estimación-de-una-proporción-bajo-muestreo-aleatorio-simple-sin-reemplazo"><i class="fa fa-check"></i><b>5.3</b> Ejemplo Resumen: Estimación de una proporción bajo muestreo aleatorio simple sin reemplazo</a></li>
<li class="chapter" data-level="5.4" data-path="muestreo-aleatorio-simple-sin-reemplazo-massr.html"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#ejemplo-resumen-estimación-del-total-de-individuos-en-una-fotografía"><i class="fa fa-check"></i><b>5.4</b> Ejemplo Resumen: Estimación del total de individuos en una fotografía</a></li>
<li class="chapter" data-level="5.5" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-3"><i class="fa fa-check"></i><b>5.5</b> Ejercicio:</a></li>
<li class="chapter" data-level="5.6" data-path="muestreo-aleatorio-simple-sin-reemplazo-massr.html"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#ejemplo-resumen-estimación-de-una-región-crítica"><i class="fa fa-check"></i><b>5.6</b> Ejemplo Resumen: Estimación de una región crítica</a></li>
<li class="chapter" data-level="5.7" data-path="muestreo-aleatorio-simple-sin-reemplazo-massr.html"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#ejemplo-resumen-estimación-del-total-de-una-población"><i class="fa fa-check"></i><b>5.7</b> Ejemplo Resumen: Estimación del total de una población</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="demostración-del-teorema-del-límite-central-para-muestras-finitas.html"><a href="demostración-del-teorema-del-límite-central-para-muestras-finitas.html"><i class="fa fa-check"></i><b>6</b> Demostración del Teorema del Límite Central para Muestras Finitas</a><ul>
<li class="chapter" data-level="6.1" data-path="demostración-del-teorema-del-límite-central-para-muestras-finitas.html"><a href="demostración-del-teorema-del-límite-central-para-muestras-finitas.html#teorema-de-límite-central-bajo-condición-de-lindberg"><i class="fa fa-check"></i><b>6.1</b> Teorema de Límite Central bajo condición de Lindberg</a></li>
<li class="chapter" data-level="6.2" data-path="demostración-del-teorema-del-límite-central-para-muestras-finitas.html"><a href="demostración-del-teorema-del-límite-central-para-muestras-finitas.html#teorema-de-límite-central-para-poblaciones-finitas"><i class="fa fa-check"></i><b>6.2</b> Teorema de Límite Central para poblaciones finitas</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="muestreo-aleatorio-simple-bernoulli-be.html"><a href="muestreo-aleatorio-simple-bernoulli-be.html"><i class="fa fa-check"></i><b>7</b> Muestreo Aleatorio Simple Bernoulli (BE)</a><ul>
<li class="chapter" data-level="7.0.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-4"><i class="fa fa-check"></i><b>7.0.1</b> Ejercicio</a></li>
<li class="chapter" data-level="7.0.2" data-path="muestreo-aleatorio-simple-bernoulli-be.html"><a href="muestreo-aleatorio-simple-bernoulli-be.html#ejemplo-1"><i class="fa fa-check"></i><b>7.0.2</b> Ejemplo</a></li>
<li class="chapter" data-level="7.0.3" data-path="muestreo-aleatorio-simple-bernoulli-be.html"><a href="muestreo-aleatorio-simple-bernoulli-be.html#un-mejor-estimador-el-proporcional-al-tamaño"><i class="fa fa-check"></i><b>7.0.3</b> Un mejor estimador: el proporcional al tamaño</a></li>
<li class="chapter" data-level="7.1" data-path="muestreo-aleatorio-simple-bernoulli-be.html"><a href="muestreo-aleatorio-simple-bernoulli-be.html#ejemplo-resumen-aduana"><i class="fa fa-check"></i><b>7.1</b> Ejemplo Resumen: Aduana</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="muestreo-aleatorio-simple-con-reemplazo-mascr.html"><a href="muestreo-aleatorio-simple-con-reemplazo-mascr.html"><i class="fa fa-check"></i><b>8</b> Muestreo Aleatorio Simple con Reemplazo (MAS/cR)</a><ul>
<li class="chapter" data-level="8.1" data-path="muestreo-aleatorio-simple-con-reemplazo-mascr.html"><a href="muestreo-aleatorio-simple-con-reemplazo-mascr.html#ejemplo-resumen-proporción-de-trabajadores-enfermos-con-o-sin-reemplazo"><i class="fa fa-check"></i><b>8.1</b> Ejemplo Resumen: Proporción de trabajadores enfermos con o sin reemplazo</a></li>
<li class="chapter" data-level="8.2" data-path="muestreo-aleatorio-simple-con-reemplazo-mascr.html"><a href="muestreo-aleatorio-simple-con-reemplazo-mascr.html#ejemplo-resumen-captura-recaptura-con-reemplazo"><i class="fa fa-check"></i><b>8.2</b> Ejemplo Resumen: Captura-Recaptura con reemplazo</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="muestreo-aleatorio-simple-ponderado-masp.html"><a href="muestreo-aleatorio-simple-ponderado-masp.html"><i class="fa fa-check"></i><b>9</b> Muestreo Aleatorio Simple Ponderado (MAS/P)</a></li>
<li class="chapter" data-level="10" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicios"><i class="fa fa-check"></i><b>10</b> Ejercicios</a></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="appendix"><span><b>Apéndice</b></span></li>
<li class="chapter" data-level="A" data-path="programación-en-r.html"><a href="programación-en-r.html"><i class="fa fa-check"></i><b>A</b> Programación en <code>R</code></a><ul>
<li class="chapter" data-level="A.1" data-path="programación-en-r.html"><a href="programación-en-r.html#algunas-ventajas-de-r-y-cosas-no-tan-padres"><i class="fa fa-check"></i><b>A.1</b> Algunas ventajas de <code>R</code> y cosas no tan padres</a><ul>
<li class="chapter" data-level="A.1.1" data-path="programación-en-r.html"><a href="programación-en-r.html#puntos-a-favor-de-r"><i class="fa fa-check"></i><b>A.1.1</b> Puntos a favor de <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="programación-en-r.html"><a href="programación-en-r.html#bienvenidx-a-r-taking-off-again-sí-así-se-llama-esta-versión"><i class="fa fa-check"></i><b>A.2</b> Bienvenidx a <code>R</code>, Taking Off Again (sí, así se llama esta versión)</a></li>
<li class="chapter" data-level="A.3" data-path="programación-en-r.html"><a href="programación-en-r.html#instalando-cosas"><i class="fa fa-check"></i><b>A.3</b> Instalando cosas</a><ul>
<li class="chapter" data-level="A.3.1" data-path="programación-en-r.html"><a href="programación-en-r.html#instalación-de-r"><i class="fa fa-check"></i><b>A.3.1</b> Instalación de <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="programación-en-r.html"><a href="programación-en-r.html#instalación-de-rstudio"><i class="fa fa-check"></i><b>A.4</b> Instalación de <code>RStudio</code></a></li>
<li class="chapter" data-level="A.5" data-path="programación-en-r.html"><a href="programación-en-r.html#primeros-pasos-en-r-usando-rstudio"><i class="fa fa-check"></i><b>A.5</b> Primeros pasos en <code>R</code> usando <code>RStudio</code></a></li>
<li class="chapter" data-level="A.6" data-path="programación-en-r.html"><a href="programación-en-r.html#cálculos-numéricos"><i class="fa fa-check"></i><b>A.6</b> Cálculos numéricos</a><ul>
<li class="chapter" data-level="A.6.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio"><i class="fa fa-check"></i><b>A.6.1</b> Ejercicio</a></li>
<li class="chapter" data-level="A.6.2" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-1"><i class="fa fa-check"></i><b>A.6.2</b> Ejercicio</a></li>
<li class="chapter" data-level="A.6.3" data-path="programación-en-r.html"><a href="programación-en-r.html#respuestas"><i class="fa fa-check"></i><b>A.6.3</b> Respuestas</a></li>
</ul></li>
<li class="chapter" data-level="A.7" data-path="programación-en-r.html"><a href="programación-en-r.html#variables"><i class="fa fa-check"></i><b>A.7</b> Variables</a><ul>
<li class="chapter" data-level="A.7.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicios"><i class="fa fa-check"></i><b>A.7.1</b> Ejercicios</a></li>
<li class="chapter" data-level="A.7.2" data-path="programación-en-r.html"><a href="programación-en-r.html#nivel-3"><i class="fa fa-check"></i><b>A.7.2</b> NIVEL 3</a></li>
</ul></li>
<li class="chapter" data-level="A.8" data-path="programación-en-r.html"><a href="programación-en-r.html#observaciones-sobre-la-aritmética-de-punto-flotante"><i class="fa fa-check"></i><b>A.8</b> Observaciones sobre la aritmética de punto flotante</a><ul>
<li class="chapter" data-level="A.8.1" data-path="programación-en-r.html"><a href="programación-en-r.html#cómo-checar-un-if"><i class="fa fa-check"></i><b>A.8.1</b> ¿Cómo checar un if?</a></li>
</ul></li>
<li class="chapter" data-level="A.9" data-path="programación-en-r.html"><a href="programación-en-r.html#leer-y-almacenar-variables-en-r"><i class="fa fa-check"></i><b>A.9</b> Leer y almacenar variables en <code>R</code></a><ul>
<li class="chapter" data-level="A.9.1" data-path="análisis-exploratorio-de-datos.html"><a href="análisis-exploratorio-de-datos.html#ejercicio-2"><i class="fa fa-check"></i><b>A.9.1</b> Ejercicio</a></li>
</ul></li>
<li class="chapter" data-level="A.10" data-path="programación-en-r.html"><a href="programación-en-r.html#instalación-de-paquetes"><i class="fa fa-check"></i><b>A.10</b> Instalación de paquetes</a><ul>
<li class="chapter" data-level="A.10.1" data-path="programación-en-r.html"><a href="programación-en-r.html#ejercicios-1"><i class="fa fa-check"></i><b>A.10.1</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="A.11" data-path="programación-en-r.html"><a href="programación-en-r.html#comentarios-adicionales-sobre-el-formato"><i class="fa fa-check"></i><b>A.11</b> Comentarios adicionales sobre el formato</a></li>
<li class="chapter" data-level="A.12" data-path="programación-en-r.html"><a href="programación-en-r.html#funciones-indicadoras"><i class="fa fa-check"></i><b>A.12</b> Funciones indicadoras</a></li>
<li class="chapter" data-level="A.13" data-path="programación-en-r.html"><a href="programación-en-r.html#conteo"><i class="fa fa-check"></i><b>A.13</b> Conteo</a></li>
<li class="chapter" data-level="A.14" data-path="programación-en-r.html"><a href="programación-en-r.html#espacios-de-probabilidad"><i class="fa fa-check"></i><b>A.14</b> Espacios de probabilidad</a></li>
<li class="chapter" data-level="A.15" data-path="programación-en-r.html"><a href="programación-en-r.html#probabilidad-condicional"><i class="fa fa-check"></i><b>A.15</b> Probabilidad condicional</a></li>
<li class="chapter" data-level="A.16" data-path="programación-en-r.html"><a href="programación-en-r.html#independencia"><i class="fa fa-check"></i><b>A.16</b> Independencia</a></li>
<li class="chapter" data-level="A.17" data-path="programación-en-r.html"><a href="programación-en-r.html#variables-aleatorias-y-función-de-distribución-acumulada"><i class="fa fa-check"></i><b>A.17</b> Variables aleatorias y función de distribución (acumulada)</a></li>
<li class="chapter" data-level="A.18" data-path="programación-en-r.html"><a href="programación-en-r.html#funciones-de-masa-de-probabilidad"><i class="fa fa-check"></i><b>A.18</b> Funciones de masa de probabilidad</a></li>
<li class="chapter" data-level="A.19" data-path="programación-en-r.html"><a href="programación-en-r.html#funciones-de-densidad"><i class="fa fa-check"></i><b>A.19</b> Funciones de densidad</a></li>
<li class="chapter" data-level="A.20" data-path="programación-en-r.html"><a href="programación-en-r.html#teorema-de-cambio-de-variable-unidimensional"><i class="fa fa-check"></i><b>A.20</b> Teorema de cambio de variable unidimensional</a></li>
<li class="chapter" data-level="A.21" data-path="programación-en-r.html"><a href="programación-en-r.html#probabilidad-multivariada"><i class="fa fa-check"></i><b>A.21</b> Probabilidad Multivariada</a></li>
<li class="chapter" data-level="A.22" data-path="programación-en-r.html"><a href="programación-en-r.html#esperanza-varianza-y-covarianza"><i class="fa fa-check"></i><b>A.22</b> Esperanza, varianza y covarianza</a><ul>
<li class="chapter" data-level="A.22.1" data-path="programación-en-r.html"><a href="programación-en-r.html#propiedades-de-valor-esperado-varianza-y-covarianza"><i class="fa fa-check"></i><b>A.22.1</b> Propiedades de valor esperado, varianza y covarianza</a></li>
</ul></li>
<li class="chapter" data-level="A.23" data-path="programación-en-r.html"><a href="programación-en-r.html#condicionamiento-por-otra-variable-aleatoria"><i class="fa fa-check"></i><b>A.23</b> Condicionamiento por otra variable aleatoria</a></li>
<li class="chapter" data-level="A.24" data-path="programación-en-r.html"><a href="programación-en-r.html#funciones-características"><i class="fa fa-check"></i><b>A.24</b> Funciones características</a></li>
<li class="chapter" data-level="A.25" data-path="programación-en-r.html"><a href="programación-en-r.html#convergencias"><i class="fa fa-check"></i><b>A.25</b> Convergencias</a><ul>
<li class="chapter" data-level="A.25.1" data-path="programación-en-r.html"><a href="programación-en-r.html#teorema-de-continuidad-de-lévy"><i class="fa fa-check"></i><b>A.25.1</b> Teorema de continuidad de Lévy</a></li>
</ul></li>
<li class="chapter" data-level="A.26" data-path="programación-en-r.html"><a href="programación-en-r.html#ley-de-los-grandes-números"><i class="fa fa-check"></i><b>A.26</b> Ley de los grandes números</a></li>
<li class="chapter" data-level="A.27" data-path="programación-en-r.html"><a href="programación-en-r.html#teorema-del-límite-central"><i class="fa fa-check"></i><b>A.27</b> Teorema del límite central</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Rodrigo Zepeda Tello</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística I: Análisis exploratorio de datos y muestreo</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="muestreo-aleatorio-simple-sin-reemplazo-massr" class="section level1">
<h1><span class="header-section-number">Capítulo 5</span> Muestreo Aleatorio Simple sin Reemplazo (MAS/sR)</h1>
<p>Vamos a considerar una de las formas más sencillas de muestreo: el aleatorio simple <em>sin reemplazo</em> . Para ello seleccionamos de <span class="math inline">\(U = (x_1, x_2, \dots, x_N)^T\)</span> a <span class="math inline">\(n\in\mathbb{N}\)</span> (fijo) observaciones asignándole la probabilidad de ser seleccionada a cada una de <span class="math inline">\(\frac{1}{N}\)</span>. Una vez se selecciona la primera, se selecciona una de las que restan de <span class="math inline">\(U\)</span> con probabilidad <span class="math inline">\(\frac{1}{N-1}\)</span>. El proceso se repite hasta extraer <span class="math inline">\(n\)</span> elementos.</p>
<p>Comencemos por un ejemplo, supongamos tenemos una población de cinco personas:
<span class="math display">\[
U = \Big( \text{Ana}, \text{Beto}, \text{Carlos}, \text{Diana}, \text{Enriqueta}\Big)^T
\]</span>
Si queremos tomar una muestra de <span class="math inline">\(3\)</span> personas sin reemplazo, las muestras posibles son:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\Big( \text{Ana}, \text{Beto}, \text{Carlos}\Big)^T\)</span></p></li>
<li><p><span class="math inline">\(\Big( \text{Ana}, \text{Carlos}, \text{Diana}\Big)^T\)</span></p></li>
<li><p><span class="math inline">\(\Big( \text{Ana}, \text{Beto}, \text{Diana}\Big)^T\)</span></p></li>
<li><p><span class="math inline">\(\Big( \text{Ana}, \text{Beto}, \text{Enriqueta}\Big)^T\)</span></p></li>
<li><p><span class="math inline">\(\Big( \text{Ana}, \text{Carlos}, \text{Enriqueta}\Big)^T\)</span></p></li>
<li><p><span class="math inline">\(\Big( \text{Ana}, \text{Diana}, \text{Enriqueta}\Big)^T\)</span></p></li>
<li><p><span class="math inline">\(\Big( \text{Beto}, \text{Carlos}, \text{Diana}\Big)^T\)</span></p></li>
<li><p><span class="math inline">\(\Big( \text{Beto}, \text{Diana}, \text{Enriqueta}\Big)^T\)</span></p></li>
<li><p><span class="math inline">\(\Big( \text{Beto}, \text{Carlos}, \text{Enriqueta}\Big)^T\)</span></p></li>
<li><p><span class="math inline">\(\Big( \text{Carlos}, \text{Diana}, \text{Enriqueta}\Big)^T\)</span></p></li>
</ol>
<p>Obtener una muestra aleatoria se puede hacer en <code>R</code> con un vector mediante <code>sample</code>:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb3-1"></a><span class="co">#Vector de nombres</span></span>
<span id="cb3-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb3-2"></a>nombres &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Ana&quot;</span>,<span class="st">&quot;Beto&quot;</span>,<span class="st">&quot;Carlos&quot;</span>,<span class="st">&quot;Diana&quot;</span>,<span class="st">&quot;Enriqueta&quot;</span>)</span>
<span id="cb3-3"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb3-3"></a></span>
<span id="cb3-4"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb3-4"></a><span class="co">#Muestra</span></span>
<span id="cb3-5"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb3-5"></a><span class="kw">sample</span>(nombres, <span class="dv">3</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Diana&quot;     &quot;Enriqueta&quot; &quot;Beto&quot;</code></pre>
<p>Formalmente, un esquema de muestreo es <strong>aleatorio simple sin reemplazo</strong> si dada una constante <span class="math inline">\(n \in \mathbb{N}\)</span> (con <span class="math inline">\(0 &lt; n \leq N\)</span>) se tiene:</p>
<p><span class="math display">\[
\mathbb{P}\big( \mathcal{S} = S \big) = \begin{cases}
\frac{1}{\binom{N}{n}} &amp; \text{ si } \#S = n \\
0 &amp; \text{ en otro caso.}
\end{cases}
\]</span>
En el caso de muestreo aleatorio simple sin reemplazo podemos calcular las probabilidades de inclusión como siguen:
<span class="math display">\[
\pi_k = \mathbb{P}(x_k \in \mathcal{S}) = \sum\limits_{i=1}^{M_1} \frac{1}{\binom{N}{n}} = \frac{\binom{N-1}{n-1}}{\binom{N}{n}} = \frac{n}{N} = f
\]</span>
donde la tercera igualdad se sigue de que hay <span class="math inline">\(M_1 = \binom{N-1}{n-1}\)</span> muestras que contienen al <span class="math inline">\(x_k\)</span>. (La lógica es, fijo el <span class="math inline">\(x_k\)</span> y entonces me quedan <span class="math inline">\(N-1\)</span> valores de <span class="math inline">\(x\)</span> a acomodar en <span class="math inline">\(n-1\)</span> espacios). Por otro lado:
<span class="math display">\[
\pi_{k,j} = \mathbb{P}(x_k \in \mathcal{S}, x_j \in S) = \sum\limits_{i=1}^{M_2}  \frac{1}{\binom{N}{n}} = \frac{\binom{N-2}{n-2}}{\binom{N}{n}} = \dfrac{n(n-1)}{N(N-1)}
\]</span>
pues hay <span class="math inline">\(M_2 = \binom{N-2}{n-2}\)</span> muestras conteniendo a <span class="math inline">\(x_k\)</span> y <span class="math inline">\(x_j\)</span> a la vez.</p>
<p>Para estimar el total poblacional dado por:
<span class="math display">\[
t = \sum\limits_{i=1}^N x_i
\]</span>
bajo <em>MAS/sR</em> podemos tomar:
<span class="math display">\[
\hat{t} = N \cdot \bar{x}_{\mathcal{S}} = N \frac{1}{n} \sum\limits_{i = 1}^n x_k =  \sum\limits_{i = 1}^n \dfrac{x_k}{n/N} =  
\sum\limits_{k=1}^N \frac{x_k}{\pi_k} \cdot \mathbb{I}_{\mathcal{S}}(x_k)
\]</span>
Notamos entonces que el estimador <span class="math inline">\(\hat{t}\)</span> es una variable aleatoria pues depende de las indicadoras de la muestra. En particular:
<span class="math display">\[
\mathbb{E}\big[ \hat{t} \big] = \mathbb{E}\bigg[\sum\limits_{k=1}^N \frac{x_k}{\pi_k} \cdot \mathbb{I}_{\mathcal{S}}(x_k) \bigg] = \sum\limits_{k=1}^N \frac{x_k}{\pi_k} \underbrace{\mathbb{E}\bigg[\mathbb{I}_{\mathcal{S}}(x_k) \bigg]}_{\pi_k}  = t
\]</span>
de donde se sigue que en promedio el estimador <span class="math inline">\(\hat{t}\)</span> vale el total.</p>
<div id="definición" class="section level2">
<h2><span class="header-section-number">5.1</span> Definición</h2>
<p>Un estimador <span class="math inline">\(\hat{\theta}\)</span> es un estimador insesgado de <span class="math inline">\(\theta\)</span> si:
<span class="math display">\[
\mathbb{E}\big[ \hat{\theta} - \theta] = 0
\]</span>
En nuestro caso <span class="math inline">\(\hat{t}\)</span> es <em>insesgado</em>.</p>
<p>De manera numérica, podemos simular la estimación del total en <code>1000</code> simulaciones como sigue:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb5-1"></a>nsim &lt;-<span class="st"> </span><span class="dv">1000</span></span>
<span id="cb5-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb5-2"></a>N    &lt;-<span class="st"> </span><span class="dv">1000</span></span>
<span id="cb5-3"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb5-3"></a>n    &lt;-<span class="st"> </span><span class="dv">100</span> </span>
<span id="cb5-4"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb5-4"></a>base.completa &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">rnorm</span>(N))</span>
<span id="cb5-5"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb5-5"></a>total         &lt;-<span class="st"> </span><span class="kw">sum</span>(base.completa<span class="op">$</span>x)</span>
<span id="cb5-6"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb5-6"></a>total.muestra &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)</span>
<span id="cb5-7"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb5-7"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nsim){</span>
<span id="cb5-8"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb5-8"></a>  muestra          &lt;-<span class="st"> </span><span class="kw">sample</span>(base.completa<span class="op">$</span>x, n)</span>
<span id="cb5-9"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb5-9"></a>  total.muestra[i] &lt;-<span class="st"> </span>N<span class="op">*</span><span class="kw">mean</span>(muestra)</span>
<span id="cb5-10"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb5-10"></a>}</span>
<span id="cb5-11"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb5-11"></a><span class="kw">mean</span>(total.muestra)</span></code></pre></div>
<pre><code>## [1] 40.33179</code></pre>
<p>Podemos ver las simulaciones como sigue:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb7-1"></a><span class="kw">ggplot</span>() <span class="op">+</span></span>
<span id="cb7-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb7-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> total.muestra, <span class="dt">y =</span> ..density..), <span class="dt">fill =</span> <span class="st">&quot;#008B8B&quot;</span>, </span>
<span id="cb7-3"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb7-3"></a>                 <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">binwidth =</span> <span class="dv">40</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb7-4"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb7-4"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept =</span> total), <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>) <span class="op">+</span></span>
<span id="cb7-5"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb7-5"></a><span class="st">  </span><span class="kw">theme_classic</span>() </span></code></pre></div>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Como podrás notar la <span class="math inline">\(\hat{t}\)</span> es una variable aleatoria y por tanto tiene varianza. De hecho:
<span class="math display">\[
\textrm{Var}(\hat{t}) = \sum\limits_{k = 1}^N \sum\limits_{l = 1}^k \Delta_{k,l} \frac{x_k}{\pi_k} \frac{x_l}{\pi_l}
\]</span>
Para demostrarlo seguimos las igualdades:
<span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
\textrm{Var}(\hat{t})  &amp; = \textrm{Var}\Bigg( \sum\limits_{k=1}^N \frac{x_k}{\pi_k} \cdot \mathbb{I}_{\mathcal{S}}(x_k) \Bigg)
\\ &amp; = \sum\limits_{k=1}^N  \frac{x_k^2}{\pi_k^2} \cdot \textrm{Var}\Big(\mathbb{I}_{\mathcal{S}}(x_k) \Big) + \sum\limits_{k = 1}^N \sum\limits_{\substack{l = 1 \\ \\ l \neq k}}^{N}  \frac{x_k}{\pi_k}  \frac{x_l}{\pi_l} \cdot \textrm{Cov}\Big(\mathbb{I}_{\mathcal{S}}(x_k), \mathbb{I}_{\mathcal{S}}(x_l) \Big)
\\ &amp; = \sum\limits_{k=1}^N  \frac{x_k^2}{\pi_k^2} \cdot \underbrace{\pi_k (1 - \pi_k)}_{\Delta_{k,k}} + \sum\limits_{k = 1}^N \sum\limits_{\substack{l = 1 \\ \\ l \neq k}}^{N} \frac{x_k}{\pi_k}  \frac{x_l}{\pi_l} \cdot \underbrace{\textrm{Cov}\Big(\mathbb{I}_{\mathcal{S}}(x_k), \mathbb{I}_{\mathcal{S}}(x_l) \Big)}_{\Delta_{k,l}}
\\ &amp; = \sum\limits_{k = 1}^N \sum\limits_{\substack{l = 1 \\ \\ l \neq k}}^{N}\Delta_{k,l} \frac{x_k}{\pi_k} \frac{x_l}{\pi_l}
\end{aligned}
\end{equation}\]</span></p>
<p>Numéricamente, en el ejemplo anterior la varianza (simulada) de <span class="math inline">\(\hat{t}\)</span> es:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb8-1"></a><span class="kw">var</span>(total.muestra)</span></code></pre></div>
<pre><code>## [1] 8801.784</code></pre>
<p>mientras que la <em>real</em> está dada por (ver ejercicio más adelante):</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb10-1"></a>f        &lt;-<span class="st"> </span>n<span class="op">/</span>N</span>
<span id="cb10-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb10-2"></a>varianza &lt;-<span class="st"> </span>N<span class="op">^</span><span class="dv">2</span><span class="op">*</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>f)<span class="op">/</span>n<span class="op">*</span><span class="kw">var</span>(base.completa<span class="op">$</span>x)</span>
<span id="cb10-3"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb10-3"></a><span class="kw">print</span>(varianza)</span></code></pre></div>
<pre><code>## [1] 8613.526</code></pre>
<p>Nota que tenemos un problema: para estimar <span class="math inline">\(\textrm{Var}(\hat{t})\)</span> necesitamos conocer todas las <span class="math inline">\(x_k\)</span> de la población ¡lo cual es imposible! Entonces necesitamos un estimador de la varianza de <span class="math inline">\(\hat{t}\)</span> para lo cual proponemos:</p>
<p><span class="math display">\[
\widehat{\textrm{Var}}(\hat{t}) = \sum\limits_{k = 1}^n \sum\limits_{l = 1}^n \dfrac{\Delta_{k,l}}{\pi_{k,l}} \frac{x_k}{\pi_k} \frac{x_l}{\pi_l}
\]</span></p>
<p>Para demostrar que el estimador es insesgado tomamos el valor esperado y agregamos las variables indicadoras correspondientes:</p>
<p><span class="math display">\[
\widehat{\textrm{Var}}(\hat{t})  = \sum\limits_{k = 1}^N \sum\limits_{l = 1}^N \dfrac{\Delta_{k,l}}{\pi_{k,l}} \frac{x_k}{\pi_k} \frac{x_l}{\pi_l} \mathbb{I}_{\mathcal{S}}(x_k) \mathbb{I}_{\mathcal{S}}(x_l) 
\]</span>
Se sigue la demostración:</p>
<p><span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
\mathbb{E}\Big[\widehat{\textrm{Var}}(\hat{t})  \Big] &amp; = \mathbb{E}\bigg[ \sum\limits_{k = 1}^N \sum\limits_{l = 1}^N \dfrac{\Delta_{k,l}}{\pi_{k,l}} \frac{x_k}{\pi_k} \frac{x_l}{\pi_l} \mathbb{I}_{\mathcal{S}}(x_k) \mathbb{I}_{\mathcal{S}}(x_l) \bigg] \\
&amp; = \sum\limits_{k = 1}^N \sum\limits_{l = 1}^N \dfrac{\Delta_{k,l}}{\pi_{k,l}} \frac{x_k}{\pi_k} \frac{x_l}{\pi_l} \underbrace{\mathbb{E}\bigg[  \mathbb{I}_{\mathcal{S}}(x_k) \mathbb{I}_{\mathcal{S}}(x_l) \bigg]}_{*} \\
\end{aligned}
\end{equation}\]</span>
donde notamos que:</p>
<p><span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
* = \mathbb{E}\bigg[  \mathbb{I}_{\mathcal{S}}(x_k) \mathbb{I}_{\mathcal{S}}(x_l) \bigg] &amp; = \textrm{Cov}\Big( \mathbb{I}_{\mathcal{S}}(x_k), \mathbb{I}_{\mathcal{S}}(x_l) \Big) + \mathbb{E}\Big[ \mathbb{I}_{\mathcal{S}}(x_k)\Big] \mathbb{E}\Big[ \mathbb{I}_{\mathcal{S}}(x_l)\Big] \\ &amp; = \pi_{k,l} - \pi_k \pi_l + \pi_k\pi_l 
\\ &amp; = \pi_{k,l}
\end{aligned}
\end{equation}\]</span></p>
<p>de donde se sigue:</p>
<p><span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
\mathbb{E}\Big[\widehat{\textrm{Var}}(\hat{t})  \Big] &amp; = \sum\limits_{k = 1}^N \sum\limits_{l = 1}^N \dfrac{\Delta_{k,l}}{\pi_{k,l}} \frac{x_k}{\pi_k} \frac{x_l}{\pi_l}\underbrace{ \pi_{k,l}}_{*} 
\\ &amp; = \sum\limits_{k = 1}^N \sum\limits_{l = 1}^N \Delta_{k,l} \frac{x_k}{\pi_k} \frac{x_l}{\pi_l} = \textrm{Var}(\hat{t})
\end{aligned}
\end{equation}\]</span></p>
<p>Podemos calcular la varianza estimada para una muestra aleatoria simple sin reemplazo como sigue (ver ejercicio):</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb12-1"></a>f        &lt;-<span class="st"> </span>n<span class="op">/</span>N</span>
<span id="cb12-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb12-2"></a>varianza &lt;-<span class="st"> </span>N<span class="op">^</span><span class="dv">2</span><span class="op">*</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>f)<span class="op">/</span>n<span class="op">*</span><span class="kw">var</span>(muestra)</span>
<span id="cb12-3"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb12-3"></a><span class="kw">print</span>(varianza)</span></code></pre></div>
<pre><code>## [1] 9111.674</code></pre>
<p><em>Observaciones</em></p>
<ol style="list-style-type: decimal">
<li><p>La media muestral <span class="math inline">\(\bar{x}_{\mathcal{S}} = \frac{1}{n}\sum\limits_{i = 1}^{n} x_i\)</span> es un estimador insesgado de la media poblacional <span class="math inline">\(\bar{x}_{\mathcal{U}} = \frac{1}{N}\sum\limits_{i = 1}^{N} x_i\)</span>. Se sigue de una factorización de <span class="math inline">\(n\)</span> del total (<span class="math inline">\(t\)</span> y <span class="math inline">\(\hat{t}\)</span> respectivamente).</p></li>
<li><p>Se puede obtener <span class="math inline">\(\textrm{Var}(\bar{x}_{\mathcal{S}})\)</span> y <span class="math inline">\(\widehat{\textrm{Var}}(\bar{x}_{\mathcal{S}})\)</span> factorizando las <span class="math inline">\(n\)</span> de manera cuadrática del <span class="math inline">\(\hat{t}\)</span>.</p></li>
</ol>
<div id="ejercicio-1" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Ejercicio</h3>
<p>Definimos:
<span class="math display">\[
s_{x,\mathcal{U}}^2 = \dfrac{1}{N-1} \sum\limits_{k = 1}^N \big( x_k - \bar{x}_{\mathcal{U}})^2
\]</span>
como la <strong>varianza poblacional ajustada</strong> y
<span class="math display">\[
s_{x,\mathcal{S}}^2 = \dfrac{1}{n-1} \sum\limits_{k = 1}^n \big( x_k - \bar{x}_{\mathcal{S}})^2
\]</span>
como la <strong>varianza muestral ajustada</strong>. Sea <span class="math inline">\(f = \frac{n}{N}\)</span> la <strong>fracción muestral</strong>. Demuestra que en el caso de muestreo aleatorio simple sin reemplazo:
<span class="math display">\[
\textrm{Var}(\hat{t}) = N^2\dfrac{1-f}{n} s^2_{x,\mathcal{U}}
\]</span>
mientras que el estimador insesgado se transforma en:
<span class="math display">\[
\widehat{\textrm{Var}}(\hat{t}) = N^2\dfrac{1-f}{n} s^2_{x,\mathcal{S}}
\]</span></p>
</div>
</div>
<div id="teorema-del-límite-central-aplicación" class="section level2">
<h2><span class="header-section-number">5.2</span> Teorema del Límite Central (Aplicación)</h2>
<!--En esta sección haremos una pequeña disgresión hacia temas de Probabilidad II. Como ésta no es requisito para la materia, veremos algunas demostraciones que se ven en dicho curso y un resultado que se obtiene en el mismo. Éste nos permitirá hablar de intervalos de confianza: intervalos aleatorios donde con cierta probabilidad aparece el valor deseado. Existen varios **teoremas de límite central** los cuales establecen comportamientos para sumas de variables aleatorias. Si bien, los resultados que aquí veamos se pueden generalizar a resultados no independientes a [variables intercambiables](https://projecteuclid.org/euclid.aop/1176992260), o [a muestro de poblaciones finitas](https://amstat.tandfonline.com/doi/abs/10.1198/000313001753272330#.XvrQlSFR3OQ) (no necesariamente independientes) plantearemos los teoremas y sus pruebas para variables aleatorias independientes con media y varianza finita (a fin de simplificar las demostraciones). Las demostraciones de los teoremas que en realidad aplican para nuestros casos pueden obtenerse de [Rosen](https://projecteuclid.org/download/pdf_1/euclid.afm/1485893466), -->
<p>En esta sección hablaremos del teorema central del límite correspondiente a muestreo aleatorio simple con poblaciones finitas. Éste no es el mismo que el de Proba 2 (en términos de hipótesis) aunque las conclusiones sean las mismas. El teorema de Proba 2 establece que si se tiene una colección <span class="math inline">\(\{ X_i \}\)</span> de variables aleatorias independientes idénticamente distribuidas (todas con distribución acumulada <span class="math inline">\(F_X\)</span>) con media <span class="math inline">\(\mu\)</span> y varianza <span class="math inline">\(\sigma^2 &lt; \infty\)</span>, entonces, si definimos <span class="math inline">\(Z\)</span> como:</p>
<p><span class="math display">\[
Z =\lim_{n \to \infty} \sqrt{\dfrac{n}{\sigma^2}} \cdot  \Big( \frac{1}{n}\sum_{i = 1}^n X_i - \mu\Big)
\]</span>
se tiene que <span class="math inline">\(Z \sim \textrm{Normal}(0,1)\)</span>.</p>
<p>En este teorema central podemos observar que hay algo muy parecido a la media muestral embebido en el teorema (la <span class="math inline">\(\frac{1}{n}\sum_{i = 1}^n X_i\)</span>) <em>pero</em> no es exactamente la media muestral (aquí se supone que todas las <span class="math inline">\(X_i\)</span> son independientes con distribución <span class="math inline">\(F_X\)</span> y en el caso de muestreo aleatorio sin reemplazo se sabe que las indicadoras <strong>NO</strong> son independientes y que de hecho tampoco son idénticamente distribuidas cuando analizamos <span class="math inline">\(\sum_{i = 1}^{n} x_i \mathbb{I}_{\mathcal{S}}(x_i)\)</span>). Entonces <em>técnicamente</em> no podemos aplicar el teorema central del límite así como está a nuestra muestra. Sin embargo, Hàjek (y más tarde <a href="https://projecteuclid.org/download/pdf_1/euclid.afm/1485893466">Rosen</a> ) encontraron condiciones <em>sin tener que pedir independencia ni distribución idéntica</em> que permiten sustituir las <span class="math inline">\(X_i\)</span> por las de la media muestral (<span class="math inline">\(x_i \mathbb{I}_{\mathcal{S}}(x_i)\)</span>) y que, cuando <span class="math inline">\(N\)</span> y <span class="math inline">\(n\)</span> tienden a infinito “de buena manera”, se tiene algo similar a esta expresión (<strong>OJO</strong> no es una expresión <em>correcta</em> pero es la idea):</p>
<p><span class="math display">\[
Z =\lim_{N, n \to \infty} \sqrt{\frac{1}{\textrm{Var}(\bar{x}_{\mathcal{S}})}} \cdot  \Big( \frac{1}{n}\sum_{i = 1}^N x_i \mathbb{I}_{\mathcal{S}}(x_i) - \bar{x}_{\mathcal{U}}\Big)
\]</span>
donde <span class="math inline">\(\mu = \sum_{k = 1}^N x_k\)</span> es la media poblacional y <span class="math inline">\(\sigma^2 = \frac{1}{N} \sum_{k = 1}^N (x_k - \mu)^2\)</span> la varianza poblacional no ajustada. La demostración propia de este teorema la posponemos para una sección posterior. Por ahora, ejemplificaremos el teorema del límite central en <code>R</code>, utilizaremos la expresión anterior para deducir y explicar el concepto de intervalo de confianza y, finalmente, haremos un ejemplo de estimación de intervalo.</p>
<div id="programación-en-r-del-teorema-del-límite-central-con-variables-aleatorias-independientes-idénticamente-distribuidas" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Programación en <code>R</code> del teorema del límite central con variables aleatorias independientes idénticamente distribuidas</h3>
<p>Lo que programaremos (por facilidad) en esta sección corresponde a ejemplos del teorema de proba 2: dadas variables aleatorias independientes idénticamente <span class="math inline">\(\{X_i\}\)</span> distribuidas con media <span class="math inline">\(\mu\)</span> y varianza finita <span class="math inline">\(\sigma^2\)</span> tenemos que:</p>
<p><span class="math display">\[
Z =\lim_{n \to \infty} \sqrt{\dfrac{n}{\sigma^2}} \cdot  \Big( \frac{1}{n}\sum_{i = 1}^n X_i - \mu\Big) \sim \textrm{Normal}(0,1)
\]</span>
donde el símbolo <span class="math inline">\(\sim\)</span> se lee “se distribuye”. En este caso la interpretación va a ser que para <span class="math inline">\(n\)</span> muy grande tendremos que
<span class="math display">\[
\sqrt{\dfrac{n}{\sigma^2}} \cdot  \Big( \frac{1}{n}\sum_{i = 1}^n X_i - \mu\Big) \mathrel{\dot\sim} \textrm{Normal}(0,1)
\]</span></p>
<p>donde <span class="math inline">\(\mathrel{\dot\sim}\)</span> se lee como “se distribuye aproximadamente”. Programaremos una función en <code>R</code> que para <span class="math inline">\(n\)</span> grande muestre eso:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-1"></a>TeoremaCentralLimite &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">numero_simulaciones =</span> <span class="dv">1000</span>, </span>
<span id="cb14-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-2"></a>                                 <span class="dt">n =</span> <span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">100</span>,<span class="dv">1000</span>,<span class="dv">10000</span>), </span>
<span id="cb14-3"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-3"></a>                                 <span class="dt">distribucion =</span> rpois, <span class="dt">mu =</span> <span class="dv">1</span>, <span class="dt">sigma =</span> <span class="dv">1</span>, </span>
<span id="cb14-4"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-4"></a>                                 <span class="dt">bins =</span> <span class="dv">50</span>, </span>
<span id="cb14-5"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-5"></a>                                 <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">distname =</span> <span class="st">&quot;Poisson(1)&quot;</span>, </span>
<span id="cb14-6"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-6"></a>                                 <span class="dt">rcolor =</span> <span class="kw">sample</span>(<span class="kw">rainbow</span>(<span class="dv">100</span>),<span class="dv">1</span>), ...){</span>
<span id="cb14-7"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-7"></a>  <span class="co">#Creamos</span></span>
<span id="cb14-8"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-8"></a>  plot_list &lt;-<span class="st"> </span><span class="kw">list</span>()</span>
<span id="cb14-9"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-9"></a>  </span>
<span id="cb14-10"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-10"></a>  <span class="cf">for</span> (k <span class="cf">in</span> n){</span>
<span id="cb14-11"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-11"></a>    </span>
<span id="cb14-12"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-12"></a>    <span class="co">#Guardamos las Zi en un vector</span></span>
<span id="cb14-13"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-13"></a>    Z &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, numero_simulaciones)</span>
<span id="cb14-14"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-14"></a>    </span>
<span id="cb14-15"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-15"></a>    <span class="co">#Simulamos todas las simulaciones</span></span>
<span id="cb14-16"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-16"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>numero_simulaciones){</span>
<span id="cb14-17"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-17"></a>      simulaciones_X &lt;-<span class="st"> </span><span class="kw">distribucion</span>(<span class="dt">n =</span> k, ...)</span>
<span id="cb14-18"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-18"></a>      Z[i]         &lt;-<span class="st"> </span><span class="kw">sqrt</span>(k)<span class="op">*</span>(<span class="kw">sum</span>(simulaciones_X<span class="op">/</span>k) <span class="op">-</span><span class="st"> </span>mu)</span>
<span id="cb14-19"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-19"></a>    }</span>
<span id="cb14-20"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-20"></a>    </span>
<span id="cb14-21"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-21"></a>    <span class="co">#Graficación</span></span>
<span id="cb14-22"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-22"></a>    x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(Z)<span class="op">-</span><span class="dv">1</span>, <span class="kw">max</span>(Z) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb14-23"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-23"></a>    y &lt;-<span class="st"> </span><span class="kw">dnorm</span>(x, <span class="dt">sd =</span> sigma)</span>
<span id="cb14-24"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-24"></a>    plot_list &lt;-<span class="st"> </span><span class="kw">list.append</span>(</span>
<span id="cb14-25"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-25"></a>      plot_list, </span>
<span id="cb14-26"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-26"></a>      <span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb14-27"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-27"></a><span class="st">      </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Z, <span class="dt">y =</span> ..density..), <span class="dt">bins =</span> bins, <span class="dt">fill =</span> rcolor, </span>
<span id="cb14-28"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-28"></a>                     <span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">Z =</span> Z)) <span class="op">+</span></span>
<span id="cb14-29"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-29"></a><span class="st">      </span><span class="kw">geom_line</span>(<span class="kw">aes_string</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y), <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span></span>
<span id="cb14-30"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-30"></a><span class="st">      </span><span class="kw">ggtitle</span>(<span class="kw">paste0</span>(<span class="st">&quot;Simulaciones con &quot;</span>, distname,<span class="st">&quot;</span><span class="ch">\n</span><span class="st">n = &quot;</span>, k)) <span class="op">+</span></span>
<span id="cb14-31"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-31"></a><span class="st">      </span><span class="kw">xlab</span>(<span class="st">&quot;Z&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;Densidad de Z&quot;</span>) <span class="op">+</span></span>
<span id="cb14-32"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-32"></a><span class="st">      </span><span class="kw">theme_bw</span>()</span>
<span id="cb14-33"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-33"></a>    )</span>
<span id="cb14-34"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-34"></a>  }</span>
<span id="cb14-35"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-35"></a>  <span class="kw">do.call</span>(<span class="st">&quot;grid.arrange&quot;</span>, <span class="kw">c</span>(plot_list, <span class="dt">ncol =</span> ncol))</span>
<span id="cb14-36"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb14-36"></a>}</span></code></pre></div>
<p>donde podemos ver la aproximación normal si tomamos, por ejemplo, las <span class="math inline">\(X_i\)</span> siguen una distribución Gamma:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb15-1"></a><span class="kw">TeoremaCentralLimite</span>(<span class="dt">distribucion =</span> rgamma, <span class="dt">mu =</span> <span class="dv">1</span>, <span class="dt">sigma =</span> <span class="fl">0.5</span>, <span class="dt">shape =</span> <span class="dv">2</span>, </span>
<span id="cb15-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb15-2"></a>                     <span class="dt">scale =</span> <span class="fl">0.5</span>, <span class="dt">distname =</span> <span class="st">&quot;Gama(2,1/2)&quot;</span>)</span></code></pre></div>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-11-1.png" width="672" />
La binomial se ve así:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb16-1"></a><span class="kw">TeoremaCentralLimite</span>(<span class="dt">distribucion =</span> rbinom, <span class="dt">mu =</span> <span class="fl">4.5</span>, <span class="dt">sigma =</span> <span class="fl">2.475</span>, <span class="dt">size =</span> <span class="dv">10</span>, </span>
<span id="cb16-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb16-2"></a>                     <span class="dt">prob =</span> <span class="fl">0.45</span>, <span class="dt">distname =</span> <span class="st">&quot;Binomial(10,0.45)&quot;</span>)</span></code></pre></div>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Poisson:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb17-1"></a><span class="kw">TeoremaCentralLimite</span>(<span class="dt">lambda =</span> <span class="dv">1</span>, <span class="dt">distname =</span> <span class="st">&quot;Poisson(1)&quot;</span>)</span></code></pre></div>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>E inclusive uniformes:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb18-1"></a><span class="kw">TeoremaCentralLimite</span>(<span class="dt">distribucion =</span> runif, <span class="dt">mu =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">sigma =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">12</span>, </span>
<span id="cb18-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb18-2"></a>                     <span class="dt">distname =</span> <span class="st">&quot;Uniforme(0,1)&quot;</span>)</span></code></pre></div>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Experimenta con otras distribuciones ¿puedes encontrar alguna para la que no funcione?</p>
</div>
<div id="ejercicio-2" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Ejercicio</h3>
<p>Repite la programación del teorema del límite central pero ahora tomando las <span class="math inline">\(X_k\)</span> con distintas distribuciones siempre y cuando <span class="math inline">\(X_k\)</span> tenga media <span class="math inline">\(\mu_k\)</span> finita y las variables aleatorias satisfagan la <a href="https://en.wikipedia.org/wiki/Lindeberg%27s_condition">condición de Lindberg</a> (una forma de hacerlo es teniendo varianzas finitas que no incrementan con la <span class="math inline">\(k\)</span>).</p>
</div>
<div id="estimación-de-intervalos-de-confianza-para-el-total" class="section level3">
<h3><span class="header-section-number">5.2.3</span> Estimación de intervalos de confianza para el total</h3>
<p>Un intervalo de confianza de <span class="math inline">\((1 - \alpha)\times 100 \%\)</span> de un estimador poblacional desconocido <span class="math inline">\(\theta = \theta(x_1, x_2, \dots, x_N)\)</span> (constante) es un intervalo aleatorio de la forma <span class="math inline">\(\big[ L(\mathcal{S}), U(\mathcal{S}) \big]\)</span> (donde <span class="math inline">\(L, U\)</span> son variables aleatorias que dependen de la muestra) tal que
<span class="math display">\[
\mathbb{P}\Big( \theta \in \big[ L(\mathcal{S}), U(\mathcal{S}) \big]\Big) = 1 - \alpha
\]</span>
Notamos que lo aleatorio del intervalo son las cotas del mismo y que, dadas distintas muestras <span class="math inline">\(\mathcal{S}\)</span> el valor de interés <span class="math inline">\(\theta\)</span> no siempre va a caer ahí. La idea de un intervalo es poder dar una cota de más o menos dónde anda un valor. Veamos un ejemplo con el total.</p>
<p>Recordamos que el estimador del total es insesgado <span class="math inline">\(\mathbb{E}\big[ \hat{t} \big] = t\)</span> y que por definición:
<span class="math display">\[
\hat{t} = N \frac{1}{n}\sum\limits_{i = 1}^N x_i \cdot \mathbb{I}_{\mathcal{S}}(x_i) 
\]</span></p>
<p>luego usando la versión de muestreo finito del teorema central del límite (factorizando <span class="math inline">\(N\)</span>) tenemos que:</p>
<p><span class="math display">\[
\sqrt{\frac{1}{\textrm{Var}(\bar{x}_{\mathcal{S}})}} \cdot  \Big( \frac{1}{n}\sum_{i = 1}^N x_i \mathbb{I}_{\mathcal{S}}(x_i) - \bar{x}_{\mathcal{U}}\Big) = 
 \cdot  N\dfrac{\Big( \frac{1}{n}\sum_{i = 1}^N x_i \mathbb{I}_{\mathcal{S}}(x_i) - \bar{x}_{\mathcal{U}}\Big)}{N\sqrt{\textrm{Var}(\bar{x}_{\mathcal{S}})}}
=  \dfrac{\hat{t} - t}{\sqrt{\textrm{Var}(\hat{t})}}  \mathrel{\dot\sim} \textrm{Normal}(0,1)
\]</span>
De donde se sigue que si se desea tener un intervalo de tamali <span class="math inline">\((1 - \alpha) \times 100 \%\)</span> lo que hay que hacer es buscar <span class="math inline">\(L(\mathcal{S})\)</span> y <span class="math inline">\(U(\mathcal{S})\)</span> tales que:</p>
<p><span class="math display">\[
\mathbb{P}\Bigg( L(\mathcal{S}) \leq \dfrac{\hat{t} - t}{\sqrt{\textrm{Var}(\hat{t})}} \leq U(\mathcal{S}) \Bigg) = 1 - \alpha
\]</span>
En este caso las probabilidades (por aproximación asintótica) se modelan bajo la hipótesis de normalidad. Y tomamos ventaja de que la normal es simétrica respecto a la media para proponer que <span class="math inline">\(L(\mathcal{S}) = -U(\mathcal{S})\)</span> y ambas correspondan a <span class="math inline">\(\pm \Phi^{-1}(\alpha/2)\)</span> (la función de distirbución acumulada inversa de la normal). Es decir, ambos deben corresponder a los cuantiles con probabilidad <span class="math inline">\(\alpha/2\)</span> y <span class="math inline">\(1 - \alpha/2\)</span>, denotados <span class="math inline">\(z_{\alpha/2}\)</span> y <span class="math inline">\(z_{1 - \alpha/2}\)</span>. Por simetría de la normal tenemos que: <span class="math inline">\(z_{\alpha/2} = - z_{1 - \alpha/2}\)</span> y por tanto:
<span class="math display">\[
\mathbb{P}\Bigg( z_{\alpha/2} \leq \dfrac{\hat{t} - t}{\sqrt{\textrm{Var}(\hat{t})}} \leq  z_{1 -\alpha/2} \Bigg) = 1 - \alpha
\]</span>
de donde despejamos:
<span class="math display">\[
\mathbb{P}\Bigg( z_{\alpha/2}\sqrt{\textrm{Var}(\hat{t})} \leq \hat{t} - t \leq z_{1- \alpha/2}\sqrt{\textrm{Var}(\hat{t})} \Bigg) = \mathbb{P}\Bigg( \hat{t} - z_{1-\alpha/2}\sqrt{\textrm{Var}(\hat{t})} \leq t \leq \hat{t} +  z_{ \alpha/2}\sqrt{\textrm{Var}(\hat{t})} \Bigg)  =  1 - \alpha
\]</span></p>
<p>Notamos que como no conocemos <span class="math inline">\(\textrm{Var}(\hat{t})\)</span> la podemos aproximar mediante <span class="math inline">\(\widehat{\textrm{Var}}(\hat{t})\)</span> (hay mejores aproximaciones mediante una <span class="math inline">\(t\)</span> de Student asintótica pero no lo usaremos ahora) y tener intervalos aproximados de la forma:
<span class="math display">\[\begin{equation}
\begin{aligned}
L(\mathcal{S}) &amp; =  \hat{t} - z_{1-\alpha/2}\sqrt{\widehat{\textrm{Var}}(\hat{t})} \\
U(\mathcal{S}) &amp; =  \hat{t} + z_{1-\alpha/2}\sqrt{\widehat{\textrm{Var}}(\hat{t})}
\end{aligned}
\end{equation}\]</span>
de manera concisa muchas veces los escribimos como:
<span class="math display">\[
 \hat{t} \pm z_{1-\alpha/2}\sqrt{\widehat{\textrm{Var}}(\hat{t})}
\]</span></p>
</div>
<div id="ejemplo-con-simulación" class="section level3">
<h3><span class="header-section-number">5.2.4</span> Ejemplo con simulación:</h3>
<p>Veamos cómo se ven múltiples intervalos simulados con confianza del <span class="math inline">\(90\%\)</span> y suponiendo la varianza es conocida</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-1"></a>nsim &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb19-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-2"></a>n    &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb19-3"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-3"></a></span>
<span id="cb19-4"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-4"></a>total.muestra  &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)</span>
<span id="cb19-5"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-5"></a>confianza.bajo &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)</span>
<span id="cb19-6"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-6"></a>confianza.alto &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, nsim)</span>
<span id="cb19-7"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-7"></a>f &lt;-<span class="st"> </span>n<span class="op">/</span>N</span>
<span id="cb19-8"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-8"></a>z &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.1</span><span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb19-9"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-9"></a></span>
<span id="cb19-10"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-10"></a>var.total      &lt;-<span class="st"> </span>N<span class="op">^</span><span class="dv">2</span><span class="op">*</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>f)<span class="op">/</span>n<span class="op">*</span><span class="kw">var</span>(base.completa<span class="op">$</span>x)</span>
<span id="cb19-11"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-11"></a></span>
<span id="cb19-12"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-12"></a>  </span>
<span id="cb19-13"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-13"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nsim){</span>
<span id="cb19-14"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-14"></a>  muestra           &lt;-<span class="st"> </span><span class="kw">sample</span>(base.completa<span class="op">$</span>x, n, <span class="dt">replace =</span> <span class="ot">FALSE</span>)</span>
<span id="cb19-15"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-15"></a>  total.muestra[i]  &lt;-<span class="st"> </span>N<span class="op">*</span><span class="kw">mean</span>(muestra)</span>
<span id="cb19-16"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-16"></a>  <span class="co">#var.total[i]    &lt;- N^2*(1 - f)/n*var(muestra)</span></span>
<span id="cb19-17"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-17"></a>  confianza.bajo[i] &lt;-<span class="st"> </span>total.muestra[i] <span class="op">-</span><span class="st"> </span>z<span class="op">*</span><span class="kw">sqrt</span>(var.total)</span>
<span id="cb19-18"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-18"></a>  confianza.alto[i] &lt;-<span class="st"> </span>total.muestra[i] <span class="op">+</span><span class="st"> </span>z<span class="op">*</span><span class="kw">sqrt</span>(var.total)</span>
<span id="cb19-19"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-19"></a>}</span>
<span id="cb19-20"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-20"></a></span>
<span id="cb19-21"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-21"></a>intervalos.simulados &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb19-22"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-22"></a>  <span class="dt">Simulacion =</span> <span class="dv">1</span><span class="op">:</span>nsim,</span>
<span id="cb19-23"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-23"></a>  <span class="dt">Intervalo.Bajo =</span> confianza.bajo,</span>
<span id="cb19-24"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-24"></a>  <span class="dt">Total.Estimado =</span> total.muestra,</span>
<span id="cb19-25"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-25"></a>  <span class="dt">Intervalo.Alto =</span> confianza.alto</span>
<span id="cb19-26"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-26"></a>)</span>
<span id="cb19-27"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-27"></a></span>
<span id="cb19-28"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-28"></a><span class="kw">ggplot</span>(intervalos.simulados) <span class="op">+</span></span>
<span id="cb19-29"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-29"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Simulacion, <span class="dt">y =</span> Total.Estimado)) <span class="op">+</span></span>
<span id="cb19-30"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-30"></a><span class="st">  </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Simulacion, <span class="dt">ymin =</span> Intervalo.Bajo, </span>
<span id="cb19-31"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-31"></a>                    <span class="dt">ymax =</span> Intervalo.Alto)) <span class="op">+</span></span>
<span id="cb19-32"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-32"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="kw">aes</span>(<span class="dt">yintercept =</span> <span class="kw">sum</span>(base.completa<span class="op">$</span>x)), </span>
<span id="cb19-33"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-33"></a>             <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>,</span>
<span id="cb19-34"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-34"></a>             <span class="dt">size =</span> <span class="dv">1</span>, <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb19-35"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-35"></a><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></span>
<span id="cb19-36"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb19-36"></a><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Simulación de intervalos de confianza&quot;</span>)</span></code></pre></div>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Nota que estos intervalos son aproximados y no siempre van a funcionar. (¿Puedes hallar un ejemplo donde no sirvan a pesar de que <span class="math inline">\(n\)</span> y <span class="math inline">\(N\)</span> sean grandes?) Luego veremos correcciones a esto; por ahora, supondremos que la aproximación es buena.</p>
</div>
</div>
<div id="ejemplo-resumen-estimación-de-una-proporción-bajo-muestreo-aleatorio-simple-sin-reemplazo" class="section level2">
<h2><span class="header-section-number">5.3</span> Ejemplo Resumen: Estimación de una proporción bajo muestreo aleatorio simple sin reemplazo</h2>
<p>Se realiza una encuesta mediante muestreo aleatorio simple sin reemplazo a la población del ITAM <span class="math inline">\(N = 5000\)</span> donde interesa conocer la proporción de gente que apoya al gobierno en turno <span class="math inline">\(p\)</span>. Implícitamente, se supone que alguien apoya (proporción <span class="math inline">\(p\)</span> de toda la población) o no lo apoya (proporción <span class="math inline">\(1-p\)</span>), que dichos conjuntos son disjuntos y que no hay una tercera opción (como <code>NO RESPONDE / DESCONOCE QUIÉN GOBIERNA</code>). La pregunta es: ¿a cuántas personas hay que encuestar si interesa estimar <span class="math inline">\(p\)</span> con un error máximo de tamaño <span class="math inline">\(\epsilon = 0.05\)</span> al <span class="math inline">\(99\%\)</span> de confianza (es decir, que el estimador <span class="math inline">\(\hat{p}\)</span> de la proporción esté, a lo más, a <span class="math inline">\(\pm 0.05\)</span> de distancia del valor verdadero <span class="math inline">\(p\)</span> con un intervalo de confianza al <span class="math inline">\(99\%\)</span>)?</p>
<p>Supongamos tomamos una muestra de tamaño <span class="math inline">\(n\)</span> dada por <span class="math inline">\(\mathcal{S} = (x_1, x_2, \dots, x_n)^T\)</span> de una población <span class="math inline">\(\mathcal{U} = (x_1, x_2, \dots, x_N)^T\)</span> de tamaño <span class="math inline">\(N\)</span>. Pensemos, además, existen <span class="math inline">\(N_1\)</span> personas que aprueban al gobierno actual y <span class="math inline">\(N- N_1\)</span> que desaprueban del mismo y por tanto la proporción que nos interesa estimar es:
<span class="math display">\[
p = \dfrac{N_1}{N}
\]</span>
Por otro lado, la proporción muestral de personas que aprueban está dada por:
<span class="math display">\[
\hat{p} = \dfrac{\sum_{i = 1}^n \mathbb{I}_{\text{Aprueba}}(x_i)}{n}
\]</span>
donde si definimos <span class="math inline">\(H = \dfrac{\sum_{i = 1}^n \mathbb{I}_{\text{Aprueba}}(x_i)}{n}\)</span> notamos que la distribución de <span class="math inline">\(H\)</span> está dada por una variable <a href="https://en.wikipedia.org/wiki/Hypergeometric_distribution">Hipergeométrica</a> (pues de una población de <span class="math inline">\(N\)</span> se seleccionan <span class="math inline">\(n\)</span> donde <span class="math inline">\(N_1\)</span> cumplen la categoría deseada). Su media y varianza están dadas respectivamente por:
<span class="math display">\[
\mathbb{E}\big[ H \big] = n \dfrac{N_1}{N} = np
\]</span>
así como por:
<span class="math display">\[
\textrm{Var}\big[ H\big] = n \dfrac{N_1}{N} \Big( 1 - \dfrac{N_1}{N}\Big) \Big( \dfrac{N-n}{N-1}\Big) = np (1-p)\Big( \dfrac{N-n}{N-1}\Big)
\]</span>
Se sigue entonces que <span class="math inline">\(\mathbb{E}\big[\hat{p}\big] = p\)</span> y por tanto <span class="math inline">\(\hat{p}\)</span> es un estimador insesgado. La varianza por otro lado es:
<span class="math display">\[
\textrm{Var}\big( \hat{p} \big) = \dfrac{p(1-p)}{n}\Big( \dfrac{N-n}{N-1}\Big)
\]</span>
Finalmente, el estimador de la varianza es:
<span class="math display">\[
\widehat{\textrm{Var}}\big( \hat{p} \big) = \dfrac{\hat{p}(1-\hat{p})}{n}\Big( \dfrac{N-n}{N-1}\Big)
\]</span>
el cual también cumple que es insesgado (demuéstralo).</p>
<p>Podemos aplicar el Teorema Central del Límite para la proporción<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> notando que la definición de <span class="math inline">\(\hat{p}\)</span> coincide con una media (de las indicadoras):
<span class="math display">\[
\underbrace{\dfrac{\hat{p} - p}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n} \Big( \frac{N-n}{N-1} \Big)}}}_{\widehat{\text{Var}}(\hat{p})}\mathrel{\dot\sim} \textrm{Normal}(0,1)
\]</span>
De donde se tiene que:
<span class="math display">\[\begin{equation}
\begin{aligned}
&amp; \mathbb{P}\Bigg(- z_{\alpha/2} \leq \dfrac{\hat{p} - p}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n} \Big( \frac{N-n}{N-1} \Big)}}\leq z_{\alpha/2}\Bigg) \approx 1 - \alpha \\
\Rightarrow &amp; \mathbb{P}\Bigg( \hat{p} - z_{\alpha/2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n} \Big( \frac{N-n}{N-1} \Big)} \leq  p \leq \hat{p} +  z_{\alpha/2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n} \Big( \frac{N-n}{N-1} \Big)}\Bigg) \approx 1 - \alpha 
\end{aligned}
\end{equation}\]</span></p>
<blockquote>
<p><strong>Nota</strong> <a href="https://opentextbc.ca/introbusinessstatopenstax/chapter/a-confidence-interval-for-a-population-proportion/">Es común encontrar en Internet</a> que para los intervalos de confianza la gente supone una población muy grande <span class="math inline">\(N\)</span> respecto a la muestra <span class="math inline">\(n\)</span> y entonces eliminan el término <span class="math inline">\(\frac{N-n}{N-1}\)</span> argumentando que <span class="math inline">\(\frac{N-n}{N-1} \approx 1\)</span> y obtienen la siguiente fórmula:
<span class="math display">\[
\hat{p} \pm z_{\alpha/2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n}} 
\]</span>
esto simplifica algunos cálculos (a mano) pero nosotros tenemos <code>R</code> y podemos hacer cálculos más exactos sin tener que suponer semejantes atrocidades.</p>
</blockquote>
<p>Como el error deseado es de tamaño <span class="math inline">\(\epsilon\)</span> queremos <span class="math inline">\(|p - \hat{p} | \leq \epsilon\)</span> esto se traduce en:
<span class="math display">\[\begin{equation}\nonumber
|p -  \hat{p}| \leq \underbrace{z_{\alpha/2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n} \Big( \frac{N-n}{N-1} \Big) }}_{\epsilon}
\end{equation}\]</span>
de donde igualamos para despejar la <span class="math inline">\(n\)</span>:
<span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
 \epsilon &amp; = z_{\alpha/2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n}\Big( \frac{N-n}{N-1} \Big)} \\
 &amp; = \dfrac{\epsilon^2 }{z_{\alpha/2}^2} = \frac{\hat{p}(1-\hat{p})}{n}\Big( \frac{N-n}{N-1} \Big) \\
 &amp; = \frac{N-1}{\hat{p}(1-\hat{p})}\dfrac{\epsilon^2 }{z_{\alpha/2}^2} =  \frac{N-n}{n} = \frac{N}{n} - 1 \\
 &amp; = \frac{N-1}{\hat{p}(1-\hat{p})}\dfrac{\epsilon^2 }{z_{\alpha/2}^2} + 1 =  \frac{N}{n} \\
 &amp; \Rightarrow n = \dfrac{N}{\frac{N-1}{\hat{p}(1-\hat{p})}\frac{\epsilon^2 }{z_{\alpha/2}^2} + 1} = \dfrac{\frac{z^2_{\alpha/2}}{\epsilon^2}\hat{p}(1-\hat{p})}{\frac{N-1}{N} + \frac{1}{N}\frac{z^2_{\alpha/2}}{\epsilon^2}\hat{p}(1-\hat{p})} = \dfrac{m}{1 + \frac{m-1}{N}}
\end{aligned}
\end{equation}\]</span>
donde
<span class="math display">\[
m = \frac{z^2_{\alpha/2}}{\epsilon^2}\hat{p}(1-\hat{p})
\]</span>
Ahora el problema es que el tamaño de muestra <span class="math inline">\(n\)</span> depende de la muestra a través de <span class="math inline">\(\hat{p}\)</span> ¡y no hemos tomado la muestra! Para ello entonces analizamos el peor caso que puede ocurrir de <span class="math inline">\(\hat{p}\)</span> de tal forma que obtengamos la <span class="math inline">\(n\)</span> que puede salir con la peor proporción <span class="math inline">\(\hat{p}\)</span> posible. Para ello maximizamos con derivadas:
<span class="math display">\[\begin{equation}\nonumber
    \begin{aligned}
    \dfrac{\partial n}{\partial \hat{p}} &amp; = \dfrac{\partial}{\partial \hat{p}} \Bigg(  \dfrac{N}{\frac{N-1}{\hat{p}(1-\hat{p})}\frac{\epsilon^2 }{z_{\alpha/2}^2} + 1} \Bigg) 
    \\ &amp; = N  \Bigg(  \dfrac{1}{\frac{N-1}{\hat{p}(1-\hat{p})}\frac{\epsilon^2 }{z_{\alpha/2}^2} + 1} \Bigg)^2 \cdot \dfrac{\partial}{\partial \hat{p}} \Bigg( \frac{N-1}{\hat{p}(1-\hat{p})}\frac{\epsilon^2 }{z_{\alpha/2}^2} + 1\Bigg)  
    \\ &amp; = \underbrace{N (N-1)\frac{\epsilon^2 }{z_{\alpha/2}^2}}_{C}  \Bigg(  \dfrac{1}{\frac{N-1}{\hat{p}(1-\hat{p})}\frac{\epsilon^2 }{z_{\alpha/2}^2} + 1} \Bigg)^2 \cdot \dfrac{\partial}{\partial \hat{p}} \Bigg( \frac{1}{\hat{p}(1-\hat{p})}\Bigg)  
    \\ &amp; = C \Bigg(  \dfrac{1}{\frac{N-1}{\hat{p}(1-\hat{p})}\frac{\epsilon^2 }{z_{\alpha/2}^2} + 1} \Bigg)^2  \Bigg( \frac{1}{\hat{p}(1-\hat{p})}\Bigg)^2 \dfrac{\partial}{\partial \hat{p}} \hat{p}(1-\hat{p}) 
    \\ &amp; = C \Bigg(  \dfrac{1}{\frac{N-1}{\hat{p}(1-\hat{p})}\frac{\epsilon^2 }{z_{\alpha/2}^2} + 1} \Bigg)^2  \Bigg( \frac{1}{\hat{p}(1-\hat{p})}\Bigg)^2  (1-2\hat{p}) = 0
    \end{aligned}
\end{equation}\]</span>
de donde se sigue que <span class="math inline">\(\hat{p} = \frac{1}{2}\)</span> es un punto crítico. De hecho puede verificarse que es el máximo (por ejemplo a través de la segunda derivada). Luego, podemos estimar la <span class="math inline">\(n\)</span> de la muestra mediante:
<span class="math display">\[
n = \left\lceil \dfrac{m}{1 + \frac{m-1}{N}} \right\rceil
\]</span>
donde <span class="math inline">\(m = \dfrac{1}{4}\frac{z^2_{\alpha/2}}{\epsilon^2}\)</span>. En el caso particular de este ejercicio, <span class="math inline">\(N = 5000\)</span>, <span class="math inline">\(\epsilon = 0.05\)</span>, <span class="math inline">\(\alpha = 0.01\)</span> y <span class="math inline">\(z^2_{\alpha/2} \approx\)</span> <code>qnorm(0.9)</code>. Luego podemos calcular:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb20-1"></a>alpha   &lt;-<span class="st"> </span><span class="fl">0.01</span></span>
<span id="cb20-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb20-2"></a>z       &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>alpha<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb20-3"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb20-3"></a>epsilon &lt;-<span class="st"> </span><span class="fl">0.05</span></span>
<span id="cb20-4"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb20-4"></a>m       &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)<span class="op">*</span>(z<span class="op">/</span>epsilon)<span class="op">^</span><span class="dv">2</span></span>
<span id="cb20-5"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb20-5"></a>N       &lt;-<span class="st"> </span><span class="dv">5000</span></span>
<span id="cb20-6"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb20-6"></a>n       &lt;-<span class="st"> </span><span class="kw">ceiling</span>(m<span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(m<span class="dv">-1</span>)<span class="op">/</span>N))</span>
<span id="cb20-7"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb20-7"></a></span>
<span id="cb20-8"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb20-8"></a><span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&quot;El tamaño de muestra es &quot;</span>, n))</span></code></pre></div>
<pre><code>## [1] &quot;El tamaño de muestra es 586&quot;</code></pre>
</div>
<div id="ejemplo-resumen-estimación-del-total-de-individuos-en-una-fotografía" class="section level2">
<h2><span class="header-section-number">5.4</span> Ejemplo Resumen: Estimación del total de individuos en una fotografía</h2>
<p>En este ejercicio vamos a determinar cuánta gente aparece en la siguiente foto:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb22-1"></a>knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;images/concierto.jpg&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-17"></span>
<img src="images/concierto.jpg" alt="Imagen de un concierto extraída de https://www.youtube.com/watch?v=pJ1YKwyH5bk" width="75%" />
<p class="caption">
Figure 5.1: Imagen de un concierto extraída de <a href="https://www.youtube.com/watch?v=pJ1YKwyH5bk" class="uri">https://www.youtube.com/watch?v=pJ1YKwyH5bk</a>
</p>
</div>
<p>Hay varias opciones para determinar la cantidad de gente que está en dicha foto. Una sería contar todas las cabecitas que aparecen; otra, diseñar un modelo de redes neuronales (o de <a href="https://yangliang.github.io/pdf/sp055u.pdf">convolusión</a> porque a la gente le encanta eso) que identifique una cabeza y la cuente. Nosotros lo que haremos (por ser un curso de estadística) será muestrear. Como investigador me interesa responder la siguiente pregunta:</p>
<blockquote>
<p>¿Cuánta gente está en la fotografía con un intervalo de error de <span class="math inline">\(\pm 50\)</span> casos al 95%?</p>
</blockquote>
<p>Para ello dividiremos la fotografía en <span class="math inline">\(N\)</span> pedazos (a determinar), muestrearemos <span class="math inline">\(n\)</span> de ellos y contaremos la cantidad de personas que aparecen en cada pedazo. Finalmente, generamos intervalos de confianza y de muestreo. Para ello repetimos el ejercicio anterior de despejar la <span class="math inline">\(n\)</span> del intervalo de confianza; por el teorema del límite central tenemos:</p>
<p><span class="math display">\[
\dfrac{\hat{t} - t}{\sqrt{\textrm{Var}(\hat{t})}} ~\sim \textrm{Normal}(0,1)
\]</span>
de donde obtenemos intervalos (¡verifícalo!) de la forma:
<span class="math display">\[
 \hat{t} \pm z_{1-\alpha/2}\cdot\sqrt{\textrm{Var}(\hat{t})} 
\]</span>
Donde podemos aproximar la varianza mediante <span class="math inline">\(\widehat{\text{Var}}(\hat{t}) = N^2\dfrac{1-f}{n} s^2_{x,\mathcal{S}}\)</span> donde recordamos que <span class="math inline">\(f = n/N\)</span> y <span class="math inline">\(s^2_{x,\mathcal{S}}\)</span> es la varianza muestral. Tomamos <span class="math inline">\(\epsilon = 50\)</span> y despejamos:</p>
<p><span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
 \epsilon &amp; =  z_{1-\alpha/2}\cdot\sqrt{\textrm{Var}(\hat{t})} \\
 \Rightarrow \dfrac{\epsilon^2}{z_{1-\alpha/2}^2} &amp; = N^2\dfrac{1-f}{n} s^2_{x,\mathcal{S}}   \\
 \Rightarrow \dfrac{\epsilon^2}{z_{1-\alpha/2}^2 s^2_{x,\mathcal{S}} N^2} &amp; = \dfrac{1-\frac{n}{N}}{n} \\
 \Rightarrow \dfrac{\epsilon^2}{z_{1-\alpha/2}^2 s^2_{x,\mathcal{S}} N^2} &amp; = \dfrac{1}{n} - \dfrac{1}{N} \\
 \Rightarrow \dfrac{\epsilon^2}{z_{1-\alpha/2}^2 s^2_{x,\mathcal{S}} N^2} + \dfrac{1}{N} &amp; = \dfrac{1}{n}  \\
 \Rightarrow \dfrac{1}{N} \Bigg( \dfrac{\epsilon^2}{z_{1-\alpha/2}^2 s^2_{x,\mathcal{S}} N} + 1 \Bigg) &amp; = \dfrac{1}{n}  \\
  \Rightarrow \dfrac{1}{N} \Bigg( \dfrac{\epsilon^2 + z_{1-\alpha/2}^2 s^2_{x,\mathcal{S}} N}{z_{1-\alpha/2}^2 s^2_{x,\mathcal{S}} N} \Bigg) &amp; = \dfrac{1}{n}  \\
  \Rightarrow  \Bigg( \dfrac{(z_{1-\alpha/2} s_{x,\mathcal{S}} N)^2} {\epsilon^2 + z_{1-\alpha/2}^2 s^2_{x,\mathcal{S}} N}\Bigg) &amp; = n  \\
\end{aligned}
\end{equation}\]</span></p>
<p>El problema aquí es que la <span class="math inline">\(n\)</span> depende de la varianza muestral <span class="math inline">\(s^2_{x,\mathcal{S}}\)</span> (actualmente desconocida) así como de la cantidad de cuadritos originales <span class="math inline">\(N\)</span> en los que dividimos la foto. Hay en la literatura varias técnicas que se pueden utilizar para estimar el <span class="math inline">\(s^2_{x,\mathcal{S}}\)</span>:</p>
<ol style="list-style-type: decimal">
<li><p>Realizar un estudio piloto (es decir un pequeño ejemplo de lo que vas a hacer en una población chica y de ahí tener la varianza). Esta es la mejor opción.</p></li>
<li><p>Buscar otros estudios similares donde se analicen objetos similares de estudio y ver sus varianzas; suponer que la de este estudio es similar. Esta es la segunda mejor opción.</p></li>
<li><p>Inventártela (sí, es una opción pero no la mejor). Vamos, ¿cuál es la probabilidad de que nadie en todo el mundo haya hecho un análisis similar al tuyo? Si realmente estás haciendo algo completamente nuevo <em>sin estudio piloto</em> pues… podrías inventarla. ¿Lo recomiendo? No; pero pasa.</p></li>
</ol>
<p>En nuestro caso utilizaremos la varianza estimada <a href="https://arxiv.org/pdf/1903.07427.pdf">de este artículo</a> reportada en <span class="math inline">\(1.02\)</span>; luego <span class="math inline">\(s^2_{x,\mathcal{S}} \approx 1.02\)</span> para nuestro análisis.</p>
<p>Finalmente, como éste es sólo un ejercicio de clase tomaremos <span class="math inline">\(N = 100\)</span> (dividir la foto en <span class="math inline">\(100\)</span> cuadritos). De manera profesional, de nuevo habría que ver diferencias en los resultados de las estimaciones en función de los cuadritos, o bien asignar un costo a la cantidad de cuadros. Concluimos entonces que para nuestro estudio:</p>
<p><span class="math display">\[
n = \left\lceil \dfrac{(z_{1-\alpha/2} s_{x,\mathcal{S}} N)^2} {\epsilon^2 + z_{1-\alpha/2}^2 s^2_{x,\mathcal{S}} N}\right\rceil  = \left\lceil \dfrac{(1.95\cdot \sqrt{1.02} \cdot 100)^2} {50^2 + 1.95^2\cdot 1.02 \cdot 100}\right\rceil
\]</span>
Podemos calcular en <code>R</code>:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb23-1"></a>n &lt;-<span class="st"> </span><span class="kw">ceiling</span>((<span class="kw">qnorm</span>(<span class="fl">0.975</span>)<span class="op">*</span><span class="kw">sqrt</span>(<span class="fl">1.02</span>)<span class="op">*</span><span class="dv">100</span>)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>(<span class="dv">50</span><span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>(<span class="kw">qnorm</span>(<span class="fl">0.975</span>)<span class="op">^</span><span class="dv">2</span><span class="op">*</span><span class="fl">1.02</span><span class="op">*</span><span class="dv">100</span>)))</span>
<span id="cb23-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb23-2"></a><span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&quot;El tamaño de muestra es &quot;</span>, n))</span></code></pre></div>
<pre><code>## [1] &quot;El tamaño de muestra es 14&quot;</code></pre>
<p>Podemos proceder a dividir la foto en los <span class="math inline">\(N = 100\)</span> pedazos:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-1"></a><span class="co">#División con base en el siguiente link:</span></span>
<span id="cb25-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-2"></a><span class="co">#https://rpubs.com/issactoast/cutimage</span></span>
<span id="cb25-3"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-3"></a><span class="kw">library</span>(imager)</span>
<span id="cb25-4"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-4"></a></span>
<span id="cb25-5"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-5"></a><span class="co">#Cargamos la imagen</span></span>
<span id="cb25-6"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-6"></a>img &lt;-<span class="st"> </span><span class="kw">load.image</span>(<span class="st">&quot;images/concierto.jpg&quot;</span>)</span>
<span id="cb25-7"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-7"></a></span>
<span id="cb25-8"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-8"></a><span class="co">#Función auxiliar del link superior</span></span>
<span id="cb25-9"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-9"></a>make.vr &lt;-<span class="st"> </span><span class="cf">function</span>( x, name ){</span>
<span id="cb25-10"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-10"></a>  <span class="kw">assign</span>( name, x, <span class="dt">envir =</span> .GlobalEnv)</span>
<span id="cb25-11"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-11"></a>}</span>
<span id="cb25-12"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-12"></a></span>
<span id="cb25-13"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-13"></a><span class="co">#División en N</span></span>
<span id="cb25-14"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-14"></a>N &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb25-15"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-15"></a><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="kw">sqrt</span>(N),<span class="kw">sqrt</span>(N)), <span class="dt">mar =</span> <span class="kw">c</span>(<span class="fl">0.1</span>,<span class="fl">0.1</span>,<span class="fl">0.1</span>,<span class="fl">0.1</span>))</span>
<span id="cb25-16"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-16"></a>k &lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb25-17"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-17"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">sqrt</span>(N)){</span>
<span id="cb25-18"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-18"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">sqrt</span>(N)){</span>
<span id="cb25-19"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-19"></a>    vr.name &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;sub&quot;</span>, k)</span>
<span id="cb25-20"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-20"></a>    k       &lt;-<span class="st"> </span>k <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb25-21"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-21"></a>    <span class="kw">imsub</span>(img, (width<span class="op">/</span><span class="kw">sqrt</span>(N))<span class="op">*</span>(i<span class="dv">-1</span>) <span class="op">&lt;</span><span class="st"> </span>x <span class="op">&amp;</span><span class="st"> </span>x <span class="op">&lt;</span><span class="st">  </span>i <span class="op">*</span><span class="st"> </span>(width<span class="op">/</span><span class="kw">sqrt</span>(N)),</span>
<span id="cb25-22"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-22"></a>          (height<span class="op">/</span><span class="kw">sqrt</span>(N))<span class="op">*</span>(j<span class="dv">-1</span>) <span class="op">&lt;</span><span class="st"> </span>y <span class="op">&amp;</span><span class="st"> </span>y <span class="op">&lt;</span><span class="st">  </span>j <span class="op">*</span><span class="st"> </span>(height<span class="op">/</span><span class="kw">sqrt</span>(N))) <span class="op">%&gt;%</span></span>
<span id="cb25-23"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-23"></a><span class="st">      </span><span class="kw">make.vr</span>(<span class="dt">name =</span> vr.name) <span class="op">%&gt;%</span></span>
<span id="cb25-24"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-24"></a><span class="st">      </span><span class="co"># save.image( file = paste0(vr.name,&quot;.jpg&quot;)) %&gt;%</span></span>
<span id="cb25-25"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-25"></a><span class="st">      </span><span class="kw">plot</span>(<span class="dt">axes =</span> <span class="ot">FALSE</span>,</span>
<span id="cb25-26"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-26"></a>           <span class="dt">xaxt=</span><span class="st">&quot;n&quot;</span>, <span class="dt">yaxt=</span><span class="st">&quot;n&quot;</span>, </span>
<span id="cb25-27"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-27"></a>           <span class="dt">xlab =</span> <span class="st">&quot;&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="dt">ann =</span> <span class="ot">FALSE</span> )    </span>
<span id="cb25-28"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-28"></a>  }</span>
<span id="cb25-29"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb25-29"></a>}</span></code></pre></div>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>Podemos acceder a cada una de las imágenes que se tienen a través de su nombre (<code>sub</code> seguido de un número entre <span class="math inline">\(0\)</span> y <span class="math inline">\(100\)</span>). Muestreamos entonces los nombres de las 15 imágenes:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb26-1"></a><span class="co">#Obtenemos los dígitos a muestrear</span></span>
<span id="cb26-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb26-2"></a>imagenes.muestreadas &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, n, <span class="dt">replace =</span> <span class="ot">FALSE</span>)</span>
<span id="cb26-3"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb26-3"></a></span>
<span id="cb26-4"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb26-4"></a><span class="co">#Agregamos el prefijo sub</span></span>
<span id="cb26-5"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb26-5"></a>imagenes.muestreadas &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;sub&quot;</span>, imagenes.muestreadas)</span></code></pre></div>
<p>Y graficamos cada una de ellas:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb27-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb27-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb27-2"></a></span>
<span id="cb27-3"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb27-3"></a><span class="cf">for</span> (imagen <span class="cf">in</span> imagenes.muestreadas){</span>
<span id="cb27-4"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb27-4"></a>  <span class="kw">plot</span>(<span class="kw">get</span>(imagen),  <span class="dt">main =</span> imagen, <span class="dt">axes =</span> <span class="ot">FALSE</span>)</span>
<span id="cb27-5"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb27-5"></a>}</span></code></pre></div>
<p><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-21-1.png" width="50%" style="display: block; margin: auto;" /><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-21-2.png" width="50%" style="display: block; margin: auto;" /><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-21-3.png" width="50%" style="display: block; margin: auto;" /><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-21-4.png" width="50%" style="display: block; margin: auto;" /><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-21-5.png" width="50%" style="display: block; margin: auto;" /><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-21-6.png" width="50%" style="display: block; margin: auto;" /><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-21-7.png" width="50%" style="display: block; margin: auto;" /><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-21-8.png" width="50%" style="display: block; margin: auto;" /><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-21-9.png" width="50%" style="display: block; margin: auto;" /><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-21-10.png" width="50%" style="display: block; margin: auto;" /><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-21-11.png" width="50%" style="display: block; margin: auto;" /><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-21-12.png" width="50%" style="display: block; margin: auto;" /><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-21-13.png" width="50%" style="display: block; margin: auto;" /><img src="Introduccion_a_Muestreo_files/figure-html/unnamed-chunk-21-14.png" width="50%" style="display: block; margin: auto;" />
Para cada una de las imágenes contamos las cabecitas que aparecen:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb28-1"></a>datos &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb28-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb28-2"></a>  <span class="dt">Imagen =</span> imagenes.muestreadas,</span>
<span id="cb28-3"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb28-3"></a>  <span class="dt">Conteo =</span> <span class="kw">c</span>(<span class="dv">13</span>, <span class="dv">11</span>, <span class="dv">9</span>, <span class="dv">14</span>, <span class="dv">9</span>, <span class="dv">15</span>, <span class="dv">14</span>, <span class="dv">10</span>, <span class="dv">1</span>, <span class="dv">22</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">17</span>, <span class="dv">16</span>)</span>
<span id="cb28-4"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb28-4"></a>)</span>
<span id="cb28-5"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb28-5"></a><span class="kw">kable</span>(datos) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">kable_styling</span>(<span class="dt">latex_options =</span> <span class="st">&quot;striped&quot;</span>)</span></code></pre></div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Imagen
</th>
<th style="text-align:right;">
Conteo
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
sub63
</td>
<td style="text-align:right;">
13
</td>
</tr>
<tr>
<td style="text-align:left;">
sub17
</td>
<td style="text-align:right;">
11
</td>
</tr>
<tr>
<td style="text-align:left;">
sub82
</td>
<td style="text-align:right;">
9
</td>
</tr>
<tr>
<td style="text-align:left;">
sub39
</td>
<td style="text-align:right;">
14
</td>
</tr>
<tr>
<td style="text-align:left;">
sub81
</td>
<td style="text-align:right;">
9
</td>
</tr>
<tr>
<td style="text-align:left;">
sub50
</td>
<td style="text-align:right;">
15
</td>
</tr>
<tr>
<td style="text-align:left;">
sub72
</td>
<td style="text-align:right;">
14
</td>
</tr>
<tr>
<td style="text-align:left;">
sub51
</td>
<td style="text-align:right;">
10
</td>
</tr>
<tr>
<td style="text-align:left;">
sub29
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
sub94
</td>
<td style="text-align:right;">
22
</td>
</tr>
<tr>
<td style="text-align:left;">
sub91
</td>
<td style="text-align:right;">
8
</td>
</tr>
<tr>
<td style="text-align:left;">
sub22
</td>
<td style="text-align:right;">
9
</td>
</tr>
<tr>
<td style="text-align:left;">
sub47
</td>
<td style="text-align:right;">
17
</td>
</tr>
<tr>
<td style="text-align:left;">
sub46
</td>
<td style="text-align:right;">
16
</td>
</tr>
</tbody>
</table>
<p>Tenemos entonces que la estimación del total <span class="math inline">\(\hat{t}\)</span> es: 1200, por otro lado la varianza muestral es <span class="math inline">\(s_{x,\mathcal{S}}\)</span> está dada por: 25.2307692. Podemos entonces establecer un intervalo de confianza para el total:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb29-1"></a>x  &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">13</span>, <span class="dv">11</span>, <span class="dv">9</span>, <span class="dv">14</span>, <span class="dv">9</span>, <span class="dv">15</span>, <span class="dv">14</span>, <span class="dv">10</span>, <span class="dv">1</span>, <span class="dv">22</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">17</span>, <span class="dv">16</span>, <span class="dv">10</span>)</span>
<span id="cb29-2"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb29-2"></a>s2            &lt;-<span class="st"> </span><span class="kw">var</span>(x)</span>
<span id="cb29-3"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb29-3"></a>N             &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb29-4"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb29-4"></a>n             &lt;-<span class="st"> </span><span class="dv">15</span></span>
<span id="cb29-5"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb29-5"></a>total.muestra &lt;-<span class="st"> </span>N<span class="op">*</span><span class="kw">mean</span>(x)</span>
<span id="cb29-6"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb29-6"></a>ci            &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.975</span>)<span class="op">*</span><span class="kw">sqrt</span>(N<span class="op">^</span><span class="dv">2</span><span class="op">*</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>n<span class="op">/</span>N)<span class="op">/</span>n<span class="op">*</span>s2)</span>
<span id="cb29-7"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb29-7"></a>ci_low        &lt;-<span class="st"> </span><span class="kw">round</span>(total.muestra <span class="op">-</span><span class="st"> </span>ci,<span class="dv">2</span>)</span>
<span id="cb29-8"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb29-8"></a>ci_up         &lt;-<span class="st"> </span><span class="kw">round</span>(total.muestra <span class="op">+</span><span class="st"> </span>ci,<span class="dv">2</span>)</span>
<span id="cb29-9"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb29-9"></a></span>
<span id="cb29-10"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb29-10"></a><span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&quot;Se estiman &quot;</span>, <span class="kw">round</span>(total.muestra,<span class="dv">2</span>), <span class="st">&quot; personas con intervalo de &quot;</span>,</span>
<span id="cb29-11"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb29-11"></a>             <span class="st">&quot;confianza al 95% de [&quot;</span>, ci_low, <span class="st">&quot; ,&quot;</span>, ci_up,<span class="st">&quot;]&quot;</span>))</span></code></pre></div>
<pre><code>## [1] &quot;Se estiman 1186.67 personas con intervalo de confianza al 95% de [959.55 ,1413.78]&quot;</code></pre>
</div>
<div id="ejercicio-3" class="section level2">
<h2><span class="header-section-number">5.5</span> Ejercicio:</h2>
<p>Cuando se resgistra un paquete de <code>R</code> en <a href="https://cran.r-project.org">CRAN</a> estos se registran junto con sus autores como muestra la imagen:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#cb31-1"></a>knitr<span class="op">::</span><span class="kw">include_graphics</span>(<span class="st">&quot;images/CRAN.png&quot;</span>)</span></code></pre></div>
<p><img src="images/CRAN.png" width="75%" /></p>
<p>La información de un paquete puede encontrarse en la página de <code>CRAN</code> dando clic en <code>Packages</code> y luego en <code>Table of available packages, sorted by name</code> y buscando el paquete deseado.</p>
<p>Se desea conocer el número promedio de autores por paquete registrado en <code>CRAN</code> con un intervalo de confianza al 80% y un error de <span class="math inline">\(\pm 1\)</span>. Obtén la <span class="math inline">\(n\)</span> necesaria para muestrear, calcula un estimador de la media y obtén intervalos de confianza. Justifica tu elección de la varianza para la <span class="math inline">\(n\)</span> mediante un estudio piloto (muestreando de manera inicial <span class="math inline">\(10\)</span> y calculando la varianza de ellos).</p>
<p><strong>Hint</strong> Para obtener una lista (censo) de todos los paquetes de <code>R</code> puedes utilizar la función <code>available.packages()</code> la cual devuelve una matriz con todos los paquetes e incluye la <code>url</code> de donde se encuentra.</p>
</div>
<div id="ejemplo-resumen-estimación-de-una-región-crítica" class="section level2">
<h2><span class="header-section-number">5.6</span> Ejemplo Resumen: Estimación de una región crítica</h2>
<p>En una elección existen dos candidatas <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span>. Se realiza una encuesta de opinión mediante muestreo aleatorio simple sin reemplazo donde se les pregunta a una cantidad suficiente de votantes por quién votarían de las dos. En este análisis no hay <code>NO SABE / NO RESPONDE</code> sino que todos los individuos indican su preferencia. Se desea determinar la cantidad de puntos porcentuales que debe haber de diferencia entre la proporción de individuos que reportan apoyan al candidato <span class="math inline">\(A\)</span> y los que reportan que apoyan al <span class="math inline">\(B\)</span> de tal forma que el <span class="math inline">\(95\%\)</span> de las veces podamos declarar de manera adecuada al ganador.</p>
<blockquote>
<p><strong>Nota</strong> Si <span class="math inline">\(A\)</span> no es el ganador entonces <span class="math inline">\(p_A &lt; 50\%\)</span> (la proporción de votantes que van a elegir a <span class="math inline">\(A\)</span> es menor a la mitad) ¿cierto?</p>
</blockquote>
<p>Para ello el análisis es como sigue: sea <span class="math inline">\(\hat{p}_A\)</span> un estimador de la proporción de individuos que van a elegir a <span class="math inline">\(A\)</span> y <span class="math inline">\(p_A\)</span> la verdadera proporción. Sin pérdida de generalidad supondremos que <span class="math inline">\(B\)</span> es el ganador; es decir que <span class="math inline">\(p_A &lt; 0.5\)</span>.
El problema puede traducirse en determinar una <span class="math inline">\(c\)</span> tal que:
<span class="math display">\[
\mathbb{P}\big( \hat{p}_A &gt; c | p_A &lt; 0.5 \big) \leq 0.05
\]</span>
Notamos que el evento <span class="math inline">\(\{ p_A &lt; 50\%\}\)</span> es por definición conocido (con probabilidad <span class="math inline">\(0\)</span> ó <span class="math inline">\(1\)</span>) pues está dado por la población (constante). Notamos que por el teorema del límite central podemos escribir:
<span class="math display">\[
\dfrac{\hat{p}_A - p_A}{\sqrt{\text{Var}(\hat{p}_A )}}\sim \text{Normal}\big(0, 1\big)
\]</span>
donde <span class="math inline">\(\hat{p}_A = \frac{1}{N} \sum_{i = 1}^N x_i \mathbb{I}_{\mathcal{S}}(x_i)\)</span> como anteriormente hicimos para proporciones y su varianza está dada por:
<span class="math display">\[
\text{Var}(\hat{p}_A ) = \frac{p_A(1-p_A)}{n}\Big( \frac{N-1}{N-n}\Big)
\]</span>
donde el cálculo se hizo en el primer ejemplo de esta sección. Podemos transformar el problema entonces en hallar <span class="math inline">\(c\)</span> tal que:
<span class="math display">\[
\mathbb{P}\bigg( \underbrace{\frac{\hat{p}_A - p_A}{\sqrt{\text{Var}(\hat{p}_A )}}}_{Z \sim \text{Normal}(0,1)} &gt; \frac{c - p_A}{\sqrt{\text{Var}(\hat{p}_A)}} \bigg| p_A &lt; 0.5 \bigg) \leq 0.05
\]</span>
Notamos que el lado izquierdo tiene una aproximación normal y entonces podemos reescribir el problema como hallar <span class="math inline">\(c\)</span> tal que:
<span class="math display">\[
\mathbb{P}\bigg( Z &gt; \frac{c - p_A}{\sqrt{\text{Var}(\hat{p}_A)}} \bigg| p_A &lt; 0.5 \bigg) \leq 0.05 \qquad \text{ donde } Z \sim \text{Normal}(0,1).
\]</span></p>
<p>Recordando la expresión para la varianza sustituyo:
<span class="math display">\[
\mathbb{P}\left( Z &gt; \dfrac{c - p_A}{\sqrt{\frac{p_A(1-p_A)}{n}\Big( \frac{N-1}{N-n}\Big)}} \Bigg| p_A &lt; 0.5 \right) \leq 0.05 \qquad \text{ donde } Z \sim \text{Normal}(0,1).
\]</span>
En función del análisis pasado, observamos que <span class="math inline">\(\dfrac{c - p_A}{\sqrt{\frac{p_A(1-p_A)}{n}\Big( \frac{N-1}{N-n}\Big)}}\)</span> es una función decreciente en términos de <span class="math inline">\(p_A\)</span> (¡compruébalo!) y que el mínimo valor se alcanza en el máximo de la <span class="math inline">\(p_A\)</span> en el intervalo; es decir cuando <span class="math inline">\(p_A = \frac{1}{2}\)</span>. Luego el problema se transforma en hallar <span class="math inline">\(c\)</span> tal que:</p>
<p><span class="math display">\[
\mathbb{P}\left( Z &gt; \dfrac{c - \frac{1}{2}}{\sqrt{\frac{\frac{1}{2}(1-\frac{1}{2})}{n}\Big( \frac{N-1}{N-n}\Big)}} \right) \leq 0.05 \qquad \text{ donde } Z \sim \text{Normal}(0,1).
\]</span>
donde eliminamos el evento <span class="math inline">\(p_A &lt; 0.5\)</span> por ser un evento seguro. Reescribimos el evento:
<span class="math display">\[
\underbrace{\mathbb{P}\left( Z &lt; \dfrac{c - \frac{1}{2}}{\sqrt{\frac{\frac{1}{2}(1-\frac{1}{2})}{n}\Big( \frac{N-1}{N-n}\Big)}} \right)}_{\Phi(x)} \geq 0.95 \qquad \text{ donde } x = \dfrac{c - \frac{1}{2}}{\sqrt{\frac{\frac{1}{2}(1-\frac{1}{2})}{n}\Big( \frac{N-1}{N-n}\Big)}}
\]</span>
de tal forma que descubrimos la acumulada de la normal; terminamos de escribir todo:
<span class="math display">\[
\Phi(x) \geq 0.95
\]</span>
donde aplicamos la función inversa de la acumulada de la normal para descubrir:
<span class="math display">\[
\dfrac{c - \frac{1}{2}}{\sqrt{\frac{\frac{1}{2}(1-\frac{1}{2})}{n}\Big( \frac{N-1}{N-n}\Big)}} \geq \phi^{-1}(0.95) \Rightarrow c = \frac{1}{2} + \phi^{-1}(0.95)\sqrt{\frac{\frac{1}{2}(1-\frac{1}{2})}{n}\Big( \frac{N-1}{N-n}\Big)}
\]</span>
de donde se sigue que:
<span class="math display">\[
\hat{p}_{A} &gt; \frac{1}{2}\Bigg(1 + \phi^{-1}(0.95)\sqrt{\frac{N-1}{n(N-n)}} \Bigg) \Rightarrow 2\hat{p}_A = 1 + \phi^{-1}(0.95)\sqrt{\frac{N-1}{n(N-n)}} 
\]</span>
Notando que los puntos porcentuales de <span class="math inline">\(B\)</span> estimados mediante <span class="math inline">\(\hat{p}_B\)</span> tienen la forma:
<span class="math display">\[
\hat{p}_B = 1 - \hat{p}_A
\]</span>
se tiene entonces que la diferencia entre puntos para determinar quien gana es:
<span class="math display">\[
\hat{p}_A - \hat{p}_B = 2\hat{p}_A - 1 \geq \phi^{-1}(0.95)\sqrt{\frac{N-1}{n(N-n)}} 
\]</span>
El mismo análisis se seguiría bajo la hipótesis de que el perdedor es <span class="math inline">\(B\)</span>; por tanto se tiene que cumplir que:
<span class="math display">\[
| \hat{p}_A - \hat{p}_B | \geq \phi^{-1}(0.95)\sqrt{\frac{N-1}{n(N-n)}} 
\]</span>
para poder declarar como ganador a aquél con más puntos porcentuales de manera correcta con una confianza del <span class="math inline">\(95\%\)</span>.</p>
</div>
<div id="ejemplo-resumen-estimación-del-total-de-una-población" class="section level2">
<h2><span class="header-section-number">5.7</span> Ejemplo Resumen: Estimación del total de una población</h2>
<p>Consideremos una población de tiburones donde se desconoce el tamaño total de la población <span class="math inline">\(N\)</span>. Algunas veces para determinar el tamaño poblacional se utiliza un modelo de <em>captura y recaptura</em>. En él se capturan <span class="math inline">\(\ell\)</span> individuos los cuales se identifican (<a href="http://www.fao.org/tempref/docrep/fao/008/a0212e/a0212E04.pdf">mediante etiquetas</a>, por ejemplo) y se devuelven a convivir entre la población de <span class="math inline">\(N\)</span> para mezclarse de vuelta. Una vez mezclados, seleccionamos <span class="math inline">\(n\)</span> nuevos individuos por muestreo aleatorio simple sin reemplazo donde descubrimos que <span class="math inline">\(K\)</span> están marcados. Suponiendo que <span class="math inline">\(K \neq 0\)</span>, determinaremos un estimador <span class="math inline">\(\hat{N}\)</span> del total poblacional (en el caso <span class="math inline">\(K = 0\)</span> tuvimos muy mala suerte y seguimos recapturando tiburones hasta encontrar alguno).</p>
<p>En primer lugar notamos que los <span class="math inline">\(K\)</span> marcados que surgen en la segunda muestra siguen una distribución hipergeométrica:
<span class="math display">\[
\mathbb{P}\big( K = x) = \dfrac{\binom{\ell}{x} \binom{N-\ell}{n-x}}{\binom{N}{n}}
\]</span>
donde <span class="math inline">\(x \in \big[ \max\{ 0, \ell-N+n\}, \min\{n,\ell\}\big]\cap\mathbb{N}\)</span>. Para construir el estimador notamos que:
<span class="math display">\[
\mathbb{E}(K) = n \frac{\ell}{N}
\]</span>
de donde podemos despejar <span class="math inline">\(N\)</span>:
<span class="math display">\[
N= n \frac{\ell}{\mathbb{E}(K) }
\]</span>
Ahora bien, dada una muestra donde se obtuvieron <span class="math inline">\(K\)</span> (de <span class="math inline">\(n\)</span>) marcados se propone un estimador de <span class="math inline">\(N\)</span> dado por:
<span class="math display">\[
\hat{N} = \ell  \cdot \frac{n}{K}
\]</span>
donde <span class="math inline">\(K = \sum_{i = 1}^n x_i\)</span> donde las <span class="math inline">\(x_i = 1\)</span> si estaba marcado y <span class="math inline">\(x_i = 0\)</span> si no lo estaba. La <span class="math inline">\(K\)</span> de hecho depende de la muestra y se puede escribir como:
<span class="math display">\[
K = \sum_{i = 1}^N x_i\mathbb{I}_{\mathcal{S}}(x_i)
\]</span>
Para estimar si <span class="math inline">\(\hat{N}\)</span> es insesgado, habría que calcular su valor esperado condicional en que <span class="math inline">\(K &gt; 0\)</span>. Para ello notamos que:
<span class="math display">\[
\mathbb{E}\big[ \hat{N} | K &gt; 0\big] =(\ell n) \cdot \mathbb{E}\big[ \frac{1}{K} \big| K &gt; 0 \big]
\]</span>
Sabemos (por la desigualdad de Jensen) que <span class="math inline">\(\mathbb{E}\big[ \frac{1}{K} \big] \neq \dfrac{1}{\mathbb{E}[K]}\)</span> por lo cual aproximamos el valor esperado mediante una expansión de Taylor; es decir para una función <span class="math inline">\(f \in \mathcal{C}^2\)</span>:
<span class="math display">\[
\mathbb{E}\big[ f(X) \big] \approx \mathbb{E}\big[ f(\mu) + (X - \mu) f&#39;(\mu) +  (X - \mu)^2 f&#39;&#39;(\mu)\big] = f(\mu) + \text{Var}\big[X\big] f&#39;&#39;(\mu)
\]</span>
donde <span class="math inline">\(\mu = \mathbb{E}\big[X\big]\)</span>. En nuestro caso <span class="math inline">\(f(k) = \frac{1}{k}\)</span> y por tanto:
<span class="math display">\[
\mathbb{E}\big[ \frac{1}{K} \big| K &gt; 0 \big]\approx \dfrac{1}{\mathbb{E}\big[ K | K &gt; 0]} + 2 \cdot \dfrac{\text{Var}\big[K | K &gt; 0\big] }{\big(\mathbb{E}\big[ K | K &gt; 0]\big)^3} = \dfrac{1}{\mu} + 2 \dfrac{\sigma^2}{\mu^3}
\]</span>
Calculamos los valores esperados:
<span class="math display">\[
\mathbb{E}\big[K\big] = \underbrace{\mathbb{E}\big[K | K = 0\big]\mathbb{P}(K = 0)}_{=0} + \mathbb{E}\big[K | K &gt; 0\big]\mathbb{P}(K &gt; 0) \Rightarrow \mathbb{E}\big[K | K &gt; 0\big] = \frac{\ell n}{N} \dfrac{1}{\mathbb{P}(K &gt; 0)}
\]</span>
de donde se sigue que:
<span class="math display">\[
\mathbb{E}\big[K | K &gt; 0\big] = \frac{\ell n}{N} \dfrac{1}{1 - \mathbb{P}(K = 0)} = \dfrac{\ell n}{N} \dfrac{1}{1 - \frac{\binom{N-\ell}{n}}{\binom{N}{n}} } = \dfrac{\ell n}{N} \cdot \dfrac{\binom{N}{n}}{\binom{N}{n} - \binom{N-\ell}{n}} = \mu
\]</span></p>
<p>Por otro lado el cálculo de la varianza:
<span class="math display">\[\begin{equation}\nonumber
\begin{aligned}
 \text{Var}\big[K | K &gt; 0\big] &amp; =\mathbb{E}\big[K^2 | K &gt; 0] - \mathbb{E}\big[K^2 | K &gt; 0]^2\\
 &amp; =  \dfrac{\mathbb{E}\big[K^2]}{\mathbb{P}(K &gt; 0)} - \mu^2 \\
 &amp; =  \dfrac{\text{Var}[K] + \mathbb{E}[K]^2}{1 - \mathbb{P}(K = 0)} - \mu^2 \\
 &amp; = \dfrac{\text{Var}[K] + \Big(n\frac{M}{N}\Big)^2}{1 - \mathbb{P}(K = 0)} - \mu^2\\
 &amp; = \dfrac{\frac{n\ell}{N} \cdot \frac{(N-\ell)}{N} \cdot \Big( \frac{N-n}{N-1} \Big) + \Big(n\frac{M}{N}\Big)^2}{1 - \mathbb{P}(K = 0)} - \mu^2 \\
 &amp; = \dfrac{\frac{n\ell}{N} \cdot \frac{(N-\ell)}{N} \cdot \Big( \frac{N-n}{N-1} \Big) + \Big(n\frac{M}{N}\Big)^2}{1 -  \frac{\binom{N-\ell}{n}}{\binom{N}{n}}} - \mu^2 \\
 &amp; = \binom{N}{n} \dfrac{\frac{n\ell}{N} \cdot \frac{(N-\ell)}{N} \cdot \Big( \frac{N-n}{N-1} \Big) + \Big(n\frac{M}{N}\Big)^2}{\binom{N}{n} -  \binom{N-\ell}{n}}- \mu^2 &amp; = \sigma^2\\
\end{aligned}
\end{equation}\]</span></p>
<p>Donde se tiene entonces que:
<span class="math display">\[
\mathbb{E}\big[ \hat{N} | K &gt; 0\big] \approx (\ell n) \Bigg[ \cdot \dfrac{1}{\mathbb{E}\big[ K | K &gt; 0]} + 2 \cdot \dfrac{\text{Var}\big[K | K &gt; 0\big] }{\big(\mathbb{E}\big[ K | K &gt; 0]\big)^3} \Bigg]
\]</span>
con los valores estimados en los renglones anteriores. En particular, <span class="math inline">\(\hat{N}\)</span> no es insesgado pero puede demostrarse que en el límite <span class="math inline">\(\lim_{\substack{n \to \infty \\ N-n\to\infty}}\)</span> lo es.</p>
<p>De manera similar puede obtenerse (ver Lohr capítulo 13):
<span class="math display">\[
\text{Var}\big[ \hat{N} | K &gt; 0\big]\approx \Big(\dfrac{n \ell}{K}\Big)^2 \dfrac{\ell - K}{K(\ell - 1)}
\]</span>
Misma que puede utilizarse para los intervalos de confianza.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>Una mejor distribución sería una <span class="math inline">\(t\)</span> de Student; empero eso lo verás en Estadística Matemática.<a href="muestreo-aleatorio-simple-sin-reemplazo-massr.html#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="notación.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="demostración-del-teorema-del-límite-central-para-muestras-finitas.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": ["night", "white", "sepia"],
"family": "sans",
"size": [2, 4]
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Introduccion_a_Muestreo.pdf", "Introduccion_a_Muestreo.epub"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true,
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
